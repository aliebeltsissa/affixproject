setwd("C:/Users/annal/OneDrive/Documents/GitHub/affixproject");

participants <- list("5aa787c66219a30001c765f8","5ae5db897edeb000014a85ee","5b212164cfbf200001cfb3ad","5b213220809d160001a2c36d","5bcd11401662020001fe82c1","5c19254b0b9f6b00014769ee","5c1bfabab0fcc900019d9ff4","5caccaed2f93d700157b4782","5cbe02ab39447e0001745a5e","5cefe8856e0eec00015971dd","5d9a125f1714540016a40a27","5dab6e7d80e1780016d5bc9b","5dcb33ab0550ef819f508abf","5e12048c7605fe8839180a14","5e283f8ad48ecf000ddd0724","5e2c6968e97bec29709a53c6","5e3ff59bf2160b23942ada93","5e42b6421f44d3143440b25c","5e42f03607b468000d8eb912","5e433ed3393e971e19f4735d","5e577e79ce30ae13226e61ae","5e6d3324f14d262fced5bbfe","5e87b28549538b0fdf96b318","5e89e89bf025be000c01eead","5e8b66490d48450346bf2755","5e8c57d9b4483e012006e7aa","5e8e55509422bb10abed1f54","5e9bd025eb6b380e1d66d04c","5ea171c1a8782801263e7540","5ea9611edec14d052ada0bae","5ea9cd383b32cf15448a86ac","5eaae42f19a24d05cbd6ccb4","5eaf1c50f3540c614eb973a5","5eb35dff41a381156be161c2","5eb71c59c55b3b0ce571ae7c","5ebc0c153f8b2e04d3833423","5ec12ed7a66dbf01c7d740c1","5ec1c01a8ccaaa5ec0080c91","5ec6d06c67b0da0fb6f85e83","5ecbb4c00bc62403dae2df59","5ecd21dec04cca02c9032485","5ed013f88fce6e0d858b732e","5ee623674afa60375e30eec3","5ee83da8817af0000d47448f","5ee942381a22491bbb7170f8","5eef3de3fb4e031bf546d887","5efd2964d36f63162f263795","5f0471a92ec97b6d1aec7739","5f09d989eff16b266fba44c0","5f0d65ef2ad0c60009209f0f","5f0f93938935de000855898b","5f11c9f84078cd0888177499","5f18a80367ef6b0bbc5f3720","5f19fa0f3e85b20d0336258c","5f1e8dc7e2161c86cdcd220a","5f219602670e5a0af2cf5237","5f33289c1fe9181376ee67d9","5f33c58329beab1f63c0dfaa","5f350f459bf003464a03ea5e","5f47e34858dd331165bf9f00","5f5a713d37f71112463ab4d9","5f5e7de4c81d3672642cd612","5f6cd5ce1758e90f12ae1123","5f708f5f0d32bb66960d4473","5f784f5b98f4963cdf902340","5f7bd801486f5e1ce581980f","5f858743256d25036d9fa693","5f91dc284909fe0b08f9e2e1","5f99cee5a2a7d109a1624e10","5fa4258658811d03fbc6ce8b","5fa4725a186c050edc3bcc20","5fa5793490f10705755818c0","5fa59d4d5a29c90da975efe9","5fc2d2d79da439201ab6addc","5fc44d83862e3e79b02e0438","5fc781689771f106330abf6a","5fd2416e5061f30735e202e9","5fd69a0014c3b25ee539f66b","5fd9c5c67fa7c74ec42bb318","5fdbf74c5474cd11e39eeaf3","5fe2308a91773957e88b89be","600e0dadada7da69afc5b3de","600f0f9c3bfcdc077c924e51","60123adc24c9f126819861b6","601705a0246e51313e8ed38e","601951245f481e000980504f","601b5c79e845ac360826c9df","601ffb441dc6d959b855eea5","602bb123612bfe330818d4ef","6042a56575ab0c1ccffc3152","60491025dd8eb31e48a0ca8d","60536ffae4f98513b671f482","605aa0bb5fb71bbcf0808892","60645fe61129208791535d15","6065d7d47409810344f7e6bb","60664619eac28843177fee96","60670ac0fc7e169231369ab1","606dc21c1ce7dc64af9d81fb","6074768dc48e0753011d3d72","607ea5504e74d104da5a108a","60883a7e91c0be66dbb96fc8","608858869a591bd129fbbc6c","608c2e566d92c2aa3543e2d2","608c64e14968cdd8dcbe1be4","6092e2aac56871319199b6a5","6093cacf9a39751eedd55916","60957b300f08087b0af0031c","60a3fe2d888e7a090d6d8f82","60a68725b2b424dc0d7ce793","60b7b8126c0c4524e913236e","60bbe0da43325dadf2b1b6a9","60c49e68081928c86ba7b98a","60d478e72e8251287b641b2d","60d7605d7af8d66774061717","60db4aed5dd7b87124f51341","60dee3200c7c3355c62326d9","60e12640be1b69b66053d55b","60e3b18d3d4205b4c52ada56","60e9ea97d19e613e60a994da","60eb26fb8db6845a14fe5a91","60ec51c51a3158a50ded8a3e","60edd136d544e7c8f5fac8a7","60f030dca19a06db1b50d16a","60f56f0103876eae7c0d870f","60f579085ebf24f9c80f223e","60f6b8f8e574e14634ead43e","60f88d7fef1959734061e5a7","60fd0f49858465796afd5da9","6100174f92a7a0e5141b195e","61001b6892ebd05a24fe82e1","61055020201a7da5a704f7dd","6107d788163252e3b5c348e3","610834993bac40f050062896","610958b8473c7b96e4bd207d","610a52647a452dee7ca89360","610d2275ba5f1ee0fdcee3e8","610f2eabb45be8717fc155e0","61125e23136464bd2cbbefc9","61143bd22a1649da3b52ae32","611bdb0fed7c9df6dce28c3f","611cebb780fbae98c5bcc84d","611dc53f0098557586e89b17","611e7d1295185bf6f56fd951","611e9c16e90a0d4c6f0d8df5","611eafa6011b0423f7d7230f",
                     "611eeafa283a2d1f57537fea","6120211d8e1eab16fcb7ad69","6122966a93af160af481836c","6124a4ba3df07e768bd9c90b","61275a3158c67415afb971ff","612a98181f4b6d1cf01f926c","61301fcb49db2f170cb02b93","6131f7010e926c9103558040","613867f34e206e4f573bc6ef","613a73d06cf1fcfef304d3fa","613ab1e64acd61ebd0a7116d","613f57084e80f056c78f9b7b","6140f1c4ead758f1b72bbe2f","6140ff9c5750f0081ca8d71f","6144742e57a61e489cc9e978","6147aed5b2a4f748dc2b6ba4","614b323022fcd8b7408005a6","614c80483d06dcf7ad552679","614c8e5469405530dc27b9d5","614dd6473c74b217ad73cc9c","61520b079436973e05f72d33","61548fa2b637194e04c9bc09","6155e204cc071b306458dfff","6156a440279fdf408ee663ae","6156b68cc77b48d6693b361c","615b042301e3a24311563ee4","615b1ab789b14c9996251fb4","615b41767003d4ece749ed9d","615da9ee365ab7d547b98979","615f371e6688c87e53e7acf5","61616ce2bb94584e11c911af","6163faf9d9ac4586fe776568","616494f1ae4537c01914c758","616631efeeac0979c1ba85a9","616891e25a026e1f7262116c","616eb493bb7e4ab4fa1de8d4","6170821d1e8ffb9c893b28a4","6171349b89a54d4823f9eca1","617142c2a843eef6f8f148b6","6171d922c871ba795b6a4827","6172078b966225960be2a7b5","617679054948369cb824d837","63ee5d8aaee278de46b7d4cc","6455490f7c5f35e4221a810a","64764d56699f097a96ec6e5c","64973d83e4fc64d6ae59c370","64a288758b7c82ff2d18da75","64ef422a4789bd6b6b9042ce","65032a60861e9a17bc1a7444","65089e7ce53888b0b3840c62","650aee87054446f772acdfcc");

library(paletteer);
cols <- paletteer_d("MetBrewer::Degas");

library(extrafont);
font_import();
loadfonts();
par(family="Montserrat");

# d' function
dPrime <- function(sbj, expectedResp, observedResp)
{
  sbjNumbers <- unique(sbj);
  dprimes <- vector(length=length(sbjNumbers), mode="numeric");
  log_beta <- vector(length=length(sbjNumbers), mode="numeric");
  c <- vector(length=length(sbjNumbers), mode="numeric");
  subjects <- vector(length=length(sbjNumbers), mode="integer");
  counter <- 1;
  for (s in sbjNumbers)
  {
    expectedRespCurrentSbj <- expectedResp[sbj==s];
    observedRespCurrentSbj <- observedResp[sbj==s];
    num_of_hits <- sum(observedRespCurrentSbj[expectedRespCurrentSbj==1])+.5;
    num_of_fa <- sum(observedRespCurrentSbj[expectedRespCurrentSbj==0])+.5;
    prop_of_hits <- num_of_hits/ (xtabs(~expectedRespCurrentSbj)[2]+1);
    prop_of_fa <- num_of_fa/ (xtabs(~expectedRespCurrentSbj)[1]+1);
    z_hits <- qnorm(prop_of_hits);
    z_fa <- qnorm(prop_of_fa); 
    dprimes[counter] <- round(z_hits - z_fa, digits = 3);
    log_beta[counter] <- round((z_fa^2 - z_hits^2)/2, digits = 3); #this is taken from Stanislaw and Todorov, PBR 1999. Log_beta=0 indicates no bias; negative values is bias for YES; positive values is bias for NO
    c[counter] <- round( -(z_hits + z_fa)/2, digits = 3); # this is taken again from Stanislaw and Todorov, PBR 1999, who note that c "...assumes that subjects respond yes when the decision variable exceeds the criterion and no otherwise; responses are based directly on the decision variable, which some researchers regard as more plausible than assuming that responses are based on a likelihood ratio [which the assumption behind beta] (Richardson, 1994). Another advantage of c is that it is unaffected by changes in d', whereas Beta is (Ingham, 1970; Macmil- lan, 1993; McNicol, 1972, pp. 63--64)". Similarly to log_beta, c=0 is no bias, negative c is bias for YES, negative c is bias for NO.
    subjects[counter] <- s;
    counter <- counter + 1;
  };
  print(data.frame(sbj=subjects, dprime=dprimes, log_beta=log_beta, c=c));
};


# Testing -----------------------------------------------------------------
# import testing data
data_all_testing <- read.csv("testing_preprocessed_clean.csv",header=T,sep=",");
data_all_testing <- subset(data_all_testing, select = -c(X)) # remove redundant column added by Pavlovia
data_testing <- data_all_testing[data_all_testing$sbj_ID %in% participants,]; # n = 196 participants
data_testing <- data_testing[!data_testing$sbj_ID %in% c('615b41767003d4ece749ed9d', '5e8b66490d48450346bf2755','615b042301e3a24311563ee4'),]
# exclusion:
#1. said yes to all BLP use questions
#2-3. means RTs above 2s
data_testing$temp_sbjID <- rep(1:193, each=111); # necessary: R doesn't like format of Prolific IDs

# make some variables factors
data_testing$sbj_ID <- as.factor(data_testing$sbj_ID);
data_testing$task <- as.factor(data_testing$task);
data_testing$item <- as.factor(data_testing$item);
data_testing$testing_condition <- as.factor(data_testing$testing_condition);
data_testing$correct <- as.logical(data_testing$correct);
summary(data_testing);

# change coding: make YES into 1 and NO into 0
data_expected <- replace(data_testing$expected, data_testing$expected == 0, 'YES');
data_expected <- replace(data_expected, data_expected == 1, 'NO');
data_expected <- replace(data_expected, data_expected == 'NO', 0);
data_expected <- replace(data_expected, data_expected == 'YES', 1);
data_testing$expected <- data_expected;
data_testing$expected <- as.numeric(data_testing$expected);

data_observed <- replace(data_testing$observed, data_testing$observed == 0, 'YES');
data_observed <- replace(data_observed, data_observed == 1, 'NO');
data_observed <- replace(data_observed, data_observed == 'NO', 0);
data_observed <- replace(data_observed, data_observed == 'YES', 1);
data_testing$observed <- data_observed;
data_testing$observed <- as.numeric(data_testing$observed);

# due to technical issue: n(0M)=40, n(1M)=37, n(2M)=34
total_0M <- 40;
total_1M <- 37;
total_2M <- 34;

# testing RTs
library(paletteer);
cols2 <- paletteer_d("palettesForR::Named");
IDs <- list(data_testing$sbj_ID);
IDs <- sapply(IDs, unique);
plot(density(data_testing$rt[data_testing$sbj_ID==IDs[1]],na.rm=TRUE),xlim=c(0,2200),ylim=c(0,0.007),xlab="RTs (ms)",main="",xaxt = "n",col=cols2[1],yaxs="i",lwd=1,cex.lab=1.5);
axis(1, at = c(0,200,400,600,800,1000,1200,1400,1600,1800,2000,2200));
for (x in 2:195) {
  lines(density(data_testing$rt[data_testing$sbj_ID==IDs[x]],na.rm=TRUE),col=cols2[x],lwd=1)
};
data_testing_rt_means <- aggregate(data_testing$rt, list(data_testing$sbj_ID), FUN=mean, na.rm=TRUE);
summary(data_testing_rt_means);
#min:158 Q1:815 med:961 mean:955 Q3:1147 max:1694
plot(data_testing_rt_means$x, ylab="Mean participant RT (ms)",xlab="Participants",main="",xaxt = "n",pch=3,yaxs="i",ylim=c(0,2750))

# yes responses globally
mean_yes <- aggregate(data_testing$observed,by=list(data_testing$sbj_ID), FUN=function(x) sum(x == 1));
names(mean_yes) <- c("sbj_ID", "yes");
summary(mean_yes$yes);
# no one responding only "yes" or no "yes"

# 0M yes responses boxplot
data_testing_0M_yes <- aggregate(data_testing$observed[data_testing$testing_condition=='0M'], by=list(data_testing$temp_sbjID[data_testing$testing_condition=='0M']), FUN = function(x) sum(x == 1));
names(data_testing_0M_yes) <- c("temp_sbjID","x_0");
data_testing_0M_yes$x_0 <- data_testing_0M_yes$x_0/total_0M*100; #transform into percent
summary(data_testing_0M_yes$x_0);
#min:12.5 Q1:40 med:50 mean:49.44 Q3:60 max:100
t.test(data_testing_0M_yes$x_0, mu=50);
#t=-0.53 p=0.60 CI=[47.37;51.52] -> not significantly different from 50%
boxplot(data_testing_0M_yes$x, ylab = "Percent of 'yes' responses",ylim=c(0,100),yaxs="i");
abline(h=50, lty=5);

# 0M scores
data_testing_0M_means <- aggregate(data_testing$correct[data_testing$testing_condition=='0M'], list(data_testing$temp_sbjID[data_testing$testing_condition=='0M']), FUN=mean, na.rm=TRUE);
names(data_testing_0M_means) <- c("temp_sbjID","x_0");
summary(data_testing_0M_means$x_0);
#min:0 Q1:0.40 med:0.50 mean:0.51 Q3:0.6 max:0.88
var(data_testing_0M_means$x_0);
#var=0.02
plot(data_testing_0M_means$x_0,pch=3,ylim=c(0,1),yaxs="i");
abline(h=0.5, lty=5);
#6170821d1e8ffb9c893b28a4 at 0% -> 100% at 1M (!) and 44% at 2M
#quite a wide range of scores
hist(data_testing_0M_means$x_0); # normally distributed
t.test(data_testing_0M_means$x_0, mu=0.5);
#t=0.53 p=0.60 CI=[0.48;0.53] -> not significantly different from 50%

# 1M yes responses boxplot
data_testing_1M_yes <- aggregate(data_testing$observed[data_testing$testing_condition=='1M'], by=list(data_testing$temp_sbjID[data_testing$testing_condition=='1M']), FUN = function(x) sum(x == 1));
names(data_testing_1M_yes) <- c("temp_sbjID","x_1");
data_testing_1M_yes$x_1 <- data_testing_1M_yes$x_1/total_1M*100; #transform into percent
summary(data_testing_1M_yes$x_1);
#min:10.8 Q1:46 med:56.8 mean:55 Q3:62.2 max:100
t.test(data_testing_1M_yes$x_1, mu=50);
#t=4.94 p=1.70e-6 CI=[53.01;57.01] -> significantly above from 50%
boxplot(data_testing_1M_yes$x, ylab = "Percent of 'yes' responses",ylim=c(0,100),yaxs="i");
abline(h=50, lty=5);

# 1M scores
data_testing_1M_means <- aggregate(data_testing$correct[data_testing$testing_condition=='1M'], list(data_testing$temp_sbjID[data_testing$testing_condition=='1M']), FUN=mean, na.rm=TRUE);
names(data_testing_1M_means) <- c("temp_sbjID","x_1");
summary(data_testing_1M_means$x_1);
#min:0.1 Q1:0.46 med:0.57 mean:0.55 Q3:0.62 max:1
#60d478e72e8251287b641b2d & 6170821d1e8ffb9c893b28a4 at 100%? -> they're at 0.5 and 0.44 respectively in 2M
var(data_testing_1M_means$x_1);
#var=0.02
plot(data_testing_1M_means$x_1,pch=3,ylim=c(0,1),yaxs="i");
abline(h=0.5, lty=5);
#quite a wide range of scores
hist(data_testing_1M_means$x_1); # normally distributed
t.test(data_testing_1M_means$x_1, mu=0.5);
#t=4.94 p=1.69e-6 CI=[0.53,0.57]

# 2M yes responses boxplot
data_testing_2M_yes <- aggregate(data_testing$observed[data_testing$testing_condition=='2M'], by=list(data_testing$temp_sbjID[data_testing$testing_condition=='2M']), FUN = function(x) sum(x == 1));
names(data_testing_2M_yes) <- c("temp_sbjID","x_2");
data_testing_2M_yes$x_2 <- data_testing_2M_yes$x_2/total_2M*100; #transform into percent
summary(data_testing_2M_yes$x_2);
#min:11.8 Q1:55.9 med:64.7 mean:64 Q3:73.5 max:100
t.test(data_testing_2M_yes$x_2, mu=50);
#t=13.54 p<2.2e-16 CI=[61.98;66.06] -> significantly above 50%
boxplot(data_testing_2M_yes$x, ylab = "Percent of 'yes' responses",ylim=c(0,100),yaxs="i");
abline(h=50, lty=5);

# yes responses across conditions
library(tidyverse);
data_testing_conditions <- list(data_testing_0M_yes,data_testing_1M_yes,data_testing_2M_yes) %>% reduce(inner_join, by='sbj_ID');
boxplot(data_testing_conditions$x_0,data_testing_conditions$x_1,data_testing_conditions$x_2, ylab='Percent of "yes" responses', xlab="Condition", names=c('0M','1M','2M'),ylim=c(0,100),yaxs="i");
abline(h=50, lty=5);
conditions_table <- table(data_testing$testing_condition, data_testing$observed);
chisq.test(conditions_table);
# X-squared=308.03, df=2, p<2.2e-16
data_testing_conditions <- data_testing_conditions %>%
  gather(condition, score, -sbj_ID);
data_testing_conditions$score <- data_testing_conditions$score/100;

ggplot(data_testing_conditions, aes(x = condition, y = score, color = condition)) +
  geom_hline(yintercept=0.5, linetype="dashed", 
             color = "darkgray",lwd=1.25) +
  geom_jitter(width = 0.1, height = 0, alpha = 0.3,color= "black",size=2) +
  labs(x = "Condition", y = 'Proportion of "yes" responses') +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        axis.text = element_text(family = "Montserrat", size = 28, color = "black"),
        text=element_text(family="Montserrat",size=28,color="black")) +
  scale_y_continuous(expand = c(0, 0),breaks=seq(0,1,0.2)) +
  expand_limits(y = 1.05) +
  stat_summary(geom = "point",fun = "mean",col = "red",size = 4,shape = 19) +
  stat_summary(geom = "errorbar", fun.data = "mean_se", width = 0.1,col="red",position = position_dodge(width = 0.5)) +
  scale_x_discrete(labels=c("0M", "1M", "2M"));

library(ggplot2);
conditions_dataframe <- as.data.frame(conditions_table);
ggplot(conditions_dataframe,
       aes(x = Var1,
           y = Freq,
           fill = Var2)) + 
  geom_bar(stat = "identity") +
  theme(axis.line = element_line()) +
  theme_classic() +
  scale_y_continuous(limits = c(0,8000), expand = c(0, 0)) +
  labs(x="Testing conditions", y="Frequency of responses", fill="Response") +
  scale_fill_manual(values = c("#F1BB7B","#FD6467"), labels=c("No","Yes"));

# 2M correct boxplot
data_testing_2M_means <- aggregate(data_testing$correct[data_testing$testing_condition=='2M'], list(data_testing$temp_sbjID[data_testing$testing_condition=='2M']), FUN=mean, na.rm=TRUE);
names(data_testing_2M_means) <- c("temp_sbjID","x_2");
par(mar=c(2,5,2,2));
boxplot(data_testing_2M_means$x_2, ylab = "2M accuracy score",family="Montserrat",cex.lab=2,cex.axis=2,boxwex=1.25);
abline(h=0.5, lty=5);
par(mar=c(5, 4, 4, 2) + 0.1); # back to default
summary(data_testing_2M_means$x_2);
#min:0.26 Q1:0.44 med:0.50 mean:0.50 Q3:0.54 max:0.71
var(data_testing_2M_means$x_2);
#var=0.005
plot(data_testing_2M_means$x_2,pch=3,ylim=c(0,1));
abline(h=0.5, lty=5); 
#nicely clustered around 50%
hist(data_testing_2M_means$x_2); # normally distributed
t.test(data_testing_2M_means$x_2, mu=0.50);
#t=-0.64 p=0.53 95% CI=[0.49;0.51]

# scores across conditions
library(tidyverse);
data_testing_conditions_scores <- list(data_testing_0M_means,data_testing_1M_means,data_testing_2M_means) %>% reduce(inner_join, by='temp_sbjID');
summary(data_testing_conditions_scores);
boxplot(data_testing_conditions_scores$x_0,data_testing_conditions_scores$x_1,data_testing_conditions_scores$x_2, ylab='Percent of correct responses', xlab="Condition", ylim=c(0,1), names=c('0M','1M','2M'));
abline(h=0.5, lty=5);

ggplot(data_testing_conditions, aes(x = condition, y = score, color = condition)) +
  geom_jitter(width = 0.1, alpha = 0.3,color= "black") +
  labs(x = "Condition", y = 'Proportion of "yes" responses') +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        text=element_text(family="Montserrat",size=20)) +
  scale_y_continuous(expand = c(0, 0),breaks=seq(0,1,0.2)) +
  expand_limits(y = 1) +
  geom_hline(yintercept=0.5, linetype="dashed", 
             color = "gray") +
  stat_summary(geom = "point",fun = "mean",col = "red",size = 3,shape = 19) +
  stat_summary(geom = "errorbar", fun.data = "mean_se", width = 0.05,col="red",position = position_dodge(width = 0.5)) +
  scale_x_discrete(labels=c("0M", "1M", "2M"));

# 2M - hits only
data_testing_2M_hits_means <- aggregate(data_testing$correct[data_testing$testing_condition=='2M'&data_testing$expected=='0'], list(data_testing$temp_sbjID[data_testing$testing_condition=='2M'&data_testing$expected=='0']), FUN=mean, na.rm=TRUE);
names(data_testing_2M_hits_means) <- c("temp_sbjID","x_2_hits");
boxplot(data_testing_2M_hits_means$x_2_hits, ylab = "Accuracy score - 2M hits");
abline(h=0.5, lty=5);
summary(data_testing_2M_hits_means$x_2_hits);
# min:0.12 Q1:0.53 med:0.65 mean:0.64 Q3:0.71 max:1
hist(data_testing_2M_hits_means$x_2_hits); # normally distributed
t.test(data_testing_2M_hits_means$x_2_hits, mu=0.50);
# significantly above chance: t=12.33, p<2.2e-16, CI=[0.62,0.66]
plot(data_testing_2M_hits_means$x_2_hits,ylim=c(0,1),ylab = "Hits",xlab="Participants",main="2M testing accuracy",pch=3,yaxs="i",col="#3B9AB2");
abline(h=0.5, lty=5);

# 2M - correct rejections only
data_testing_2M_rejs_means <- aggregate(data_testing$correct[data_testing$testing_condition=='2M'&data_testing$expected=='1'], list(data_testing$temp_sbjID[data_testing$testing_condition=='2M'&data_testing$expected=='1']), FUN=mean, na.rm=TRUE);
names(data_testing_2M_rejs_means) <- c("temp_sbjID","x_2_rejs");
boxplot(data_testing_2M_rejs_means$x_2_rejs, ylim=c(0,1), ylab = "Accuracy score - 2M correct rejections");
abline(h=0.5, lty=5);
summary(data_testing_2M_rejs_means$x_2_rejs);
# min:0.0 Q1:0.24 med:0.35 mean:0.36 Q3:0.47 max:0.94
hist(data_testing_2M_rejs_means$x_2_rejs); # normally distributed
t.test(data_testing_2M_rejs_means$x_2_rejs, mu=0.50);
# significantly below chance: t=-12.06, p<2.2e-16, CI=[0.33,0.38]
plot(data_testing_2M_rejs_means$x_2_rejs,ylim=c(0,1),ylab = "Correct rejections",xlab="Participants",pch=3,yaxs="i",col="#E1AF00");
abline(h=0.5, lty=5);

# 2M - all response types
library(tidyverse);
misses <- list();
for (i in 1:193) { # calculate misses for each participant
  temp <- data_testing[data_testing$temp_sbjID==i&data_testing$testing_condition=='2M',];
  miss <- temp %>%
    summarize(count = sum(expected == 1 & observed == 0));
  miss <- miss/40;
  misses <- append(misses, miss)
};
data_testing_2M_means$misses <- misses;
data_testing_2M_means$misses <- as.numeric(data_testing_2M_means$misses);
summary(data_testing_2M_means$misses);
# min:0 Q1:0.13 med:0.15 mean:0.15 Q3:0.20 max:0.38

hits <- list();
for (i in 1:193) { # calculate hits for each participant
  temp <- data_testing[data_testing$temp_sbjID==i&data_testing$testing_condition=='2M',];
  hit <- temp %>%
    summarize(count = sum(expected == 1 & observed == 1));
  hit <- hit/40
  hits <- append(hits, hit)
};
data_testing_2M_means$hits <- hits;
data_testing_2M_means$hits <- as.numeric(data_testing_2M_means$hits);
summary(data_testing_2M_means$hits);
# min:0 Q1:0.23 med:0.28 mean:0.27 Q3:0.30 max:0.43

rejs <- list();
for (i in 1:193) { # calculate correct rejections for each participant
  temp <- data_testing[data_testing$temp_sbjID==i&data_testing$testing_condition=='2M',];
  rej <- temp %>%
    summarize(count = sum(expected == 0 & observed == 0));
  rej <- rej/40
  rejs <- append(rejs, rej)
};
data_testing_2M_means$rejs <- rejs;
data_testing_2M_means$rejs <- as.numeric(data_testing_2M_means$rejs);
summary(data_testing_2M_means$rejs);
# min:0 Q1:0.10 med:0.15 mean:0.15 Q3:0.20 max:0.40

alarms <- list();
for (i in 1:193) { # calculate false alarms for each participant
  temp <- data_testing[data_testing$temp_sbjID==i&data_testing$testing_condition=='2M',];
  alarm <- temp %>%
    summarize(count = sum(expected == 0 & observed == 1));
  alarm <- alarm/40
  alarms <- append(alarms, alarm)
};
data_testing_2M_means$alarms <- alarms;
data_testing_2M_means$alarms <- as.numeric(data_testing_2M_means$alarms);
summary(data_testing_2M_means$alarms);
# min:0.03 Q1:0.26 med:0.28 mean:0.27 Q3:0.33 max:0.43

# 2M - combined plots
#1 - side-by-side scatterplots of hits & correct rejection accuracy
par(mfrow=c(2,1), mai = c(1, 1, 0.25, 0.5));
plot(data_testing_2M_hits_means$x,ylim=c(0,1),ylab = "Hits",xlab="Participants",main="2M testing accuracy",pch=3,yaxs="i",col="#3B9AB2");
abline(h=0.5, lty=5);
plot(data_testing_2M_rejs_means$x,ylim=c(0,1),ylab = "Correct rejections",xlab="Participants",pch=3,yaxs="i",col="#E1AF00");
abline(h=0.5, lty=5);
par(mfrow=c(1,1), mai = c(1, 1, 1, 1));

#2 - scatterplot with hits accuracy & correct rejection accuracy
plot(data_testing_2M_hits_means$x,ylim=c(0,1),ylab = "Accuracy",xlab="Participants",main="2M testing",pch=3,yaxs="i",col="#3B9AB2");
points(data_testing_2M_rejs_means$x,ylim=c(0,1),xlab="Participants",pch=3,yaxs="i",col="#E1AF00");
abline(h=0.5, lty=5);

#3 - plot connecting hit score to correct rejection score
library(ggplot2);
data_testing_2M_bygroup_means <- merge(data_testing_2M_hits_means,data_testing_2M_rejs_means,by="temp_sbjID");
names(data_testing_2M_bygroup_means) <- c("temp_sbjID","hits_mean","rejs_mean");
data_long <- reshape2::melt(data_testing_2M_bygroup_means, id.vars = "sbj_ID", variable.name = "condition", value.name = "accuracy");
ggplot(data_long, aes(x = condition, y = accuracy, group = temp_sbjID)) +
  geom_line(size=0.2) +
  geom_point(aes(color = condition), size = 3);

#4 - plot of difference between hit & correct rejection accuracy
data_testing_2M_bygroup_means$diff <- data_testing_2M_bygroup_means$hits_mean-data_testing_2M_bygroup_means$rejs_mean;
plot(data_testing_2M_bygroup_means$diff,ylim=c(-1,1),ylab="Accuracy difference",main="Difference between hits & correct rejection accuracy",xlab="Participants",pch=19,yaxs="i",col="#0B775E",cex=1.5);
abline(h=0, lty=5);

# testing accuracy*RTs
cor(data_testing_2M_means$x, data_testing_rt_means$x); # r = 0.04
plot(data_testing_rt_means$x, data_testing_2M_means$x, pch=19);

cor(data_testing_2M_hits_means$x, data_testing_rt_means$x); # r = 0.04
plot(data_testing_rt_means$x, data_testing_2M_hits_means$x, pch=19);

cor(data_testing_2M_rejs_means$x, data_testing_rt_means$x); # r = -0.01
plot(data_testing_rt_means$x, data_testing_2M_rejs_means$x, pch=19);

# correlation between 1M & 2M
temp <- merge(data_testing_2M_means, data_testing_1M_means,by.x='temp_sbjID',by.y='temp_sbjID');
cor(temp$x_1, temp$x_2); # r=-0.04
# 1M accuracy uncorrelated with 2M accuracy

# testing d'
dprimes <- dPrime(data_testing$temp_sbjID, data_testing$expected, data_testing$observed);
summary(dprimes)

data_testing_2M <- data_testing[data_testing$testing_condition == '2M',];
dprimes2M <- dPrime(data_testing_2M$temp_sbjID, data_testing_2M$expected, data_testing_2M$observed);
summary(dprimes2M);
# d':-0.02 c:-0.37
data_testing_2M_means$dprime <- dprimes2M$dprime;
data_testing_2M_means$c <- dprimes2M$c;

# testing strategy
library(tidyverse);
strats <- subset(data_testing, select = c(temp_sbjID, strategy));
strats <- strats[!duplicated(strats),];

# boxplot for accuracy of participants saying they just used intuition
intuition_sbjIDs <- list('2','14','15','17','25','26','28','29','37','47','48','51','52','58','65','66','78','89','90','93','97','102','104','107','108','110','111','113','115','120','121','122','124','131','140','175','179','181','188','189','191');
data_testing$intuition <- FALSE;
data_testing$intuition[data_testing$temp_sbjID %in% intuition_sbjIDs] <- TRUE;
data_testing_intuition_2M_means <- aggregate(data_testing$correct[data_testing$testing_condition=='2M'& data_testing$intuition==TRUE], list(data_testing$temp_sbjID[data_testing$testing_condition=='2M'& data_testing$intuition==TRUE]), FUN=mean, na.rm=TRUE);
colnames(data_testing_intuition_2M_means)[colnames(data_testing_intuition_2M_means)=="Group.1"]="temp_sbjID";
boxplot(data_testing_intuition_2M_means$x, ylab = "Accuracy score (in %)");
abline(h=0.5, lty=5);
summary(data_testing_intuition_2M_means); # mean: 49%

dprimes_intuition <- dPrime(data_testing$temp_sbjID[data_testing$intuition==TRUE&data_testing$testing_condition=='2M'], data_testing$expected[data_testing$intuition==TRUE&data_testing$testing_condition=='2M'], data_testing$observed[data_testing$intuition==TRUE&data_testing$testing_condition=='2M']);
names(dprimes_intuition) <- c("temp_sbjID","dprime","log_beta","c");
summary(dprimes_intuition);
# dprime:-0.05 c:-0.22

intuition_2M <- data_testing_2M_means[data_testing_2M_means$temp_sbjID %in% intuition_sbjIDs,];
summary(intuition_2M$hits); # mean = 0.25
summary(intuition_2M$rejs); # mean = 0.17
summary(intuition_2M$misses); # mean = 0.18
summary(intuition_2M$alarms); # mean = 0.26

# participants saying they used familiar chunks
chunks_sbjIDs <- list('1','8','9','10','12','13','22','24','41','53','55','62','76','80','97','105','109','117','119','127','129','138','139','141','149','152','178','185','186');
data_testing$chunks <- FALSE;
data_testing$chunks[data_testing$temp_sbjID %in% chunks_sbjIDs] <- TRUE;
data_testing_chunks_2M_means <- aggregate(data_testing$correct[data_testing$testing_condition=='2M'& data_testing$chunks==TRUE], list(data_testing$sbj_ID[data_testing$testing_condition=='2M'& data_testing$chunks==TRUE]), FUN=mean, na.rm=TRUE);
colnames(data_testing_chunks_2M_means)[colnames(data_testing_chunks_2M_means)=="Group.1"]="sbj_ID";
boxplot(data_testing_chunks_2M_means$x, ylab = "Accuracy score (in %)");
abline(h=0.5, lty=5);
summary(data_testing_chunks_2M_means$x); 
# min:0.32 Q1:0.47 med:0.50 mean:0.49 Q3:0.53 max:0.71
dprimes_chunks <- dPrime(data_testing$temp_sbjID[data_testing$chunks==TRUE&data_testing$testing_condition=='2M'], data_testing$expected[data_testing$chunks==TRUE&data_testing$testing_condition=='2M'], data_testing$observed[data_testing$chunks==TRUE&data_testing$testing_condition=='2M']);
names(dprimes_chunks) <- c("temp_sbjID","dprime","log_beta","c");
summary(dprimes_chunks);
# dprime:-0.03 c:-0.48

chunks_2M <- data_testing_2M_means[data_testing_2M_means$temp_sbjID %in% chunks_sbjIDs,];
summary(chunks_2M$hits); # mean = 0.29
summary(chunks_2M$rejs); # mean = 0.13
summary(chunks_2M$misses); # mean = 0.14
summary(chunks_2M$alarms); # mean = 0.29



# Familiarity -------------------------------------------------------------
data_all_familiarity <- read.csv("familiarity_preprocessed_clean.csv",header=T,sep=",");
data_all_familiarity <- subset(data_all_familiarity, select = -c(X)) # remove redundant column added by Pavlovia
data_familiarity <- data_all_familiarity[data_all_familiarity$sbj_ID %in% participants,]; # n = 196 participants
data_familiarity <- data_familiarity[!data_familiarity$sbj_ID %in% c('615b41767003d4ece749ed9d', '5e8b66490d48450346bf2755','615b042301e3a24311563ee4'),] # same participants excluded as for testing

familiarity_missing <- data_familiarity[data_familiarity$sbj_ID=='6156b68cc77b48d6693b361c',];
# this participant only has 27 datapoints instead of 28 somehow

# looking at data from participant 5aa787c66219a30001c765f8
temp2 <- data_familiarity[data_familiarity$sbj_ID=='5aa787c66219a30001c765f8',];
summary(temp2);

# make some variables factors
data_familiarity$sbj_ID <- as.factor(data_familiarity$sbj_ID);
data_familiarity$task <- as.factor(data_familiarity$task);
data_familiarity$correct <- as.logical(data_familiarity$correct);
data_familiarity$target <- as.factor(data_familiarity$target);
data_familiarity$confound <- as.factor(data_familiarity$confound);

# familiarity accuracy boxplot
data_familiarity_means <- aggregate(data_familiarity$correct, list(data_familiarity$sbj_ID), FUN=mean);
colnames(data_familiarity_means)[colnames(data_familiarity_means)=="Group.1"]="sbj_ID";
boxplot(data_familiarity_means$x, ylab = "Familiarity score");
abline(h=0.5, lty=5);
summary(data_familiarity_means$x);
# min:0.29 Q1:0.50 med:0.57 mean:0.57 Q3:0.64 max:0.86
hist(data_familiarity_means$x); # normally distributed
t.test(data_familiarity_means$x, mu=0.50);
# t = 9.16, p < 2.2e-16, CI = [0.55, 0.58]
# significantly above chance

# familiarity RTs
IDs <- list(data_familiarity$sbj_ID);
IDs <- sapply(IDs, unique);
plot(density(data_familiarity$rt[data_familiarity$sbj_ID==IDs[1]]),xlim=c(0,4000),ylim=c(0,0.007),xlab="Familiarity RTs (ms)",main="",xaxt = "n",col=cols[1],lwd=2,yaxs="i");
axis(1, at = c(0,500,1000,1500,2000,2500,3000,3500,4000));
for (x in 2:193) {
  lines(density(data_familiarity$rt[data_familiarity$sbj_ID==IDs[x]]),col=cols[x],lwd=2)
};
data_familiarity_rt_means <- aggregate(data_familiarity$rt, list(data_familiarity$sbj_ID), FUN=mean, na.rm=TRUE);
summary(data_familiarity_rt_means);
#min:222 Q1:1275 med:1671 mean:1892 Q3:2140 max:9185
#5e577e79ce30ae13226e61ae max: 57% accuracy so good

# familiarity accuracy*RTs
cor(data_familiarity_means$x, data_familiarity_rt_means$x); # r = 0.20
plot(data_familiarity_rt_means$x, data_familiarity_means$x, xlab="Mean participant RT (in ms)", ylab="Mean participant familiarity score (in %)", pch=19, cex=2, cex.lab=1.45);

# familiarity accuracy*testing accuracy
cor(data_familiarity_means$x, data_testing_2M_means$x); # r = 0.11
cor(data_familiarity_means$x, data_testing_2M_hits_means$x); # r = 0.12
cor(data_familiarity_means$x, data_testing_2M_rejs_means$x); # r = -0.02


# BLP ---------------------------------------------------------------------
data_all_BLP <- read.csv("BLP_preprocessed.csv",header=T,sep=",");
data_all_BLP <- subset(data_all_BLP, select = -c(X)) # remove redundant column added by Pavlovia
data_BLP <- data_all_BLP[data_all_BLP$sbj_ID %in% participants,]; # n = 196 participants
data_BLP <- data_BLP[!data_BLP$sbj_ID %in% c('615b41767003d4ece749ed9d','5e8b66490d48450346bf2755','615b042301e3a24311563ee4'),] # same participants excluded as for testing
data_BLP <- subset(data_BLP, select = -c(AoAgioL1, AoAgioL2, AoAgioL3, AoAgioL4, anniInstrL1, anniInstrL2, anniInstrL3, anniInstrL4, anniPaeseL1, anniPaeseL2, anniPaeseL3, anniPaeseL4, anniFamigliaL1, anniFamigliaL2, anniFamigliaL3, anniFamigliaL4, anniLavoroL1, anniLavoroL2, anniLavoroL3, anniLavoroL4, PercAmiciL1, PercAmiciL2, PercAmiciL3, PercAmiciL4, PercFamigliaL1, PercFamigliaL2, PercFamigliaL3, PercFamigliaL4, PercLavoroL1, PercLavoroL2, PercLavoroL3, PercLavoroL4, PercStessoL1, PercStessoL2, PercStessoL3, PercStessoL4, PercCalcoliL1, PercCalcoliL2, PercCalcoliL3, PercCalcoliL4, ProfParlaL1, ProfParlaL2, ProfParlaL3, ProfParlaL4, ProfCapisceL1, ProfCapisceL2, ProfCapisceL3, ProfCapisceL4, ProfLeggeL1, ProfLeggeL2, ProfLeggeL3, ProfLeggeL4, ProfScriveL1, ProfScriveL2, ProfScriveL3, ProfScriveL4, AttMiStessoL1, AttMiStessoL2, AttMiStessoL3, AttMiStessoL4, AttCulturaL1, AttCulturaL2, AttCulturaL3, AttCulturaL4, AttLivNativoL1, AttLivNativoL2, AttLivNativoL3, AttLivNativoL4, AttMadrelinguaL1, AttMadrelinguaL2, AttMadrelinguaL3, AttMadrelinguaL4));

# standardise language responses
data_BLP[data_BLP == "polish"|data_BLP == "POLISH"] <- "Polish";
data_BLP[data_BLP == "portuguese"|data_BLP == "Portugal"] <- "Portuguese";
data_BLP[data_BLP == "italian"] <- "Italian";
data_BLP[data_BLP == "spanish"] <- "Spanish";
data_BLP[data_BLP == "greek"|data_BLP=="Greece"] <- "Greek";
data_BLP[data_BLP == "french"|data_BLP=="fRANCH"] <- "French";
data_BLP[data_BLP == "arabic"] <- "Arabic";
data_BLP[data_BLP == "ENGLISH"|data_BLP == "english"|data_BLP=="english "|data_BLP == "englis"|data_BLP == "eanglish"|data_BLP == "Enlish"] <- "English";
data_BLP[data_BLP == "xhosa"|data_BLP=="XHOSA"] <- "Xhosa";
data_BLP[data_BLP == "tshivenda"] <- "Tshivenda";
data_BLP[data_BLP == "SETSWANA"] <- "Setswana";
data_BLP[data_BLP == "zulu"] <- "Zulu";
data_BLP[data_BLP == "TSWANA"] <- "Tswana";
data_BLP[data_BLP == "sotho"] <- "Sotho";
data_BLP[data_BLP == "SHONA"] <- "Shona";
data_BLP[data_BLP == "hungarian"] <- "Hungarian";
data_BLP[data_BLP == "afrikaans"|data_BLP=="AFRIKAANS"] <- "Afrikaans";
data_BLP[data_BLP == "german"|data_BLP=="GERMAN"|data_BLP=="germany"|data_BLP=="Deustch"] <- "German";
data_BLP[data_BLP == "sweedish"] <- "Swedish";
data_BLP[data_BLP == "Deutch"] <- "Dutch"; # probably - maybe Deutsch?
data_BLP[data_BLP == "SESOTHO"] <- "Sesotho";
data_BLP[data_BLP == "RUSSIAN"|data_BLP=="russian"] <- "Russian";
data_BLP[data_BLP == "tswana"] <- "Tswana";
data_BLP[data_BLP == "SEPEDI"|data_BLP=="sepedi"] <- "Sepedi";
data_BLP[data_BLP == "XItsonga"] <- "Xitsonga";
data_BLP[data_BLP == "N/A"] <- "n/a";

# correcting some participants' demographic information - correction based off of Prolific's information
data_BLP["Age"][data_BLP["sbj_ID"] == "5aa787c66219a30001c765f8"] <- "24";
data_BLP["Gender"][data_BLP["sbj_ID"] == "5aa787c66219a30001c765f8"] <- "Man";
data_BLP["Gender"][data_BLP["sbj_ID"] == "5bcd11401662020001fe82c1"] <- "Man";
data_BLP["Gender"][data_BLP["sbj_ID"] == "5e3ff59bf2160b23942ada93"] <- "Man";
data_BLP["Age"][data_BLP["sbj_ID"] == "5e577e79ce30ae13226e61ae"] <- "24";
data_BLP["Age"][data_BLP["sbj_ID"] == "5e8c57d9b4483e012006e7aa"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "5ecbb4c00bc62403dae2df59"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "5ee942381a22491bbb7170f8"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "5f219602670e5a0af2cf5237"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "5f47e34858dd331165bf9f00"] <- "21";
data_BLP["Gender"][data_BLP["sbj_ID"] == "5f5a713d37f71112463ab4d9"] <- "Woman";
data_BLP["Age"][data_BLP["sbj_ID"] == "5f99cee5a2a7d109a1624e10"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "5fa4725a186c050edc3bcc20"] <- "23";
data_BLP["Age"][data_BLP["sbj_ID"] == "5fc2d2d79da439201ab6addc"] <- "24";
data_BLP["Age"][data_BLP["sbj_ID"] == "5fc44d83862e3e79b02e0438"] <- "24";
data_BLP["Age"][data_BLP["sbj_ID"] == "5fd9c5c67fa7c74ec42bb318"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "6065d7d47409810344f7e6bb"] <- "24";
data_BLP["Age"][data_BLP["sbj_ID"] == "60883a7e91c0be66dbb96fc8"] <- "23";
data_BLP["Age"][data_BLP["sbj_ID"] == "608c2e566d92c2aa3543e2d2"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "60e3b18d3d4205b4c52ada56"] <- "24";
data_BLP["Gender"][data_BLP["sbj_ID"] == "60e9ea97d19e613e60a994da"] <- "Man";
data_BLP["Age"][data_BLP["sbj_ID"] == "611eafa6011b0423f7d7230f"] <- "20";
data_BLP["Age"][data_BLP["sbj_ID"] == "612a98181f4b6d1cf01f926c"] <- "21";
data_BLP["Age"][data_BLP["sbj_ID"] == "61301fcb49db2f170cb02b93"] <- "25";
data_BLP["Age"][data_BLP["sbj_ID"] == "6156b68cc77b48d6693b361c"] <- "21";
data_BLP["Age"][data_BLP["sbj_ID"] == "616891e25a026e1f7262116c"] <- "22";
data_BLP["Gender"][data_BLP["sbj_ID"] == "616eb493bb7e4ab4fa1de8d4"] <- "Woman";
data_BLP["Age"][data_BLP["sbj_ID"] == "6171d922c871ba795b6a4827"] <- "23";

# participants having declared they speak a load of languages to Prolific:
#60ec51c51a3158a50ded8a3e
#6093cacf9a39751eedd55916
#5eaae42f19a24d05cbd6ccb4
# what to do with these? Trust what they've declared here?

# make some variables factors
data_BLP$task <- as.factor(data_BLP$task)
data_BLP$sbj_ID <- as.factor(data_BLP$sbj_ID);
data_BLP$Age <- as.numeric(data_BLP$Age);
data_BLP$Gender <- as.factor(data_BLP$Gender);
data_BLP$Education <- as.factor(data_BLP$Education);
data_BLP$L1 <- as.factor(data_BLP$L1);
data_BLP$L2 <- as.factor(data_BLP$L2);
data_BLP$L3 <- as.factor(data_BLP$L3);
data_BLP$L4 <- as.factor(data_BLP$L4);
data_BLP$otherLs <- as.factor(data_BLP$otherLs);
data_BLP$AttentionL1 <- as.factor(data_BLP$AttentionL1);
data_BLP$AttentionL2 <- as.factor(data_BLP$AttentionL2);
data_BLP$AttentionL3 <- as.factor(data_BLP$AttentionL3);
data_BLP$AttentionL4 <- as.factor(data_BLP$AttentionL4);
summary(data_BLP);
# maybe exclude 614e230ff8700b32ea648508: very high (though not perfect) scores across 4 Ls

library(toolbox);
scores_list <- combineCols(data_BLP, cols=c('L1Score','L2Score','L3Score','L4Score'),by_name=TRUE); # combine scores into 1 list
data_BLP$temp_sbjID <- c(1:193); # necessary: R doesn't like format of Prolific IDs

# multilingual balance: variance
vars <- list();
for (i in 1:193) { # calculate variance for each participant
  temp <- unlist(scores_list[i]);
  var <- var(temp,na.rm=TRUE);
  vars <- append(vars, var)
};
data_BLP$lang_var <- vars;
data_BLP$lang_var <- as.numeric(data_BLP$lang_var);
plot(data_BLP$temp_sbjID,data_BLP$lang_var,pch=19,xlab="Subject number",ylab="Language score variance",ylim=c(0,15000),cex.lab=1.5,yaxs="i");

# multilingual balance: entropy
entropies <- list();
library(DescTools);
for (i in 1:193) { # calculate entropy for each participant
  temp <- unlist(scores_list[i]);
  entropy <- Entropy(temp,na.rm=TRUE);
  entropies <- append(entropies, entropy)
};
data_BLP$lang_ent <- entropies;
data_BLP$lang_ent <- as.numeric(data_BLP$lang_ent);
plot(data_BLP$temp_sbjID,data_BLP$lang_ent,pch=19,xlab="Subject number",ylab="Language score entropy",cex.lab=1.5,ylim=c(0,2.5),yaxs="i");
# some outliers very close to 0 - the monolinguals

# multilingual balance: entropy - Gullifer & Titone (2018)
library(languageEntropy);
for (i in 1:193) { # transfrom 0-10 scores into 0-1
  temp <- unlist(scores_list[i]);
  total <- sum(temp)
  for (j in 1:4) {
    temp[j] <- temp[j]/total
  }
  scores_list[i] <- list(temp)
}
entropies_gul <- data.frame(t(sapply(scores_list,c)))
colnames(entropies_gul) <- c('L1Score','L2Score','L3Score','L4Score');
sbj_ID <- seq.int(193);
entropies_gul <- data.frame(sbj_ID, entropies_gul);
entropies_gul$L2Score[entropies_gul$L2Score==0] <- NA;
entropies_gul$L3Score[entropies_gul$L3Score==0] <- NA;
entropies_gul$L4Score[entropies_gul$L4Score==0] <- NA;
entropy_gul <- languageEntropy(entropies_gul, sbj_ID, L1Score, L2Score, L3Score, L4Score, 
                               contextName = "All");
data_BLP$lang_ent_gul <- entropy_gul$All.entropy;
cor(unlist(data_BLP$lang_ent),unlist(data_BLP$lang_ent_gul),method="pearson"); # r = 1 so same function

# corr of variance & entropy
cor(unlist(data_BLP$lang_var),unlist(data_BLP$lang_ent),method="pearson"); # r = -0.86 strongly negatively correlated

# multilingual experience: summing all language scores
data_BLP["L2Score"][is.na(data_BLP["L2Score"])] <- 0;
data_BLP["L3Score"][is.na(data_BLP["L3Score"])] <- 0;
data_BLP["L4Score"][is.na(data_BLP["L4Score"])] <- 0;
data_BLP$multi_exp <- data_BLP$L1Score + data_BLP$L2Score + data_BLP$L3Score + data_BLP$L4Score;
plot(data_BLP$temp_sbjID,data_BLP$multi_exp,pch=19,xlab="Subject number",ylab="Amount of total multilingual experience (out of 872)",ylim=c(0,872),cex.lab=1.5,yaxs="i");

# L1 - L2 score
data_BLP$L1_L2_diff <- data_BLP$L1Score - data_BLP$L2Score;
plot(data_BLP$temp_sbjID,data_BLP$L1_L2_diff,pch=19,xlab="Subject number",ylab="Score difference of L1 and L2",cex.lab=1.5,ylim=c(0,218),yaxs="i");

# vector distances
distances <- read.csv("distances_exp1.csv",header=T,sep=",");
distances <- subset(distances, select = -c(X)); # remove redundant column added by Python
names(distances) <- c('sbj_ID','vector_distance');
data_BLP <- merge(data_BLP,distances,by="sbj_ID");
cor(data_BLP$lang_ent,data_BLP$vector_distance); # r = -0.20
summary(data_BLP$vector_distance);
#min:0.63 Q1:0.90 med:0.93 mean:0.93 Q3:0.97 max:1
plot(data_BLP$temp_sbjID,data_BLP$vector_distance,pch=19,xlab="Subject number",ylab="Vector distance (multilingual balance)",cex.lab=1.5,yaxs="i");



# CLUSTERING #
complete_cases <- complete.cases(data_BLP)
data_filtered <- data_BLP[complete_cases, ]

# all with language dominance scores
png('corrPlot.png', width=1000, height=1000);
corrplot::corrplot(cor(data_filtered[,c(19:38)]), type="lower", order="original", diag=T, method="circle", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=0.5);
dev.off();

png('corrPlotClustering.png', width=1000, height=1000);
corrplot::corrplot(cor(data_filtered[,c(19:38)]), type="lower", order="hclust", diag=T, method="circle", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=0.5);
dev.off();

# all without language dominance scores
png('corrPlot2.png', width=1000, height=1000);
corrplot::corrplot(cor(data_filtered[,c(19:34)]), type="lower", order="original", diag=T, method="circle", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=0.5);
dev.off();

png('corrPlotClustering2.png', width=1000, height=1000);
corrplot::corrplot(cor(data_filtered[,c(19:34)]), type="lower", order="hclust", diag=T, method="circle", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=0.5);
dev.off();

par(mfrow=c(2,2));
hist(data_BLP$HistoryL1Score, xlim=c(0,60), breaks=seq(0,60,2));
hist(data_BLP$UseL1Score, xlim=c(0,60), breaks=seq(0,60,2));
hist(data_BLP$HistoryL2Score, xlim=c(0,60), breaks=seq(0,60,2));
hist(data_BLP$UseL2Score, xlim=c(0,60), breaks=seq(0,60,2));
par(mfrow=c(1,1));

Hmisc::varclus(data_BLP[,19:38]); # Error: x matrix must be numeric

# all participants
#with language dominance scores
pca_varimax <- psych::principal(data_BLP[,19:38], nfactors=16, rotate='varimax');
data_BLP <- cbind(data_BLP, pca_varimax$scores[,c('RC12','RC1','RC2', 'RC7','RC3','RC6')]);
names(data_BLP)[116:121] <- c('RC12_L3','RC1_L4','RC2_use_L1vsL2','RC7_hist_L2','RC3_prof_L2','RC6_use_L4');

#without language dominance scores
pca_varimax2 <- psych::principal(data_BLP[,19:34], nfactors=16, rotate='varimax');
data_BLP <- cbind(data_BLP, pca_varimax2$scores[,c('RC1','RC9','RC2','RC6')]);
names(data_BLP)[117:120] <- c('RC1_L3','RC9_L4','RC2_use_L1vsL2','RC6_use_L4');

complete_cases <- complete.cases(data_BLP)
data_filtered <- data_BLP[complete_cases, ]

png('corrPlot3.png', width=1000, height=1000);
corrplot::corrplot(cor(data_filtered[,c(19:34,115:119)]), type="lower", order="original", diag=T, method="circle", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=0.5);
dev.off();

png('corrPlotClustering3.png', width=1000, height=1000);
corrplot::corrplot(cor(data_filtered[,c(19:34,115:119)]), type="lower", order="hclust", diag=T, method="circle", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=0.5);
dev.off();

# code from Davide that doesn't work
source("C:/Users/annal/OneDrive/Documents/Me/SISSA/BASL/BASL analysis/FunnyPeopleFunction_RodriguezLaioClustering.R");
funnyPeople(scores=as.vector(ppt_in_pca_space_5), sbjId=rep(1:192,5), itemId=rep(1:5, each=30), outForMatlabFunction=F);

# adding testing scores and BLP metrics together
library(tidyverse);
data_BLP_extracted_all <- subset(data_BLP, select=c(sbj_ID,temp_sbjID,Gender,Age,HistoryL1Score,HistoryL2Score,HistoryL3Score,HistoryL4Score,UseL1Score,UseL2Score,UseL3Score,UseL4Score,ProficiencyL1Score,ProficiencyL2Score,ProficiencyL3Score,ProficiencyL4Score,AttitudeL1Score,AttitudeL2Score,AttitudeL3Score,AttitudeL4Score,L1Score,L2Score,L3Score,L4Score,lang_var,lang_ent,multi_exp,L1_L2_diff,vector_distance));
data_BLP_testing_all <- list(data_testing_2M_means,data_testing_2M_hits_means,data_testing_2M_rejs_means,data_BLP_extracted_all) %>% reduce(inner_join, by='temp_sbjID');

# corr of variance & accuracy
cor(data_BLP_testing_all$dprime,data_BLP_testing_all$lang_var); # r = -0.02

cor(data_BLP_testing_all$x_2, data_BLP_testing_all$lang_var); # r = -0.02
plot(data_BLP$lang_var, data_testing_2M_means$x, xlab="Language score variance", ylab="Testing accuracy (in %)", pch=19);

cor(data_BLP_testing_all$x_2_hits, data_BLP_testing_all$lang_var); # r = -0.02
plot(data_BLP$lang_var, data_testing_2M_hits_means$x, xlab="Language score variance", ylab="Testing hit accuracy (in %)", pch=19);

cor(data_BLP_testing_all$x_2_rejs, data_BLP_testing_all$lang_var); # r = 0.01
plot(data_BLP$lang_var, data_testing_2M_rejs_means$x, xlab="Language score variance", ylab="Testing rejection accuracy (in %)", pch=19);

# corr of entropy & accuracy
cor(data_BLP_testing_all$dprime,data_BLP_testing_all$lang_ent); # r = 0.01

cor(data_BLP_testing_all$x_2, data_BLP_testing_all$lang_ent); # r = 0.01
plot(data_BLP$lang_ent, data_testing_2M_means$x, xlab="Language score entropy", ylab="Testing accuracy (in %)", cex.lab=1.5,pch=19);

cor(data_BLP_testing_all$x_2_hits, data_BLP_testing_all$lang_ent); # r = 0.04
plot(data_BLP$lang_ent, data_testing_2M_hits_means$x, xlab="Language score entropy", ylab="Testing hit accuracy (in %)", cex.lab=1.5,pch=19);

cor(data_BLP_testing_all$x_2_rejs, data_BLP_testing_all$lang_ent); # r = -0.03
plot(data_BLP$lang_ent, data_testing_2M_rejs_means$x, xlab="Language score entropy", ylab="Testing rejection accuracy (in %)", cex.lab=1.5,pch=19);

# corr of multilingual experience & accuracy
cor(data_BLP_testing_all$dprime,data_BLP_testing_all$multi_exp); # r = 0.08

cor(data_BLP_testing_all$x_2, data_BLP_testing_all$multi_exp); # r = 0.08
plot(data_BLP$multi_exp, data_testing_2M_means$x, xlab="Language score entropy", ylab="Testing accuracy (in %)", cex.lab=1.5,pch=19);

cor(data_BLP_testing_all$x_2_hits, data_BLP_testing_all$multi_exp); # r = 0.08
plot(data_BLP$multi_exp, data_testing_2M_hits_means$x, xlab="Language score entropy", ylab="Testing hit accuracy (in %)", cex.lab=1.5,pch=19);

cor(data_BLP_testing_all$x_2_rejs, data_BLP_testing_all$multi_exp); # r = -0.01
plot(data_BLP$multi_exp, data_testing_2M_rejs_means$x, xlab="Language score entropy", ylab="Testing rejection accuracy (in %)", cex.lab=1.5,pch=19);

# corr of L1-L2 score & accuracy
cor(data_BLP_testing_all$dprime,data_BLP_testing_all$L1_L2_diff); # r = 0.02

cor(data_BLP_testing_all$x_2, data_BLP_testing_all$L1_L2_diff); # r = 0.01
plot(data_BLP$L1_L2_diff, data_testing_2M_means$x, xlab="Language score entropy", ylab="Testing accuracy (in %)", cex.lab=1.5,pch=19);

cor(data_BLP_testing_all$x_2_hits, data_BLP_testing_all$L1_L2_diff); # r = 0.01
plot(data_BLP$L1_L2_diff, data_testing_2M_hits_means$x, xlab="Language score entropy", ylab="Testing hit accuracy (in %)", cex.lab=1.5,pch=19);

cor(data_BLP_testing_all$x_2_rejs, data_BLP_testing_all$L1_L2_diff); # r = 0.01
plot(data_BLP$L1_L2_diff, data_testing_2M_rejs_means$x, xlab="Language score entropy", ylab="Testing rejection accuracy (in %)", cex.lab=1.5,pch=19);

# corr of vector distance score & accuracy
cor(data_BLP_testing_all$dprime,data_BLP_testing_all$vector_distance); # r = 0.03

cor(data_BLP_testing_all$x_2, data_BLP_testing_all$vector_distance); # r = 0.03
plot(data_BLP$L1_L2_diff, data_testing_2M_means$x, xlab="Language score entropy", ylab="Testing accuracy (in %)", cex.lab=1.5,pch=19);

cor(data_BLP_testing_all$x_2_hits, data_BLP_testing_all$vector_distance); # r = 0.05
plot(data_BLP$L1_L2_diff, data_testing_2M_hits_means$x, xlab="Language score entropy", ylab="Testing hit accuracy (in %)", cex.lab=1.5,pch=19);

cor(data_BLP_testing_all$x_2_rejs, data_BLP_testing_all$vector_distance); # r = -0.02
plot(data_BLP$L1_L2_diff, data_testing_2M_rejs_means$x, xlab="Language score entropy", ylab="Testing rejection accuracy (in %)", cex.lab=1.5,pch=19);

# dprimes - 2M
data_BLP_testing_dprimes2M <- list(dprimes2M,data_BLP_extracted_all) %>% reduce(inner_join, by='sbj_ID');
cor(data_BLP_testing_dprimes2M$dprime,data_BLP_testing_dprimes$RC1_L3);
cor(data_BLP_testing_dprimes2M$dprime,data_BLP_testing_dprimes$RC2_use_L1vsL2);
cor(data_BLP_testing_dprimes2M$dprime,data_BLP_testing_dprimes$RC6_use_L4);
cor(data_BLP_testing_dprimes2M$dprime,data_BLP_testing_dprimes$RC9_L4);
######################################
# also c

# dprimes - all
data_BLP_testing_dprimes <- list(dprimes,data_BLP_extracted_all) %>% reduce(inner_join, by='sbj_ID');
cor(data_BLP_testing_dprimes$dprime,data_BLP_testing_dprimes$RC1_L3);
cor(data_BLP_testing_dprimes$dprime,data_BLP_testing_dprimes$RC2_use_L1vsL2);
cor(data_BLP_testing_dprimes$dprime,data_BLP_testing_dprimes$RC6_use_L4);
cor(data_BLP_testing_dprimes$dprime,data_BLP_testing_dprimes$RC9_L4);
summary(data_BLP_testing_all);

# correlation plot of testing scores and BLP metrics
png('corrPlot3_all.png', width=1500, height=1500);
corrplot::corrplot(cor(data_BLP_testing_all[,c(2:30)]), type="lower", order="original", diag=T, method="circle", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=0.5);
dev.off();

# 1M & 2M clustering
data_testing_1M2M_means <- merge(data_testing_1M_means,data_testing_2M_means,by.x='sbj_ID',by.y='sbj_ID');
data_BLP_testing_1M2M_means <- merge(data_testing_1M2M_means, data_BLP_extracted_all[,c('sbj_ID','lang_ent','multi_exp','L1_L2_diff','RC1_L3','RC9_L4','RC2_use_L1vsL2','RC6_use_L4')], by.x='sbj_ID',by.y='sbj_ID', all.x=T);
png('corrPlot_1M2Mmeans.png', width=1000, height=1000);
corrplot::corrplot(cor(data_BLP_testing_1M2M_means[,c(2:10)]), type="lower", order="original", diag=T, method="circle", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=0.5);
dev.off();

png('corrPlotClustering_1M2Mmeans.png', width=1000, height=1000);
corrplot::corrplot(cor(data_BLP_testing_1M2M_means[,c(2:10)]), type="lower", order="hclust", diag=T, method="circle", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=0.5);
dev.off();
# some small correlations of x_1 (1M accuracy) with BLP variables

data_testing_1M2M_yes <- merge(data_testing_1M_yes,data_testing_2M_yes,by.x='sbj_ID',by.y='sbj_ID');
data_BLP_testing_1M2M_yes <- merge(data_testing_1M2M_yes, data_BLP_extracted_all[,c('sbj_ID','lang_ent','multi_exp','L1_L2_diff','RC1_L3','RC9_L4','RC2_use_L1vsL2','RC6_use_L4')], by.x='sbj_ID',by.y='sbj_ID', all.x=T);
png('corrPlot_1M2Myes.png', width=1000, height=1000);
corrplot::corrplot(cor(data_BLP_testing_1M2M_yes[,c(2:10)]), type="lower", order="original", diag=T, method="circle", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=0.5);
dev.off();

png('corrPlotClustering_1M2Myes.png', width=1000, height=1000);
corrplot::corrplot(cor(data_BLP_testing_1M2M_yes[,c(2:10)]), type="lower", order="hclust", diag=T, method="circle", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=0.5);
dev.off();
# r=0.61 between x_1 and x_2: those who respond "yes" more in 1M condition also
#respond "yes" more in 2M condition.

# calculating exact correlations of interesting correlations found in corrplots
cor(data_BLP_testing_all$HistoryL2Score, data_BLP_testing_all$x_2_hits); # r = 0.20
cor(data_BLP_testing_all$HistoryL3Score, data_BLP_testing_all$x_2_hits); # r = 0.19
cor(data_BLP_testing_all$UseL4Score, data_BLP_testing_all$x_2_rejs); # r = 0.19
cor(data_BLP_testing_all$L2Score, data_BLP_testing_all$x_2_hits); # r = 0.19
cor(data_BLP_testing_all$L2Score, data_BLP_testing_all$x_2_rejs); # r = -0.19
cor(data_BLP_testing_all$RC1_L3, data_BLP_testing_all$x_2);
cor(data_BLP_testing_all$RC2_use_L1vsL2, data_BLP_testing_all$x_2);
cor(data_BLP_testing_all$RC6_use_L4, data_BLP_testing_all$x_2);
cor.test(data_BLP_testing_all$RC9_L4, data_BLP_testing_all$x_2);


# gender difference
data_BLP_testing_gender <- list(data_testing_2M_means,subset(data_BLP, select=c(sbj_ID,Gender))) %>% reduce(inner_join, by='sbj_ID');
boxplot(data_BLP_testing_gender$x_2~data_BLP_testing_gender$Gender, ylim=c(0,1), ylab = "Accuracy score - 2M",xlab="Gender");
abline(h=0.5, lty=5);


# familiarity correlations
data_BLP_familiaritymeans <- merge(data_familiarity_means, data_BLP_extracted_all[,c('sbj_ID','lang_ent','multi_exp','L1_L2_diff','RC1_L3','RC9_L4','RC2_use_L1vsL2','RC6_use_L4','group')], by.x='sbj_ID',by.y='sbj_ID', all.x=T);
png('corrPlot_familiarity.png', width=1000, height=1000);
corrplot::corrplot(cor(data_BLP_familiaritymeans[,c(2:9)]), type="lower", order="original", diag=T, method="circle", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=0.5);
dev.off();

png('corrPlotClustering_familiarity.png', width=1000, height=1000);
corrplot::corrplot(cor(data_BLP_familiaritymeans[,c(2:9)]), type="lower", order="hclust", diag=T, method="circle", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=0.5);
dev.off();
# mean familiarity accuracy not correlated with any BLP variables


################
# LINEAR MODEL #
################
library(lme4);
library(emmeans)

# TESTING #
data_testing_lm <- merge(data_testing, data_BLP[,c('temp_sbjID','sbj_ID','Gender','Age','L2Score','lang_ent','multi_exp','L1_L2_diff','vector_distance','RC1_L3','RC9_L4','RC2_use_L1vsL2','RC6_use_L4')], by.x='sbj_ID',by.y='sbj_ID', all.x=T);

#all testing conditions - 'yes' responses
lm_TestingConditions <- glmer(observed ~ scale(trialn) + testing_condition + (1+testing_condition|sbj_ID), data=subset(data_testing_lm, rt>300 & rt<3000), family='binomial');
summary(lm_TestingConditions); # all conditions sig
emmeans(lm_TestingConditions, pairwise ~ testing_condition, adjust = "tukey");
# 0M-1M: estimate=0.275, p<0.001
# 0M-2M: estimate=0.675, p<0.001
# 1M-2M: estimate=0.400, p<0.001
lm_Gender <- glmer(observed ~ scale(trialn) + testing_condition*Gender + (1+testing_condition|sbj_ID), data=subset(data_testing_lm, rt>300 & rt<3000), family='binomial');
summary(lm_Gender); # Gender non sig as main effect (p=0.83 for O,p=0.27 for F); 1M:O p=0.10; 2M:O p=0.09; 1M:F p=0.83; 2M:F p=0.52
lm_Age <- glmer(observed ~ scale(trialn) + testing_condition*scale(Age) + (1+testing_condition|sbj_ID), data=subset(data_testing_lm, rt>300 & rt<3000), family='binomial');
summary(lm_Age); # Age sig as main effect (p=0.03); 1M:Age p=0.054; 2M:Age p=0.006
lm_RC1 <- glmer(observed ~ scale(trialn) + testing_condition*RC1_L3 + (1+testing_condition|sbj_ID), data=subset(data_testing_lm, rt>300 & rt<3000), family='binomial');
summary(lm_RC1); # RC1 non sig as main effect (p=0.17); 1M:RC1 p=0.37; 2M:RC1 p=0.36
lm_RC9 <- glmer(observed ~ scale(trialn) + testing_condition*RC9_L4 + (1+testing_condition|sbj_ID), data=subset(data_testing_lm, rt>300 & rt<3000), family='binomial');
summary(lm_RC9); # RC9 non sig as main effect (p=0.19); 1M:RC9 p=0.45; 2M:RC9 p=0.54
lm_RC2 <- glmer(observed ~ scale(trialn) + testing_condition*RC2_use_L1vsL2 + (1+testing_condition|sbj_ID), data=subset(data_testing_lm, rt>300 & rt<3000), family='binomial');
summary(lm_RC2); # RC2 non sig as main effect (p=0.22); 1M:RC2 p=0.56; 2M:RC2 p=0.66
lm_RC6 <- glmer(observed ~ scale(trialn) + testing_condition*RC6_use_L4 + (1+testing_condition|sbj_ID), data=subset(data_testing_lm, rt>300 & rt<3000), family='binomial');
summary(lm_RC6); # RC9 non sig as main effect (p=0.11); 1M:RC6 p=0.59; 2M:RC6 p=0.52
lm_ent <- glmer(observed ~ scale(trialn) + testing_condition*lang_ent + (1+testing_condition|sbj_ID), data=subset(data_testing_lm, rt>300 & rt<3000), family='binomial');
summary(lm_ent); # lang_ent non sig (p=0.67); 1M:ent p=0.26; 2M:ent p=0.23
lm_multiexp <- glmer(observed ~ scale(trialn) + testing_condition*scale(multi_exp) + (1|sbj_ID), data=subset(data_testing_lm, rt>300 & rt<3000), family='binomial');
summary(lm_multiexp); # multi_exp non-sig (p=0.42); 1M:multiexp p=0.21; 2M:multiexp p=0.19
lm_L1L2diff <- glmer(observed ~ scale(trialn) + testing_condition*scale(L1_L2_diff) + (1+testing_condition|sbj_ID), data=subset(data_testing_lm, rt>300 & rt<3000), family='binomial');
summary(lm_L1L2diff); # L1_L2_diff non sig (p=0.62); 1M:L1_L2_diff (p=0.02); 2M:L1_L2_diff (p=0.03)
# 1M:scale(L1L2diff) - estimate = -0.09 -> bigger L1L2diff gives smaller scores
# 2M:scale(L1L2diff) - estimate = -0.11 -> bigger L1L2diff gives smaller scores
lm_vdist <- glmer(observed ~ scale(trialn) + testing_condition*vector_distance + (1+testing_condition|sbj_ID), data=subset(data_testing_lm, rt>300 & rt<3000,L2Score>0), family='binomial');
summary(lm_vdist); # w/ monos: vdist non sig (p=0.23); 1M:vdist sig (p=0.0.07); 2M:vdist sig (p=0.03)
# w/out monos: vdist non sig (p=0.23); 1M:vdist sig (p=0.007); 2M:vdist sig (0.03)

#2M - accuracy
data_testing_lm_2M <- subset(data_testing_lm[data_testing$testing_condition=='2M',]);
lm_2M_Gender <- glmer(observed ~ scale(trialn) + expected*Gender + (1+expected|sbj_ID), data=data_testing_lm_2M, family='binomial');
summary(lm_2M_Gender); # Gender non sig (p=0.13 for O, p=0.15 for F); exp:O p=0.054; exp:F 0.54
lm_2M_Age <- glmer(observed ~ scale(trialn) + expected*scale(Age) + (1+expected|sbj_ID), data=data_testing_lm_2M, family='binomial');
summary(lm_2M_Age); # Age non sig (p=0.62), also for interaction (p=0.16)
lm_2M_RC1 <- glmer(observed ~ scale(trialn) + expected*RC1_L3 + (1+expected|sbj_ID), data=data_testing_lm_2M, family='binomial');
summary(lm_2M_RC1); # RC1 non sig (p=0.58), also for interaction (p=0.75)
lm_2M_RC9 <- glmer(observed ~ scale(trialn) + expected*RC9_L4 + (1+expected|sbj_ID), data=data_testing_lm_2M, family='binomial');
summary(lm_2M_RC9); # RC9 non sig (p=0.91), also for interaction (p=0.16)
lm_2M_RC2 <- glmer(observed ~ scale(trialn) + expected*RC2_use_L1vsL2 + (1+expected|sbj_ID), data=data_testing_lm_2M, family='binomial');
summary(lm_2M_RC2); # RC2 non sig (p=0.15), also for interaction (p=0.62)
lm_2M_RC6 <- glmer(observed ~ scale(trialn) + expected*RC6_use_L4 + (1+expected|sbj_ID), data=data_testing_lm_2M, family='binomial');
summary(lm_2M_RC6); # RC6 non sig (p=0.24), also for interaction (p=0.39)
lm_2M_ent <- glmer(observed ~ scale(trialn) + expected*lang_ent + (1+expected|sbj_ID), data=data_testing_lm_2M, family='binomial');
summary(lm_2M_ent); # lang_ent non sig (p=0.14), also for interaction (p=0.11)
lm_2M_multiexp <- glmer(observed ~ scale(trialn) + expected*scale(multi_exp) + (1+expected|sbj_ID), data=data_testing_lm_2M, family='binomial');
summary(lm_2M_multiexp); # multi_exp sig (p=0.04), marginally sig for interaction (p=0.08)
lm_2M_L1L2diff <- glmer(observed ~ scale(trialn) + expected*scale(L1_L2_diff) + (1+expected|sbj_ID), data=data_testing_lm_2M, family='binomial');
summary(lm_2M_L1L2diff); # L1_L2_diff sig (p=0.03), interaction non sig (p=0.26)
lm_2M_vdist <- glmer(observed ~ scale(trialn) + expected*vector_distance + (1+expected|sbj_ID), data=data_testing_lm_2M[data_testing_lm_2M$L2Score>0,], family='binomial');
summary(lm_2M_vdist); # w/ monos: vdist non sig (p=0.57); expected:vdist marg. sig (p=0.097)
# w/out monos: vdist non sig (p=0.58); expected:vdist marg. sig (p=0.08)

# FAMILIARITY #
#data_BLP_familiarity <- merge(data_familiarity, data_BLP_extracted_all[,c('sbj_ID','Gender','Age','L2Score','lang_ent','vector_distance','multi_exp','L1_L2_diff','RC1_L3','RC9_L4','RC2_use_L1vsL2','RC6_use_L4')], by.x='sbj_ID',by.y='sbj_ID', all.x=T);
data_BLP_familiarity <- merge(data_familiarity, data_BLP_extracted_all, by="sbj_ID",all.x=T);
data_BLP_familiarity <- merge(data_BLP_familiarity, subset(data_BLP,select=c('RC1_L3','RC9_L4','RC2_use_L1vsL2','RC6_use_L4')),by="sbj_ID",all.x=T);
lm_fam_Gender <- glmer(correct ~ scale(trialn) + Gender + (1|sbj_ID), data=data_BLP_familiarity, family='binomial');
summary(lm_fam_Gender); # Gender(Other) marginally sig (p=0.06); Woman non sig (p=0.82)
lm_fam_Age <- glmer(correct ~ scale(trialn) + scale(Age) + (1|sbj_ID), data=data_BLP_familiarity, family='binomial');
summary(lm_fam_Gender); # Age marginally sig (p=0.06)
lm_fam_RC1 <- glmer(correct ~ scale(trialn) + RC1_L3 + (1|sbj_ID), data=data_BLP_familiarity, family='binomial');
summary(lm_fam_RC1); # RC1_L3 non sig (p=0.34)
lm_fam_RC9 <- glmer(correct ~ scale(trialn) + RC9_L4 + (1|sbj_ID), data=data_BLP_familiarity, family='binomial');
summary(lm_fam_RC9); # RC9_L4 non sig (p=0.51)
lm_fam_RC2 <- glmer(correct ~ scale(trialn) + RC2_use_L1vsL2 + (1|sbj_ID), data=data_BLP_familiarity, family='binomial');
summary(lm_fam_RC2); # RC2_use_L1vsL2 non sig (p=0.52)
lm_fam_RC6 <- glmer(correct ~ scale(trialn) + RC6_use_L4 + (1|sbj_ID), data=data_BLP_familiarity, family='binomial');
summary(lm_fam_RC6); # RC6_use_L4 marginally non sig (p=0.06)
lm_fam_ent <- glmer(correct ~ scale(trialn) + lang_ent + (1|sbj_ID), data=data_BLP_familiarity, family='binomial');
summary(lm_fam_ent); # lang_ent non sig (p=0.72)
lm_fam_multiexp <- glmer(correct ~ scale(trialn) + scale(multi_exp) + (1|sbj_ID), data=data_BLP_familiarity, family='binomial');
summary(lm_fam_multiexp); # multi_exp non sig (p=0.63)
lm_fam_L1L2diff <- glmer(correct ~ scale(trialn) + scale(L1_L2_diff) + (1|sbj_ID), data=data_BLP_familiarity, family='binomial');
summary(lm_fam_L1L2diff); # L1_L2_diff non sig (p=0.40)
lm_fam_vdist <- glmer(correct ~ scale(trialn) + vector_distance + (1|sbj_ID), data=data_BLP_familiarity[data_BLP_familiarity$L2Score>0,], family='binomial');
summary(lm_fam_vdist); # w/ monos: vdist non sig (p=0.46)
# w/out monos: vdist non sig (p=0.53)


# exploration of main effects & directionality of interactions #
#age
data_BLP_testing_0M_yes <- merge(data_testing_0M_yes, subset(data_BLP,select=c('sbj_ID','Age')), by.x='sbj_ID',by.y='sbj_ID', all.x=T);
summary(data_BLP_testing_0M_yes$x_0);
#min:12.5 Q1:40 med:50 mean:49 Q3:60 max:100
data_BLP_testing_1M_yes <- merge(data_testing_1M_yes, subset(data_BLP,select=c('sbj_ID','Age')), by.x='sbj_ID',by.y='sbj_ID', all.x=T);
summary(data_BLP_testing_1M_yes$x_1);
#min:11 Q1:46 med:57 mean:55 Q3:62 max:100
data_BLP_testing_2M_yes <- merge(data_testing_2M_yes, subset(data_BLP,select=c('sbj_ID','Age')), by.x='sbj_ID',by.y='sbj_ID', all.x=T);
summary(data_BLP_testing_2M_yes$x_2);
#min:12 Q1:56 med:65 mean:64 Q3:74 max:100

data_BLP_testing_0M_yes_av <- aggregate(data_BLP_testing_0M_yes$x_0, by=list(data_BLP_testing_0M_yes$Age), FUN = mean);
names(data_BLP_testing_0M_yes_av) <- c('Age','mean_0M_yes');
data_BLP_testing_1M_yes_av <- aggregate(data_BLP_testing_1M_yes$x_1, by=list(data_BLP_testing_1M_yes$Age), FUN = mean);
names(data_BLP_testing_1M_yes_av) <- c('Age','mean_1M_yes');
data_BLP_testing_2M_yes_av <- aggregate(data_BLP_testing_2M_yes$x_2, by=list(data_BLP_testing_2M_yes$Age), FUN = mean);
names(data_BLP_testing_2M_yes_av) <- c('Age','mean_2M_yes');

plot(data_BLP_testing_0M_yes$Age,data_BLP_testing_0M_yes$x_0,xlab="Age",ylab="0M 'yes' responses (in %)",ylim=c(0,100),pch=19,yaxs="i");
points(data_BLP_testing_0M_yes_av$Age,data_BLP_testing_0M_yes_av$mean_0M_yes,type="b",pch=19,col='red',lwd=2);
plot(data_BLP_testing_1M_yes$Age,data_BLP_testing_1M_yes$x_1,xlab="Age",ylab="1M 'yes' responses (in %)",ylim=c(0,100),pch=19,yaxs="i");
points(data_BLP_testing_1M_yes_av$Age,data_BLP_testing_1M_yes_av$mean_1M_yes,type="b",pch=19,col='red',lwd=2);
plot(data_BLP_testing_2M_yes$Age,data_BLP_testing_2M_yes$x_2,xlab="Age",ylab="2M 'yes' responses (in %)",ylim=c(0,100),pch=19,yaxs="i");
points(data_BLP_testing_2M_yes_av$Age,data_BLP_testing_2M_yes_av$mean_2M_yes,type="b",pch=19,col='red',lwd=2);
#Not sure the effect of Age is visible in these graphs
#I think, from 0M to 2M, the lower-age score lowers and the higher-
#age score increases
#So the older you are, especially in testing conditions with more
#morphemes, the more likely you are to answer "yes"


#L1_L2_diff
data_BLP_testing_0M_L1L2_yes <- merge(data_testing_0M_yes, subset(data_BLP,select=c('sbj_ID','L1_L2_diff')), by.x='sbj_ID',by.y='sbj_ID', all.x=T);
data_BLP_testing_1M_L1L2_yes <- merge(data_testing_1M_yes, subset(data_BLP,select=c('sbj_ID','L1_L2_diff')), by.x='sbj_ID',by.y='sbj_ID', all.x=T);
data_BLP_testing_2M_L1L2_yes <- merge(data_testing_2M_yes, subset(data_BLP,select=c('sbj_ID','L1_L2_diff')), by.x='sbj_ID',by.y='sbj_ID', all.x=T);

plot(data_BLP_testing_0M_L1L2_yes$L1_L2_diff,data_BLP_testing_0M_L1L2_yes$x_0,xlab="L1-L2 difference",ylab="0M 'yes' responses (in %)",ylim=c(0,100),pch=19,yaxs="i");
abline(lm(data_BLP_testing_0M_L1L2_yes$x_0~data_BLP_testing_0M_L1L2_yes$L1_L2_diff), col = "red",lwd=2);
plot(data_BLP_testing_1M_L1L2_yes$L1_L2_diff,data_BLP_testing_1M_L1L2_yes$x_1,xlab="L1-L2 difference",ylab="1M 'yes' responses (in %)",ylim=c(0,100),pch=19,yaxs="i");
abline(lm(data_BLP_testing_1M_L1L2_yes$x_1~data_BLP_testing_1M_L1L2_yes$L1_L2_diff), col = "red",lwd=2);
plot(data_BLP_testing_2M_L1L2_yes$L1_L2_diff,data_BLP_testing_2M_L1L2_yes$x_2,xlab="L1-L2 difference",ylab="2M 'yes' responses (in %)",ylim=c(0,100),pch=19,yaxs="i");
abline(lm(data_BLP_testing_2M_L1L2_yes$x_2~data_BLP_testing_2M_L1L2_yes$L1_L2_diff), col = "red",lwd=2);
#So in 1M and even more in 2M, a bigger difference between the L1
#and L2 score means that participants respond "yes" to items less.
#With a bilingual perspective, the more balanced they are, the more
#likely they are to say "yes" to 1M and 2M items.

cols3 <- paletteer_d("MetBrewer::Homer2");

library(effects);
par(mar=c(5,5,2,2));

L1_L2_diff_values <- c(0,quantile(data_testing_lm$L1_L2_diff, seq(.25,.75,.25)));
L1_L2_diff_predictions <- data.frame(Effect(mod=lm_L1L2diff, focal.predictors=c('testing_condition','L1_L2_diff'), xlevels=list(L1_L2_diff=L1_L2_diff_values)));
L1_L2_diff_predictions <- na.omit(L1_L2_diff_predictions)

# plot 1
with(subset(L1_L2_diff_predictions, testing_condition=='0M'),
     plot(L1_L2_diff, fit, type='b', lwd=2, ylim=c(0.4,0.8),col='black',xlab='Amount of imbalance between top 2 languages',ylab='Proportion of "yes" responses',family="Montserrat",cex.lab=2,cex.axis=1.75));
with(subset(L1_L2_diff_predictions, testing_condition=='0M'),
     polygon(c(L1_L2_diff, L1_L2_diff[4:1]), c(upper,lower[4:1]), col=rgb(t(col2rgb(cols3[6])/255),alpha=0.5)));
with(subset(L1_L2_diff_predictions, testing_condition=='1M'),
     lines(L1_L2_diff, fit, type='b', lwd=2,col='black'));
with(subset(L1_L2_diff_predictions, testing_condition=='1M'),
     polygon(c(L1_L2_diff, L1_L2_diff[4:1]), c(upper,lower[4:1]), col=rgb(t(col2rgb(cols3[5])/255),alpha=0.5)));
with(subset(L1_L2_diff_predictions, testing_condition=='2M'),
     lines(L1_L2_diff, fit, type='b', lwd=2, col='black'));
with(subset(L1_L2_diff_predictions, testing_condition=='2M'),
     polygon(c(L1_L2_diff, L1_L2_diff[4:1]), c(upper,lower[4:1]), col=rgb(t(col2rgb(cols3[4])/255),alpha=0.5)));
legend("topright",title="Condition:",c("0M","1M","2M"),
       fill=c(cols3[6],cols3[5],cols3[4]),bty = "n",
       cex=1.5,y.intersp=0.75);

# plot 2
with(subset(L1_L2_diff_predictions, L1_L2_diff=="0"),
     plot(as.numeric(testing_condition), fit, type="b", lty=1, lwd=6, col=cols[4], ylim=c(0.45,0.75), xlab="Testing condition", ylab='Proportion of "yes" responses',cex.lab=2,xaxt="n",yaxt="n"))
#with(subset(L1_L2_diff_predictions, L1_L2_diff=="0"),
#     polygon(c(testing_condition, testing_condition[3:1]), c(upper,lower[3:1]), col=rgb(t(col2rgb(cols[4])/255),alpha=0.5)));
axis(2,at=c(0.45,0.5,0.6,0.7),cex.axis=2)
axis(1,at=c(1,2,3),labels=c("0M","1M","2M"),cex.axis=2)
abline(h=0.5, lty=5, lwd=4);
with(subset(L1_L2_diff_predictions, L1_L2_diff=="50.95"),
     lines(as.numeric(testing_condition), fit, type="b", lty=2, lwd=6, col=cols[3]))
#with(subset(L1_L2_diff_predictions, L1_L2_diff=="50.95"),
#     polygon(c(testing_condition, testing_condition[3:1]), c(upper,lower[3:1]), col=rgb(t(col2rgb(cols[3])/255),alpha=0.5)));
with(subset(L1_L2_diff_predictions, L1_L2_diff=="97.446"),
     lines(as.numeric(testing_condition), fit, type="b", lty=3, lwd=6, col=cols[2]))
#with(subset(L1_L2_diff_predictions, L1_L2_diff=="97.446"),
#     polygon(c(testing_condition, testing_condition[3:1]), c(upper,lower[3:1]), col=rgb(t(col2rgb(cols[2])/255),alpha=0.5)));
legend("topleft",title="Bilingual balance:",c("Balanced","Moderately balanced","Unbalanced"),
       lty=c(1,2,3),lwd=4,col=c(cols[4],cols[3],cols[2]),bty = "n",
       cex=1.5,y.intersp=0.75);

par(mar=c(5, 4, 4, 2) + 0.1) # back to default


#correlation between L1_L2_diff and age?
cor(data_BLP$Age, data_BLP$L1_L2_diff); # r=-0.01
#So age and L1_L2_diff uncorrelated: the effects they have on the 'yes' 
#responses are separate.

# check - if entropy includes just 3 languages, do we see the same effect as
#with L1_L2_diff above?
scores_list_just3 <- combineCols(data_BLP, cols=c('L1Score','L2Score','L3Score'),by_name=TRUE); # combine scores into 1 list
entropies_just3 <- list();
for (i in 1:193) { # calculate entropy for each participant
  temp <- unlist(scores_list_just3[i]);
  entropy <- Entropy(temp,na.rm=TRUE);
  entropies_just3 <- append(entropies_just3, entropy)
};
data_BLP$lang_ent_just3 <- entropies_just3;
data_BLP$lang_ent_just3 <- as.numeric(data_BLP$lang_ent_just3);
plot(data_BLP$temp_sbjID,data_BLP$lang_ent_just3,pch=19,xlab="Subject number",ylab="Language score entropy",cex.lab=1.5,ylim=c(0,2.5),yaxs="i");
# some outliers very close to 0 - the monolinguals

data_ent_lm <- merge(data_testing, data_BLP[,c('sbj_ID','lang_ent_just3')], by.x='sbj_ID',by.y='sbj_ID', all.x=T);
m26 <- glmer(observed ~ scale(trialn) + testing_condition*lang_ent_just3 + (1+testing_condition|sbj_ID), data=subset(data_ent_lm, rt>300 & rt<3000), family='binomial');
summary(m26); # lang_ent_just3 non sig (p=0.55), interaction non sig
# so this effect only visible at bilingual level, not including trilingual data


######################
# DENSITY CLUSTERING #
######################
library(viridis);
density_peak_clustering <- function(scores, 
                                    sbjId, #these are the "objects" 
                                    dimensions, #this would be the item in a psychological experiment
                                    threshold=.2
)
  
{
  #this just checks that the scores are numbers
  if (!is.numeric(scores)) stop('The score vector should be numeric');
  
  #this arranges the input data into a dataframe, in the wide format cause that's what the function 'dist', which we'll use below, needs 
  temp <- data.frame(dimension=dimensions, sbjId=sbjId, score=scores);
  tempWide <- reshape(temp, timevar="dimension", idvar="sbjId", direction="wide"); 
  
  #this method doesn't handle well missing data, so here I substitute them with the mean for that dimension
  for (j in 2:ncol(tempWide)) 
  {
    tempWide[,j][is.na(tempWide[,j])] <- rep(mean(tempWide[,j], na.rm=T), length(tempWide[,j][is.na(tempWide[,j])]));
  };
  
  #this prepares the core data frame:
  density_peaks <- data.frame(subject=tempWide$sbjId, ro=rep(0,length(tempWide$sbjId)), delta=rep(0,length(tempWide$sbjId)), cluster=rep(0,length(tempWide$sbjId)));
  
  #this computes the distance between points
  distances <- as.matrix(dist(tempWide[,2:ncol(tempWide)]));
  rownames(distances) <- tempWide$sbjId;
  colnames(distances) <- tempWide$sbjId;
  
  #this computes the density for each point, ro in R&L2014 terminology
  temp <- ifelse(distances > threshold*median(distances, na.rm=T), 0, 1); #here we take the median of the distance distribution as a reference point, but the method should be robust with respect to this arbitrary choice
  density_peaks$ro <- rowSums(temp, na.rm=T);
  
  #this computes the distance to the closest, higher-density point
  for(j in 1:nrow(density_peaks)) density_peaks$delta[j] <- min(distances[j,which(density_peaks$ro>density_peaks$ro[j])]); 
  #delta is 'Inf' by definition for the highest-density point, so we change it with max(delta)
  density_peaks$delta[density_peaks$ro==max(density_peaks$ro)] <- max(density_peaks$delta[density_peaks$delta!=Inf], na.rm=T);
  
  #plot the decision plot
  with(density_peaks, plot(jitter(ro,2), jitter(delta,2), type="n", axes=F, xlab='Number of relative neighbours (ro)', ylab='Minimal distance to higher density point (delta)'));
  axis(1);
  axis(2);
  with(density_peaks, text(jitter(ro,2), jitter(delta,2), as.character(subject)));

  #ask the user to identify the cluster centres  
  print("Pick up your cluster centres. Press ENTER when done.");
  scan(what="character") ->> centres;
  
  #assign the cluster centres their cluster ID  
  clusterCounter <- 1;
  for (j in 1:length(centres))
  {
    density_peaks$cluster[density_peaks$subject==centres[j]] <- clusterCounter;
    clusterCounter <- clusterCounter+1;
  };
  
  #assign all the other points their cluster ID  
  unassignedPoints <- which(density_peaks$cluster==0);
  unassignedPoints <- unassignedPoints[order(density_peaks$ro[unassignedPoints], decreasing=T)]; #here I order the unassigned points based on their density. This eliminates the risk that points are passed through the cluster assignment algorithm when its neighbours are still all unassigned themselves.
  for (j in unassignedPoints)
  {
    nearestHigherDensityNeighbour <- which(distances[j,] == min(distances[j,which(density_peaks$ro>density_peaks$ro[j])]));
    density_peaks[j,'cluster'] <- density_peaks[nearestHigherDensityNeighbour,'cluster'];
  }
  
  #this plots the points, color-coded by cluster, in a compressed, 2D space (via Multidimensional scaling) 
  temp <- cmdscale(distances, k=2);
  plot(temp[,1], temp[,2], bty='n', xlab='(Multidimensional scaling)', ylab='', main='', type='n');
  cluster_colors <- viridis(length(centres));
  for (j in 1:length(centres)) text(temp[density_peaks$cluster==j,1], temp[density_peaks$cluster==j,2], density_peaks$subject[density_peaks$cluster==j], col=cluster_colors[j]);
  
  # create the dataframe with delta, ro, and sbjId
  result <- data.frame(cluster = density_peaks$cluster, delta = density_peaks$delta, ro = density_peaks$ro, sbjId = density_peaks$subject)
  
  # return the result
  return(result)
};

data_BLP_clustering <- subset(data_BLP, select=c(temp_sbjID,RC1_L3,RC9_L4,RC2_use_L1vsL2,RC6_use_L4));
data_clustering <- data.frame();
sbj_ID <- as.character(data_BLP_clustering$temp_sbjID);
for (x in 1:193) {
  temp_sbj_ID = sbj_ID[x]
  RC1_L3 = data_BLP_clustering[x,2]
  RC9_L4 = data_BLP_clustering[x,3]
  RC2_use_L1vsL2 = data_BLP_clustering[x,4]
  RC6_use_L4 = data_BLP_clustering[x,5]
  temp <- data.frame('sbj_ID'=rep(temp_sbj_ID,4),
                     'scores'=c(RC1_L3,RC9_L4,RC2_use_L1vsL2,RC6_use_L4),
                     'dimensions'=c('RC1_L3','RC9_L4','RC2_use_L1vsL2','RC6_use_L4'))
  data_clustering <- rbind(data_clustering,temp)
};
summary(data_clustering);

result <- density_peak_clustering(data_clustering$scores,data_clustering$sbj_ID,data_clustering$dimensions);
# cluster centres: 40, 97, 133

# new clustering analysis based on new version of Laio clustering technique
#getting all the participant IDs together
new_cluster1 <- list('2','3','4','5','6','7','8','10','12','13','14','15','16','19','20','21','22','23','24','25','27','28','29','31','32','33','35','36','38','39','41','43','44','45','46','47','48','49','50',
                     '51','52','53','55','56','57','58','59','60','61','63','64','66','67','68','69','72','73','74','75','76','77','78','79','81','82','83','84','87','88','89','94','95','100',
                     '101','102','106','107','108','110','113','114','115','117','118','120','124','125','127','128','131','132','134','135','138','141','142','143','144','145','146','148','149','150',
                     '153','155','156','157','158','159','160','161','162','163','165','166','167','170','171','174','176','177','179','182','183','185','187','188','189','191');
new_cluster2 <- list('11','26','34','37','42','54','62','65','92','98','105','116','123','130','136','137','139','147','169','173','175','178','190');
new_cluster3 <- list('1','9','17','18','30','40','70','71','80','86','90','96','97','99','103','111','112','126','133','152','154','186','192','193');
new_cluster4 <- list('85','93','104','109','121','122','129','140','151','172','180','181');
new_cluster5 <- list('91','119','164','168','184');

#creating separate dataframes
cluster1 <- subset(data_BLP[data_BLP$temp_sbjID %in% new_cluster1,],select=c(temp_sbjID,HistoryL1Score,HistoryL2Score,HistoryL3Score,HistoryL4Score,UseL1Score,UseL2Score,UseL3Score,UseL4Score,ProficiencyL1Score,ProficiencyL2Score,ProficiencyL3Score,ProficiencyL4Score,AttitudeL1Score,AttitudeL2Score,AttitudeL3Score,AttitudeL4Score,L1Score,L2Score,L3Score,L4Score)); 
# n = 129
cluster2 <- subset(data_BLP[data_BLP$temp_sbjID %in% new_cluster2,],select=c(temp_sbjID,HistoryL1Score,HistoryL2Score,HistoryL3Score,HistoryL4Score,UseL1Score,UseL2Score,UseL3Score,UseL4Score,ProficiencyL1Score,ProficiencyL2Score,ProficiencyL3Score,ProficiencyL4Score,AttitudeL1Score,AttitudeL2Score,AttitudeL3Score,AttitudeL4Score,L1Score,L2Score,L3Score,L4Score)); 
# n = 23
cluster3 <- subset(data_BLP[data_BLP$temp_sbjID %in% new_cluster3,],select=c(temp_sbjID,HistoryL1Score,HistoryL2Score,HistoryL3Score,HistoryL4Score,UseL1Score,UseL2Score,UseL3Score,UseL4Score,ProficiencyL1Score,ProficiencyL2Score,ProficiencyL3Score,ProficiencyL4Score,AttitudeL1Score,AttitudeL2Score,AttitudeL3Score,AttitudeL4Score,L1Score,L2Score,L3Score,L4Score));
# n = 24
cluster4 <- subset(data_BLP[data_BLP$temp_sbjID %in% new_cluster4,],select=c(temp_sbjID,HistoryL1Score,HistoryL2Score,HistoryL3Score,HistoryL4Score,UseL1Score,UseL2Score,UseL3Score,UseL4Score,ProficiencyL1Score,ProficiencyL2Score,ProficiencyL3Score,ProficiencyL4Score,AttitudeL1Score,AttitudeL2Score,AttitudeL3Score,AttitudeL4Score,L1Score,L2Score,L3Score,L4Score));
# n = 12
cluster5 <- subset(data_BLP[data_BLP$temp_sbjID %in% new_cluster5,],select=c(temp_sbjID,HistoryL1Score,HistoryL2Score,HistoryL3Score,HistoryL4Score,UseL1Score,UseL2Score,UseL3Score,UseL4Score,ProficiencyL1Score,ProficiencyL2Score,ProficiencyL3Score,ProficiencyL4Score,AttitudeL1Score,AttitudeL2Score,AttitudeL3Score,AttitudeL4Score,L1Score,L2Score,L3Score,L4Score));
# n = 5

#getting average of scores to find dimension pulling clusters apart
cluster1_means <- data.frame('cluster_id'='1');
for (x in 2:21) {
  name <- colnames(cluster1)[x];
  mean <- mean(cluster1[,x]);
  cluster1_means[name] <- mean;
};

cluster2_means <- data.frame('cluster_id'='2');
for (x in 2:21) {
  name <- colnames(cluster2)[x];
  mean <- mean(cluster2[,x]);
  cluster2_means[name] <- mean;
};

cluster3_means <- data.frame('cluster_id'='3');
for (x in 2:21) {
  name <- colnames(cluster3)[x];
  mean <- mean(cluster3[,x]);
  cluster3_means[name] <- mean;
};
cluster4_means <- data.frame('cluster_id'='4');
for (x in 2:21) {
  name <- colnames(cluster4)[x];
  mean <- mean(cluster4[,x]);
  cluster4_means[name] <- mean;
};

cluster5_means <- data.frame('cluster_id'='5');
for (x in 2:21) {
  name <- colnames(cluster5)[x];
  mean <- mean(cluster5[,x]);
  cluster5_means[name] <- mean;
};

cluster_means <- rbind(cluster1_means, cluster2_means, cluster3_means, cluster4_means, cluster5_means);

# plots by dimension
#1
cols2 <- paletteer_d("ggthemes::Classic_20");
plot(cluster_means[,2],ylim=c(0,55),type="b",cex=2,lwd=2,pch=19,col=cols2[1],ylab="Score means",xlab="Cluster");
for (x in 3:17) {
  points(cluster_means[,x],type="b",cex=2,lwd=2,pch=19,col=cols2[x-1])
}
legend("right",title="Score:",c("HistL1","HistL2","HistL3","HistL4","UseL1","UseL2","UseL3","UseL4","ProfL1","ProfL2","ProfL3","ProfL4","AttL1","AttL2","AttL3","AttL4"),
       fill=c(cols2[1],cols2[2],cols2[3],cols2[4],cols2[5],cols2[6],cols2[7],cols2[8],cols2[9],cols2[10],cols2[11],cols2[12],cols2[13],cols2[14],cols2[15],cols2[16]),bty = "n",
       cex=1,y.intersp=0.5);

#2
par(mfrow=c(2,2));
plot(cluster_means[,2],ylim=c(0,55),type="b",cex=2,cex.lab=1.5,lwd=2,pch=19,col=cols2[1],ylab="Score means",xlab="Cluster");
y = 2;
for (x in 3:5) {
  points(cluster_means[,x],type="b",cex=2,lwd=2,pch=19,col=cols2[y]);
  y <- y + 1
}
legend("right",title="Score:",c("HistL1","HistL2","HistL3","HistL4"),
       fill=c(cols2[1],cols2[2],cols2[3],cols2[4]),bty = "n",
       cex=1,y.intersp=0.5);

plot(cluster_means[,6],ylim=c(0,55),type="b",cex=2,cex.lab=1.5,lwd=2,pch=19,col=cols2[1],ylab="Score means",xlab="Cluster");
y = 2;
for (x in 7:9) {
  points(cluster_means[,x],type="b",cex=2,lwd=2,pch=19,col=cols2[y]);
  y <- y + 1
}
legend("right",title="Score:",c("UseL1","UseL2","UseL3","UseL4"),
       fill=c(cols2[1],cols2[2],cols2[3],cols2[4]),bty = "n",
       cex=1,y.intersp=0.5);

plot(cluster_means[,10],ylim=c(0,55),type="b",cex=2,cex.lab=1.5,lwd=2,pch=19,col=cols2[1],ylab="Score means",xlab="Cluster");
y = 2;
for (x in 11:13) {
  points(cluster_means[,x],type="b",cex=2,lwd=2,pch=19,col=cols2[y]);
  y <- y + 1
}
legend("right",title="Score:",c("ProfL1","ProfL2","ProfL3","ProfL4"),
       fill=c(cols2[1],cols2[2],cols2[3],cols2[4]),bty = "n",
       cex=1,y.intersp=0.5);

plot(cluster_means[,14],ylim=c(0,55),type="b",cex=1.5,cex.lab=1.5,lwd=2,pch=19,col=cols2[1],ylab="Score means",xlab="Cluster");
y = 2;
for (x in 15:17) {
  points(cluster_means[,x],type="b",cex=2,lwd=2,pch=19,col=cols2[y]);
  y <- y + 1
}
legend("right",title="Score:",c("AttL1","AttL2","AttL3","AttL4"),
       fill=c(cols2[1],cols2[2],cols2[3],cols2[4]),bty = "n",
       cex=1,y.intersp=0.5);
par(mfrow=c(1,1));

# testing scores per cluster
data_BLP_extracted_all <- subset(data_BLP, select=c(temp_sbjID,sbj_ID,HistoryL1Score,HistoryL2Score,HistoryL3Score,HistoryL4Score,UseL1Score,UseL2Score,UseL3Score,UseL4Score,ProficiencyL1Score,ProficiencyL2Score,ProficiencyL3Score,ProficiencyL4Score,AttitudeL1Score,AttitudeL2Score,AttitudeL3Score,AttitudeL4Score,L1Score,L2Score,L3Score,L4Score,lang_var,lang_ent,multi_exp,L1_L2_diff,RC1_L3,RC9_L4,RC2_use_L1vsL2,RC6_use_L4));
data_BLP_extracted_all$cluster <- "1";
data_BLP_extracted_all$cluster[data_BLP_extracted_all$temp_sbjID %in% new_cluster2] <- "2";
data_BLP_extracted_all$cluster[data_BLP_extracted_all$temp_sbjID %in% new_cluster3] <- "3";
data_BLP_extracted_all$cluster[data_BLP_extracted_all$temp_sbjID %in% new_cluster4] <- "4";
data_BLP_extracted_all$cluster[data_BLP_extracted_all$temp_sbjID %in% new_cluster5] <- "5";
data_BLP_extracted_all$cluster <- as.factor(data_BLP_extracted_all$cluster);

data_BLP_testing_all <- list(data_testing_0M_means,data_testing_1M_means,data_testing_2M_means,data_BLP_extracted_all) %>% reduce(inner_join, by='sbj_ID');
summary(data_BLP_testing_all);

boxplot(data_BLP_testing_all$x_0 ~ data_BLP_testing_all$cluster,xlab='Cluster',ylab='0M Accuracy',cex.lab=1.5,ylim=c(0,1),yaxs="i");
abline(h=0.5, lty=5); # all at 50% mean, some fluctuation across groups
boxplot(data_BLP_testing_all$x_1 ~ data_BLP_testing_all$cluster,xlab='Cluster',ylab='1M Accuracy',cex.lab=1.5,ylim=c(0,1),yaxs="i");
abline(h=0.5, lty=5); # most above 50%, cluster 5 below (but cluster 5 n = 5)
boxplot(data_BLP_testing_all$x_2 ~ data_BLP_testing_all$cluster,xlab='Cluster',ylab='2M Accuracy',cex.lab=1.5,ylim=c(0,1),yaxs="i");
abline(h=0.5, lty=5); # all at 50% mean, quite even


# group boxplot - yes responses
data_BLP_testing_all_yes <- list(data_testing_2M_yes,data_BLP_extracted_all) %>% reduce(inner_join, by='sbj_ID');
data_BLP_testing_all_yes$x_2 <- data_BLP_testing_all_yes$x_2 * 2.5

boxplot(data_BLP_testing_all_yes$x_2 ~ data_BLP_testing_all_yes$cluster,xlab='Cluster',ylab='Percent of yes responses - 2M',cex.lab=1.5,ylim=c(0,100),yaxs="i");
abline(h=50, lty=5); # all at 65%, except cluster 5 (but cluster 5 n = 5)


# familiarity responses in each cluster
data_BLP_familiarity_all <- list(data_familiarity_means,data_BLP_extracted_all) %>% reduce(inner_join, by='sbj_ID');
collapsed_familiarity_all <- subset(data_BLP_familiarity_all, select=c(sbj_ID,x,cluster));
boxplot(collapsed_familiarity_all$x ~ collapsed_familiarity_all$cluster,xlab='Cluster',ylab='Familiarity accuracy',cex.lab=1.5,ylim=c(0,1),yaxs="i");
abline(h=0.5, lty=5); # all at 57% roughly
hist(collapsed_familiarity_all$x); # normally distributed


# cluster lmer
data_testing_lm$cluster <- "1";
data_testing_lm$cluster[data_testing_lm$temp_sbjID %in% new_cluster2] <- "2";
data_testing_lm$cluster[data_testing_lm$temp_sbjID %in% new_cluster3] <- "3";
data_testing_lm$cluster[data_testing_lm$temp_sbjID %in% new_cluster4] <- "4";
data_testing_lm$cluster[data_testing_lm$temp_sbjID %in% new_cluster5] <- "5";
data_testing_lm$cluster <- as.factor(data_testing_lm$cluster);

#all testing conditions - 'yes' responses
lm_clusters <- glmer(observed ~ scale(trialn) + testing_condition*cluster + (1+testing_condition|sbj_ID), data=subset(data_testing_lm, rt>300 & rt<3000), family='binomial');
summary(lm_clusters); # cluster non significant as main effect, 1M*cluster5 sig (p < 0.01), 2M*cluster5 sig (p < 0.01)
#2M accuracy
data_testing_lm_2M <- subset(data_testing_lm[data_testing$testing_condition=='2M',]);
lm_2M_clusters <- glmer(observed ~ scale(trialn) + expected*cluster + (1+expected|sbj_ID), data=data_testing_lm_2M, family='binomial');
summary(lm_2M_clusters); # cluster non sig
#familiarity
data_BLP_familiarity <- merge(data_familiarity, data_BLP_extracted_all[,c('sbj_ID','cluster','lang_ent','multi_exp','L1_L2_diff','RC1_L3','RC9_L4','RC2_use_L1vsL2','RC6_use_L4')], by.x='sbj_ID',by.y='sbj_ID', all.x=T);
lm_fam_clusters <- glmer(correct ~ scale(trialn) + cluster + (1|sbj_ID), data=data_BLP_familiarity, family='binomial');
summary(lm_fam_clusters); # cluster non sig

# examination of significant cluster5*1M interaction
data_BLP_testing_0M_cluster_yes <- merge(data_testing_0M_yes, subset(data_BLP_extracted_all,select=c('sbj_ID','cluster')), by.x='sbj_ID',by.y='sbj_ID', all.x=T);
data_BLP_testing_1M_cluster_yes <- merge(data_testing_1M_yes, subset(data_BLP_extracted_all,select=c('sbj_ID','cluster')), by.x='sbj_ID',by.y='sbj_ID', all.x=T);
data_BLP_testing_2M_cluster_yes <- merge(data_testing_2M_yes, subset(data_BLP_extracted_all,select=c('sbj_ID','cluster')), by.x='sbj_ID',by.y='sbj_ID', all.x=T);

plot(data_BLP_testing_0M_cluster_yes$cluster,data_BLP_testing_0M_cluster_yes$x_0,xlab="Cluster",ylab="0M 'yes' responses",ylim=c(0,40),pch=19);
abline(h=20,lty=5);
plot(data_BLP_testing_1M_cluster_yes$cluster,data_BLP_testing_1M_cluster_yes$x_1,xlab="Cluster",ylab="1M 'yes' responses",ylim=c(0,40),pch=19);
abline(h=20,lty=5);
plot(data_BLP_testing_2M_cluster_yes$cluster,data_BLP_testing_2M_cluster_yes$x_2,xlab="Cluster",ylab="2M 'yes' responses",ylim=c(0,40),pch=19);
abline(h=20,lty=5);

summary(data_BLP_testing_0M_cluster_yes$x_0[data_BLP_testing_0M_cluster_yes$cluster==5]);
#min=17 Q1=19 med=21 mean=22 Q3=24 max=28
summary(data_BLP_testing_1M_cluster_yes$x_1[data_BLP_testing_1M_cluster_yes$cluster==5]);
#min=10 Q1=15 med=16 mean=16 Q3=19 max=22
summary(data_BLP_testing_2M_cluster_yes$x_2[data_BLP_testing_2M_cluster_yes$cluster==5]);
#min=5 Q1=13 med=19 mean=15 Q3=19 max=21

df_list <- list(data_BLP_testing_0M_cluster_yes[data_BLP_testing_0M_cluster_yes$cluster==5,],data_BLP_testing_1M_cluster_yes[data_BLP_testing_1M_cluster_yes$cluster==5,],data_BLP_testing_2M_cluster_yes[data_BLP_testing_2M_cluster_yes$cluster==5,]);
data_BLP_testing_cluster5_yes <- df_list %>% reduce(full_join, by='sbj_ID');
plot(data_BLP_testing_cluster5_yes$x_0,type="b",lwd=2,pch=19,ylim=c(0,40),xlab="sbj_ID",ylab="Yes responses",cex.lab=1.5,yaxs="i",col=cols2[1]);
points(data_BLP_testing_cluster5_yes$x_1,type="b",lwd=2,pch=19,col=cols2[2]);
points(data_BLP_testing_cluster5_yes$x_2,type="b",lwd=2,pch=19,col=cols2[3]);
legend("bottomright",title="Condition:",c("0M","1M","2M"),
       fill=c(cols2[1],cols2[2],cols2[3]),bty = "n",
       cex=1,y.intersp=0.5);

#Cluster 5 n=5 so not reliable, but despite that, significant interaction
#Cluster 5 say 'yes' more in 0M, then 1M, then 2M: opposite from other clusters


################################
# ANALYSIS WITH JUST CLUSTER 1 #
################################
# testing
data_testing_c1 <- subset(data_testing_lm[data_testing_lm$cluster=="1",]);
data_testing_c1_0M_yes <- aggregate(data_testing_c1$observed[data_testing_c1$testing_condition=='0M'], by=list(data_testing_c1$sbj_ID[data_testing_c1$testing_condition=='0M']), FUN = function(x) sum(x == 1));
names(data_testing_c1_0M_yes) <- c("sbj_ID","x_0");
data_testing_c1_0M_yes$x_0 <- data_testing_c1_0M_yes$x_0/total_0M*100; #transform into percent
summary(data_testing_c1_0M_yes$x_0);
#FULL DATASET: min:12.5 Q1:40 med:50 mean:49.44 Q3:60 max:100
#CLUSTER 1: min:12.5 Q1:40 med:50 mean:48.47 Q3:57.5 max:100
t.test(data_testing_c1_0M_yes$x_0, mu=50);
#FULL DATASET: t=-0.53 p=0.60 CI=[47.37;51.52] -> not significantly different from 50%
#CLUSTER 1: t=-1.22 p=0.23 CI=[45.98;50.96] -> not significantly different from 50%
boxplot(data_testing_c1_0M_yes$x, ylab = "Percent of 'yes' responses",ylim=c(0,100),yaxs="i");
abline(h=50, lty=5);

# 0M scores
data_testing_c1_0M_means <- aggregate(data_testing_c1$correct[data_testing_c1$testing_condition=='0M'], list(data_testing_c1$sbj_ID[data_testing_c1$testing_condition=='0M']), FUN=mean, na.rm=TRUE);
names(data_testing_c1_0M_means) <- c("sbj_ID","x_0");
summary(data_testing_c1_0M_means$x_0);
#FULL DATASET: min:0 Q1:0.40 med:0.50 mean:0.51 Q3:0.6 max:0.88
#CLUSTER 1: min:0 Q1:0.43 med:0.50 mean:0.52 Q3:0.6 max:0.88
var(data_testing_c1_0M_means$x_0);
#FULL DATASET: var=0.02
#CLUSTER 1: var=0.02
plot(data_testing_c1_0M_means$x_0,pch=3,ylim=c(0,1),yaxs="i");
abline(h=0.5, lty=5);
#quite a wide range of scores
hist(data_testing_c1_0M_means$x_0); # normally distributed
t.test(data_testing_c1_0M_means$x_0, mu=0.5);
#FULL DATASET: t=0.53 p=0.60 CI=[0.48;0.53] -> not significantly different from 50%
#CLUSTER 1: t=1.22 p=0.23 CI=[0.49;0.54] -> not significantly different from 50%

# 1M yes responses boxplot
data_testing_c1_1M_yes <- aggregate(data_testing_c1$observed[data_testing_c1$testing_condition=='1M'], by=list(data_testing_c1$sbj_ID[data_testing_c1$testing_condition=='1M']), FUN = function(x) sum(x == 1));
names(data_testing_c1_1M_yes) <- c("sbj_ID","x_1");
data_testing_c1_1M_yes$x_1 <- data_testing_c1_1M_yes$x_1/total_1M*100; #transform into percent
summary(data_testing_c1_1M_yes$x_1);
#FULL DATASET: min:10.8 Q1:46 med:56.8 mean:55 Q3:62.2 max:100
#CLUSTER 1: min:10.8 Q1:46 med:54.01 mean:54.3 Q3:62.2 max:100
t.test(data_testing_c1_1M_yes$x_1, mu=50);
#FULL DATASET: t=4.94 p=1.70e-6 CI=[53.01;57.01] -> significantly above 50%
#CLUSTER 1: t=3.53 p=0.001 CI=[51.89;56.72] -> significantly above 50%
boxplot(data_testing_c1_1M_yes$x, ylab = "Percent of 'yes' responses",ylim=c(0,100),yaxs="i");
abline(h=50, lty=5);

# 1M scores
data_testing_c1_1M_means <- aggregate(data_testing_c1$correct[data_testing_c1$testing_condition=='1M'], list(data_testing_c1$sbj_ID[data_testing_c1$testing_condition=='1M']), FUN=mean, na.rm=TRUE);
names(data_testing_c1_1M_means) <- c("sbj_ID","x_1");
summary(data_testing_c1_1M_means$x_1);
#FULL DATASET: min:0.1 Q1:0.46 med:0.57 mean:0.55 Q3:0.62 max:1
#CLUSTER 1: min:0.11 Q1:0.46 med:0.54 mean:0.54 Q3:0.62 max:1
var(data_testing_c1_1M_means$x_1);
#FULL DATASET: var=0.02
#CLUSTER 1: var=0.02
plot(data_testing_c1_1M_means$x_1,pch=3,ylim=c(0,1),yaxs="i");
abline(h=0.5, lty=5);
#quite a wide range of scores
hist(data_testing_c1_1M_means$x_1); # normally distributed
t.test(data_testing_c1_1M_means$x_1, mu=0.5);
#FULL DATASET: t=4.94 p=1.69e-6 CI=[0.53,0.57] -> significantly above 50%
#CLUSTER 1: t=3.53 p=0.001 CI=[0.52,0.57] -> significantly above 50%

# 2M yes responses boxplot
data_testing_c1_2M_yes <- aggregate(data_testing_c1$observed[data_testing_c1$testing_condition=='2M'], by=list(data_testing_c1$sbj_ID[data_testing_c1$testing_condition=='2M']), FUN = function(x) sum(x == 1));
names(data_testing_c1_2M_yes) <- c("sbj_ID","x_2");
data_testing_c1_2M_yes$x_2 <- data_testing_c1_2M_yes$x_2/total_2M*100; #transform into percent
summary(data_testing_c1_2M_yes$x_2);
#FULL DATASET: min:11.8 Q1:55.9 med:64.7 mean:64 Q3:73.5 max:100
#CLUSTER 1: min:11.8 Q1:55.9 med:64.7 mean:63.6 Q3:73.5 max:94.12
t.test(data_testing_c1_2M_yes$x_2, mu=50);
#FULL DATASET: t=13.54 p<2.2e-16 CI=[61.98;66.06] -> significantly above 50%
#CLUSTER 1: t=11.13 p<2.2e-16 CI=[61.17;66.01] -> significantly above 50%
boxplot(data_testing_c1_2M_yes$x, ylab = "Percent of 'yes' responses",ylim=c(0,100),yaxs="i");
abline(h=50, lty=5);

# yes responses across conditions
library(tidyverse);
data_testing_c1_conditions <- list(data_testing_c1_0M_yes,data_testing_c1_1M_yes,data_testing_c1_2M_yes) %>% reduce(inner_join, by='sbj_ID');
boxplot(data_testing_c1_conditions$x_0,data_testing_c1_conditions$x_1,data_testing_c1_conditions$x_2, ylab='Percent of "yes" responses', xlab="Condition", names=c('0M','1M','2M'),ylim=c(0,100),yaxs="i");
abline(h=50, lty=5);
conditions_table_c1 <- table(data_testing_c1$testing_condition, data_testing_c1$observed);
chisq.test(conditions_table_c1);
#FULL DATASET: X-squared=308.03, df=2, p<2.2e-16
#CLUSTER 1: X-squared=220.61, df=2, p<2.2e-16

#FAMILIARITY
# familiarity accuracy boxplot
data_familiarity_c1 <- subset(data_familiarity[data_familiarity$sbj_ID %in% data_testing_c1$sbj_ID,])
data_familiarity_c1_means <- aggregate(data_familiarity_c1$correct, list(data_familiarity_c1$sbj_ID), FUN=mean);
colnames(data_familiarity_c1_means)[colnames(data_familiarity_c1_means)=="Group.1"]="sbj_ID";
boxplot(data_familiarity_c1_means$x, ylab = "Familiarity score");
abline(h=0.5, lty=5);
summary(data_familiarity_c1_means$x);
#FULL DATASET: min:0.29 Q1:0.50 med:0.57 mean:0.57 Q3:0.64 max:0.86
#CLUSTER 1: min:0.32 Q1:0.50 med:0.57 mean:0.57 Q3:0.64 max:0.86
hist(data_familiarity_c1_means$x); # normally distributed
t.test(data_familiarity_c1_means$x, mu=0.50);
#FULL DATASET: t = 9.16, p < 2.2e-16, CI = [0.55, 0.58] -> significantly above chance
#CLUSTER 1: t = 7.26, p=3.31e-11, CI = [0.55, 0.58] -> significantly above chance

# lmer
# TESTING #
data_testing_c1_lm <- subset(data_testing_lm[data_testing_lm$sbj_ID %in% data_testing_c1$sbj_ID,]);

#all testing conditions - 'yes' responses
lm_c1_TestingConditions <- glmer(observed ~ scale(trialn) + testing_condition + (1+testing_condition|sbj_ID), data=subset(data_testing_c1_lm, rt>300 & rt<3000), family='binomial');
summary(lm_c1_TestingConditions); # all conditions sig
lm_c1_Gender <- glmer(observed ~ scale(trialn) + testing_condition*Gender + (1+testing_condition|sbj_ID), data=subset(data_testing_c1_lm, rt>300 & rt<3000), family='binomial');
summary(lm_c1_Gender);
#FULL DATASET: Gender non significant as main effect and interaction
#CLUSTER 1: Gender non significant as main effect and interaction
lm_c1_Age <- glmer(observed ~ scale(trialn) + testing_condition*scale(Age) + (1+testing_condition|sbj_ID), data=subset(data_testing_c1_lm, rt>300 & rt<3000), family='binomial');
summary(lm_c1_Age);
#FULL DATASET: Age significant as main effect (p=0.03) and interaction (Age*1M p=0.05. Age*2M p=0.006)
#CLUSTER 1: Age non significant as main effect (p=0.07) and sig as interaction (Age*1M p=0.03; Age*2M p=0.001)
lm_c1_RC1 <- glmer(observed ~ scale(trialn) + testing_condition*RC1_L3 + (1+testing_condition|sbj_ID), data=subset(data_testing_c1_lm, rt>300 & rt<3000), family='binomial');
summary(lm_c1_RC1);
#FULL DATASET: RC1 non significant as main effect (p=0.165) and interaction
#CLUSTER 1: RC1 non significant as main effect (p=0.198) and interaction
lm_c1_RC9 <- glmer(observed ~ scale(trialn) + testing_condition*RC9_L4 + (1+testing_condition|sbj_ID), data=subset(data_testing_c1_lm, rt>300 & rt<3000), family='binomial');
summary(lm_c1_RC9);
#FULL DATASET: RC9 non significant as main effect (p=0.19) and interaction
#CLUSTER 1: RC9 non significant as main effect (p=0.47) and interaction
lm_c1_RC2 <- glmer(observed ~ scale(trialn) + testing_condition*RC2_use_L1vsL2 + (1+testing_condition|sbj_ID), data=subset(data_testing_c1_lm, rt>300 & rt<3000), family='binomial');
summary(lm_c1_RC2);
#FULL DATASET: RC2 non significant as main effect (p=0.22) and interaction
#CLUSTER 1: RC2 non significant as main effect (p=0.25) and interaction
lm_c1_RC6 <- glmer(observed ~ scale(trialn) + testing_condition*RC6_use_L4 + (1+testing_condition|sbj_ID), data=subset(data_testing_c1_lm, rt>300 & rt<3000), family='binomial');
summary(lm_c1_RC6);
#FULL DATASET: RC6 non significant as main effect (p=0.11) and interaction
#CLUSTER 1: RC6 non significant as main effect (p=0.12) and interaction
lm_c1_ent <- glmer(observed ~ scale(trialn) + testing_condition*lang_ent + (1+testing_condition|sbj_ID), data=subset(data_testing_c1_lm, rt>300 & rt<3000), family='binomial');
summary(lm_c1_ent);
#FULL DATASET: 2M sig (p=0.003), lang_ent non-sig (p=0.67)
#CLUSTER 1: 2M sig (p=0.002), lang_ent non-sig (p=0.31)
lm_c1_multiexp <- glmer(observed ~ scale(trialn) + testing_condition*scale(multi_exp) + (1|sbj_ID), data=subset(data_testing_c1_lm, rt>300 & rt<3000), family='binomial');
summary(lm_c1_multiexp);
#FULL DATASET: 1M sig (p=4e-15), 2M sig (p<2e-16), multi_exp non-sig (p=0.42)
#CLUSTER 1: 1M sig (p=8e-5), 2M sig (p=6e-11), multi_exp non-sig (p=0.22)
lm_c1_L1L2diff <- glmer(observed ~ scale(trialn) + testing_condition*scale(L1_L2_diff) + (1+testing_condition|sbj_ID), data=subset(data_testing_c1_lm, rt>300 & rt<3000), family='binomial');
summary(lm_c1_L1L2diff);
#FULL DATASET: 1M sig (p=3e-13) 2M sig (p<2e-16), L1_L2_diff non sig (p=0.62), 1M*L1_L2_diff (p=0.02) & 2M*L1_L2_diff (p=0.03) sig
#CLUSTER 1: 1M sig (p=9e-10) 2M sig (p<2e-16), L1_L2_diff non sig (p=0.47), 1M*L1_L2_diff non sig (p=0.34) & 2M*L1_L2_diff non sig (p=0.10)


#2M - accuracy
data_testing_c1_lm_2M <- subset(data_testing_lm_2M[data_testing_lm_2M$sbj_ID %in% data_testing_c1$sbj_ID,]);
lm_c1_2M_Gender <- glmer(observed ~ scale(trialn) + expected*Gender + (1+expected|sbj_ID), data=data_testing_c1_lm_2M, family='binomial');
summary(lm_c1_2M_Gender);
#FULL DATASET: Gender non sig (p=0.13 for Other, p=0.15 for Woman)
#CLUSTER 1: Gender non sig (p=0.10 for Other, p=0.40 for Woman), expected*Other sig (p=0.04)
lm_c1_2M_Age <- glmer(observed ~ scale(trialn) + expected*scale(Age) + (1+expected|sbj_ID), data=data_testing_c1_lm_2M, family='binomial');
summary(lm_c1_2M_Age);
#FULL DATASET: Age non sig (p=0.62), also for interaction (p=0.16)
#CLUSTER 1: Age non sig (p=0.95), also for interaction (p=0.48)
lm_c1_2M_RC1 <- glmer(observed ~ scale(trialn) + expected*RC1_L3 + (1+expected|sbj_ID), data=data_testing_c1_lm_2M, family='binomial');
summary(lm_c1_2M_RC1);
#FULL DATASET: RC1 non sig (p=0.58), also for interaction (p=0.75)
#CLUSTER 1: RC1 non sig (p=0.44), also for interaction (p=0.96)
lm_c1_2M_RC9 <- glmer(observed ~ scale(trialn) + expected*RC9_L4 + (1+expected|sbj_ID), data=data_testing_c1_lm_2M, family='binomial');
summary(lm_c1_2M_RC9);
#FULL DATASET: RC9 non sig (p=0.91), also for interaction (p=0.16)
#CLUSTER 1: RC9 non sig (p=0.30), also for interaction (p=0.15)
lm_c1_2M_RC2 <- glmer(observed ~ scale(trialn) + expected*RC2_use_L1vsL2 + (1+expected|sbj_ID), data=data_testing_c1_lm_2M, family='binomial');
summary(lm_c1_2M_RC2);
#FULL DATASET: RC2 non sig (p=0.15), also for interaction (p=0.62)
#CLUSTER 1: RC2 non sig (p=0.11), also for interaction (p=0.67)
lm_c1_2M_RC6 <- glmer(observed ~ scale(trialn) + expected*RC6_use_L4 + (1+expected|sbj_ID), data=data_testing_c1_lm_2M, family='binomial');
summary(lm_c1_2M_RC6);
#FULL DATASET: RC6 non sig (p=0.24), also for interaction (p=0.39)
#CLUSTER 1: RC6 sig (p=0.03), non sig for interaction (p=0.40)
lm_c1_2M_ent <- glmer(observed ~ scale(trialn) + expected*lang_ent + (1+expected|sbj_ID), data=data_testing_c1_lm_2M, family='binomial');
summary(lm_c1_2M_ent);
#FULL DATASET: lang_ent non sig (p=0.14), also for interaction (p=0.11)
#CLUSTER 1: lang_ent non sig (p=0.44), also for interaction (p=0.40)
lm_c1_2M_multiexp <- glmer(observed ~ scale(trialn) + expected*scale(multi_exp) + (1+expected|sbj_ID), data=data_testing_c1_lm_2M, family='binomial');
summary(lm_c1_2M_multiexp);
#FULL DATASET: multi_exp sig (p=0.04), marginally sig for interaction (p=0.08)
#CLUSTER 1: multi_exp non sig (p=0.33), non sig for interaction (p=0.35)
lm_c1_2M_L1L2diff <- glmer(observed ~ scale(trialn) + expected*scale(L1_L2_diff) + (1+expected|sbj_ID), data=data_testing_c1_lm_2M, family='binomial');
summary(m47);
#FULL DATASET: L1_L2_diff sig (p=0.03), interaction non sig (p=0.26)
#CLUSTER 1: L1_L2_diff marginally sig (p=0.06), interaction non sig (p=0.77)


# FAMILIARITY #
data_c1_BLP_familiarity <- subset(data_BLP_familiarity[data_BLP_familiarity$sbj_ID %in% data_testing_c1$sbj_ID,]);
lm_c1_fam_Gender <- glmer(correct ~ scale(trialn) + Gender + (1|sbj_ID), data=data_c1_BLP_familiarity, family='binomial');
summary(lm_c1_fam_Gender);
#FULL DATASET: Gender(Other) marginally sig (p=0.06); Woman non sig (p=0.82)
#CLUSTER 1: Gender non sig (p=0.12 for Other; p=0.77 for Woman)
lm_c1_fam_Age <- glmer(correct ~ scale(trialn) + scale(Age) + (1|sbj_ID), data=data_BLP_familiarity, family='binomial');
summary(lm_c1_fam_Age);
#FULL DATASET: Age marginally sig (p=0.06)
#CLUSTER 1: Age marginally sig (p=0.06)
lm_c1_fam_RC1 <- glmer(correct ~ scale(trialn) + RC1_L3 + (1|sbj_ID), data=data_c1_BLP_familiarity, family='binomial');
summary(lm_c1_fam_RC1);
#FULL DATASET: RC1_L3 non sig (p=0.34)
#CLUSTER 1: RC1_L3 non sig (p=0.71)
lm_c1_fam_RC9 <- glmer(correct ~ scale(trialn) + RC9_L4 + (1|sbj_ID), data=data_c1_BLP_familiarity, family='binomial');
summary(lm_c1_fam_RC9);
#FULL DATASET: RC9_L4 non sig (p=0.51)
#CLUSTER 1: RC9_L4 non sig (p=0.56)
lm_c1_fam_RC2 <- glmer(correct ~ scale(trialn) + RC2_use_L1vsL2 + (1|sbj_ID), data=data_c1_BLP_familiarity, family='binomial');
summary(lm_c1_fam_RC2);
#FULL DATASET: RC2_use_L1vsL2 non sig (p=0.52)
#CLUSTER 1: RC2_use_L1vsL2 non sig (p=0.53)
lm_c1_fam_RC6 <- glmer(correct ~ scale(trialn) + RC6_use_L4 + (1|sbj_ID), data=data_c1_BLP_familiarity, family='binomial');
summary(lm_c1_fam_RC6);
#FULL DATASET: RC6_use_L4 marginally non sig (p=0.06)
#CLUSTER 1: RC6_use_L4 marginally non sig (p=0.07)
lm_c1_fam_ent <- glmer(correct ~ scale(trialn) + lang_ent + (1|sbj_ID), data=data_c1_BLP_familiarity, family='binomial');
summary(lm_c1_fam_ent);
#FULL DATASET: lang_ent non sig (p=0.72)
#CLUSTER 1: lang_ent non sig (0.44)
lm_c1_fam_multiexp <- glmer(correct ~ scale(trialn) + scale(multi_exp) + (1|sbj_ID), data=data_c1_BLP_familiarity, family='binomial');
summary(lm_c1_fam_multiexp);
#FULL DATASET: multi_exp non sig (p=0.63)
#CLUSTER 1: multi_exp non sig (p=0.47)
lm_c1_fam_L1L2diff <- glmer(correct ~ scale(trialn) + scale(L1_L2_diff) + (1|sbj_ID), data=data_c1_BLP_familiarity, family='binomial');
summary(lm_c1_fam_L1L2diff);
#FULL DATASET: L1_L2_diff non sig (p=0.40)
#CLUSTER 1: L1_L2_diff non sig (p=0.38)



###################
# CLUSTERING TREE #
###################
library(Hmisc);
data_BLP_short <- subset(data_BLP, select=-c(sbj_ID,Age,Gender,Education,L1,L2,L3,L4,otherLs,task,AttentionL1,AttentionL2,AttentionL3,AttentionL4,temp_sbjID));
temp <- subset(data_BLP_short, select=c(HistoryL1Score,HistoryL2Score,HistoryL3Score,HistoryL4Score,UseL1Score,UseL2Score,UseL3Score,UseL4Score,ProficiencyL1Score,ProficiencyL2Score,ProficiencyL3Score,ProficiencyL4Score,AttitudeL1Score,AttitudeL2Score,AttitudeL3Score,AttitudeL4Score,L1Score,L2Score,L3Score,L4Score,lang_var,lang_ent,multi_exp,L1_L2_diff,RC1_L3,RC9_L4,RC2_use_L1vsL2,RC6_use_L4));
plot(varclus(as.matrix(temp)));



# remove datapoints if participant doesn't know additional languages
data_BLP$langfilter1 <- TRUE;
data_BLP$langfilter2 <- TRUE;
data_BLP$langfilter3 <- TRUE;
data_BLP$langfilter4 <- TRUE;
data_BLP$langfilter2[data_BLP$L2Score==0] <- FALSE;
data_BLP$langfilter3[data_BLP$L3Score==0] <- FALSE;
data_BLP$langfilter4[data_BLP$L4Score==0] <- FALSE;
data_BLP$L2Score[data_BLP$langfilter2==FALSE] <- NA;
data_BLP$L3Score[data_BLP$langfilter3==FALSE] <- NA;
data_BLP$L4Score[data_BLP$langfilter4==FALSE] <- NA;
ok2 <- ! is.na(data_BLP$L2Score);
ok3 <- ! is.na(data_BLP$L3Score);
ok4 <- ! is.na(data_BLP$L4Score);

# plot language scores per participant
#by temp_sbjID
plot(data_BLP$L1Score~data_BLP$temp_sbjID,ylab="Language Score",ylim=c(0,230),xlab="Participant",main="",pch=19,cex.lab=1.5,col=cols2[1],xaxt="n",yaxs="i");
axis(1, at = c(1:193));
points(data_BLP$L2Score~data_BLP$temp_sbjID,subset=ok2,pch=19,col=cols2[2]);
points(data_BLP$L3Score~data_BLP$temp_sbjID,subset=ok2,pch=19,col=cols2[3]);
points(data_BLP$L4Score~data_BLP$temp_sbjID,subset=ok2,pch=19,col=cols2[4]);
legend("bottomleft",title="Language:",c("L1","L2","L3","L4"),fill=c(cols2[1],cols2[2],cols2[3],cols2[4]),bty = "n",
       cex=1,y.intersp=0.5);
abline(h=218, lty=5);

#by lang_ent
sorted_order1 <- order(data_BLP$lang_ent);
plot(data_BLP$L1Score[sorted_order1]~data_BLP$temp_sbjID[sorted_order1],ylab="Language Score",ylim=c(0,230),xlab="Participants, by increasing lang_ent",main="",pch=19,cex.lab=1.5,col=cols2[1],xaxt="n",yaxs="i");
points(data_BLP$L2Score[sorted_order1]~data_BLP$temp_sbjID[sorted_order1],subset=ok2,pch=19,col=cols2[2]);
points(data_BLP$L3Score[sorted_order1]~data_BLP$temp_sbjID[sorted_order1],subset=ok2,pch=19,col=cols2[3]);
points(data_BLP$L4Score[sorted_order1]~data_BLP$temp_sbjID[sorted_order1],subset=ok2,pch=19,col=cols2[4]);
legend("bottomleft",title="Language:",c("L1","L2","L3","L4"),fill=c(cols2[1],cols2[2],cols2[3],cols2[4]),bty = "n",
       cex=1,y.intersp=0.5);
abline(h=218, lty=5);

#by multi_exp
sorted_order2 <- order(data_BLP$multi_exp);
plot(data_BLP$L1Score[sorted_order2]~data_BLP$temp_sbjID[sorted_order2],ylab="Language Score",ylim=c(0,230),xlab="Participants, by increasing multi_exp",main="",pch=19,cex.lab=1.5,col=cols2[1],xaxt="n",yaxs="i");
points(data_BLP$L2Score[sorted_order2]~data_BLP$temp_sbjID[sorted_order2],subset=ok2,pch=19,col=cols2[2]);
points(data_BLP$L3Score[sorted_order2]~data_BLP$temp_sbjID[sorted_order2],subset=ok2,pch=19,col=cols2[3]);
points(data_BLP$L4Score[sorted_order2]~data_BLP$temp_sbjID[sorted_order2],subset=ok2,pch=19,col=cols2[4]);
legend("bottomleft",title="Language:",c("L1","L2","L3","L4"),fill=c(cols2[1],cols2[2],cols2[3],cols2[4]),bty = "n",
       cex=1,y.intersp=0.5);
abline(h=218, lty=5);

#by L1_L2_diff
sorted_order3 <- order(data_BLP$L1_L2_diff);
plot(data_BLP$L1Score[sorted_order3]~data_BLP$temp_sbjID[sorted_order3],ylab="Language Score",ylim=c(0,230),xlab="Participants, by increasing L1_L2_diff",main="",pch=19,cex.lab=1.5,col=cols2[1],xaxt="n",yaxs="i");
points(data_BLP$L2Score[sorted_order3]~data_BLP$temp_sbjID[sorted_order3],subset=ok2,pch=19,col=cols2[2]);
points(data_BLP$L3Score[sorted_order3]~data_BLP$temp_sbjID[sorted_order3],subset=ok2,pch=19,col=cols2[3]);
points(data_BLP$L4Score[sorted_order3]~data_BLP$temp_sbjID[sorted_order3],subset=ok2,pch=19,col=cols2[4]);
legend("bottomleft",title="Language:",c("L1","L2","L3","L4"),fill=c(cols2[1],cols2[2],cols2[3],cols2[4]),bty = "n",
       cex=1,y.intersp=0.5);
abline(h=218, lty=5)

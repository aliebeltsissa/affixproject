geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2) +
scale_fill_manual(values=c("#999999", "#646464")) +
theme(text = element_text(family = "serif")) +
labs(y="Scores", title="Semantic condition") +
theme(legend.position = "none") +
theme(axis.title.x = element_blank()) +
theme(axis.text.x = element_text(size = 12)) +
theme(plot.title = element_text(size = 14)) +
theme(plot.title = element_text(hjust = 0.5)) +
ylim(0, 100)
ggarrange(cog2, con2, int2, sem2,
ncol = 2, nrow = 2)
sem<-data.frame(Mean=c(66.62,51.28),
sd=c(2.57,3.32),
Type=as.factor(c("Bilingual","Monolingual")),
Category=c("Bilingual","Monolingual"),
Insert= c(0.0, 0.5))
sem2 <- ggplot(sem, aes(x=Category, y=Mean, fill=Category)) +
geom_bar(position=position_dodge(), stat="identity",
colour='black') +
geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2) +
scale_fill_manual(values=c("#999999", "#646464")) +
theme(text = element_text(family = "serif")) +
labs(y="Scores", title="Semantic condition") +
theme(legend.position = "none") +
theme(axis.title.x = element_blank()) +
theme(axis.text.x = element_text(size = 12)) +
theme(plot.title = element_text(size = 14)) +
theme(plot.title = element_text(hjust = 0.5)) +
ylim(0, 100)
ggarrange(cog2, con2, int2, sem2,
ncol = 2, nrow = 2)
bi<-data.frame(Mean=c(72.72,50.93,60.07,66.62),
sd=c(2.46,3.13,2.68,2.57),
Type=as.factor(c("Cognate","Control","Interlingual Homophone","Semantic")),
Category=c("Cognate","Control","Interlingual Homophone","Semantic"),
Insert= c(0.0, 0.1, 0.5, 1))
bi2<-ggplot(bi, aes(x=Category, y=Mean, fill=Category)) +
geom_bar(position=position_dodge(), stat="identity",
colour='black') +
geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2) +
scale_fill_manual(values=c("#696969", "#808080", "#a9a9a9", "#DCDCDC")) +
theme(text = element_text(family = "serif")) +
labs(y="Scores", title="Bilinguals") +
theme(legend.position = "none") +
theme(axis.title.x = element_blank()) +
theme(axis.text.x = element_text(size = 12)) +
theme(plot.title = element_text(size = 14)) +
theme(plot.title = element_text(hjust = 0.5)) +
ylim(0, 100)
mono<-data.frame(Mean=c(72.03,50.02,59.55,51.28),
sd=c(2.50,3.56,2.82,3.32),
Type=as.factor(c("Cognate","Control","Interlingual Homophone","Semantic")),
Category=c("Cognate","Control","Interlingual Homophone","Semantic"),
Insert= c(0.0, 0.1, 0.5, 1))
mono2 <- ggplot(mono, aes(x=Category, y=Mean, fill=Category)) +
geom_bar(position=position_dodge(), stat="identity",
colour='black') +
geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2) +
scale_fill_manual(values=c("#696969", "#808080", "#a9a9a9", "#DCDCDC")) +
theme(text = element_text(family = "serif")) +
labs(y="Scores", title="Monolinguals") +
theme(legend.position = "none") +
theme(axis.title.x = element_blank()) +
theme(axis.text.x = element_text(size = 12)) +
theme(plot.title = element_text(size = 14)) +
theme(plot.title = element_text(hjust = 0.5)) +
ylim(0, 100)
ggarrange(bi2, mono2,
ncol = 1, nrow = 2)
summary3<-read.csv("C:/Users/annal/OneDrive - University of Sussex/School/2021-2022/Spring term - 4th year project/Data/SummaryAnalysisByParticipant3.csv")
attach(summary3)
str(summary3)
summary3 <- summary3 %>%
gather(key = "condition", value = "scores", CogDiffCon, IntDiffCon, SemDiffCon) %>%
convert_as_factor(Participant.External.Session.ID, condition)
res.aov <- aov(scores ~ condition, data = summary3)
summary4 <- summary4 %>%
gather(key = "langexp", value = "exp", Eng_yearsused, Fr_yearsused, Eng_hoursspeaking, Fr_hoursspeaking) %>%
convert_as_factor(Participant.External.Session.ID, langexp)
summary4<-read.csv("C:/Users/annal/OneDrive - University of Sussex/School/2021-2022/Spring term - 4th year project/Data/SummaryAnalysisByParticipant4.csv")
attach(summary4)
str(summary4)
summary4 <- summary4 %>%
gather(key = "condition", value = "scores", CognateLogOdds, ControlLogOdds, InterlingualHomophoneLogOdds, SemanticLogOdds) %>%
convert_as_factor(Participant.External.Session.ID, condition)
summary4 <- summary4 %>%
gather(key = "langexp", value = "exp", Eng_yearsused, Fr_yearsused, Eng_hoursspeaking, Fr_hoursspeaking) %>%
convert_as_factor(Participant.External.Session.ID, langexp)
res.aov <- summary4 %>%
anova_test(scores ~ langexp + condition)
get_anova_table(res.aov)
knitr::opts_chunk$set(echo = TRUE,
eval = TRUE,
warning = FALSE,
fig.path = "graphics/",
fig.width = 8,
fig.height = 4,
fig.retina = 2,
fig.align = "center",
fig.pos = "t",
collapse = TRUE
)
load("data/class5.RData");
library(lme4); #this is necessary for 'lmer'
library(rms); #this is necessary for 'rcs'
package.install(rms)
install.packages("rms")
library(rms); #this is necessary for 'rcs'
library(Hmisc)
install.packages("htmltools")
install.packages("htmltools")
knitr::opts_chunk$set(echo = TRUE,
eval = TRUE,
warning = FALSE,
fig.path = "graphics/",
fig.width = 8,
fig.height = 4,
fig.retina = 2,
fig.align = "center",
fig.pos = "t",
collapse = TRUE
)
load("data/class5.RData");
library(lme4); #this is necessary for 'lmer'
library(rms); #this is necessary for 'rcs'
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
remove.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
knitr::opts_chunk$set(echo = TRUE,
eval = TRUE,
warning = FALSE,
fig.path = "graphics/",
fig.width = 8,
fig.height = 4,
fig.retina = 2,
fig.align = "center",
fig.pos = "t",
collapse = TRUE
)
load("data/class5.RData");
library(lme4); #this is necessary for 'lmer'
library(rms); #this is necessary for 'rcs'
m4 <- lmer(rt ~ 1 + rcs(ticks,4)*condition + (1|sbjId) + (1|target), data=data_for_analysis);
summary(m4)[[10]]; #betas are quite crazy (high and low), and quite some variability. Lots of significance, but not easy to interpret. But wait before jumping there, let's check whether the non-linearity was worth it:
anova(m4,m3); #it does provide a nice improvement in goodness of fit, for the extra complexity that it costs (which is a lot, note -- 6 dfs)
#does the model fit the data better?
library(effects);
###########
# PILOT 4 #
###########
setwd("C:/Users/annal/OneDrive/Documents/GitHub/affixproject")
# import testing data
data_pilot4_testing <- read.csv("testing_preprocessed.csv",header=T,sep=",");
View(data_pilot4_testing)
data_pilot4_testing = subset(data_pilot4_testing, select = -c(X)) # remove redundant column added by Pavlovia
# import testing data
data_pilot4_testing <- read.csv("testing_preprocessed.csv",header=T,sep=",");
data_pilot4_testing = subset(data_pilot4_testing, select = -c(X)) # remove redundant column added by Pavlovia
# import testing data
data_pilot4_testing <- read.csv("testing_preprocessed.csv",header=T,sep=",");
data_pilot4_testing = subset(data_pilot4_testing, select = -c(X)) # remove redundant column added by Pavlovia
# import testing data
data_pilot4_testing <- read.csv("testing_preprocessed.csv",header=T,sep=",");
data_pilot4_testing = subset(data_pilot4_testing, select = -c(X)) # remove redundant column added by Pavlovia
# make some variables factors
data_pilot4_testing$sbj_ID <- as.factor(data_pilot4$sbj_ID);
# make some variables factors
data_pilot4_testing$sbj_ID <- as.factor(data_pilot4_testing$sbj_ID);
data_pilot4_testing$task <- as.factor(data_pilot4_testing$task);
data_pilot4_testing$item <- as.factor(data_pilot4_testing$item);
data_pilot4_testing$correct <- as.logical(data_pilot4_testing$correct);
summary(data_pilot4_testing);
# boxplot of all pilot 4 testing data
data_pilot4_testing_means <- aggregate(data_pilot4_testing$correct[complete.cases(data_pilot4_testing$correct)], list(data_pilot4_testing$sbj_ID[complete.cases(data_pilot4_testing$correct)]), FUN=sum);
data_pilot4_testing_means$x<-(data_pilot4_testing_means$x)*10/4;
boxplot(data_pilot4_testing_means$x, ylab = "Accuracy score (in %)");
abline(h=50, lty=5);
# split into different pilot 4 versions: 4.1 is with 4 training reps, 4.1 is with 8
data_pilot4.1_testing <- subset(data_pilot4_testing, sbj_ID=='5fb7b8880045d6396a86c803'|sbj_ID=='5f4cc4ea00dba58ecd5a98a4'|sbj_ID=='615c43b800752a4f3d0fd1f0'|sbj_ID=='6175a0a52e748285b3476b27'|sbj_ID=='60b55a6d44e17d6f0b810cdd'|sbj_ID=='60d87fdab51e54fe4863f97f'|sbj_ID=='60ba2011cd8052508d401296'|sbj_ID=='5ee7b7c9eef92207297a0ad4'|sbj_ID=='614060a52d7c64c27ef9887c'|sbj_ID=='5d97c38dce449e001244dc15'|sbj_ID=='5ed54d02957bee0c0de36cac'|sbj_ID=='61158a5c1d8390415ff117a8'|sbj_ID=='5e823b35726b2a9508db127c'|sbj_ID=='5caca6b4a9acb200011a6547'|sbj_ID=='5cf14e1eb4397d0001f94e20'|sbj_ID=='5cb4adc019ee7300189e8547'|sbj_ID=='5f3161410f87706425490ae1'|sbj_ID=='5e8783b0fde5153fbd9dca43'|sbj_ID=='60c9c6e1728092717b93abde'|sbj_ID=='5feb64b3341f42bb63200e36');
data_pilot4.2_testing <- subset(data_pilot4_testing, sbj_ID=='60f1846c851ee5a978a0e015'|sbj_ID=='60fd703ecd62eb39eb07c328'|sbj_ID=='60ddf71e95896d2595f0e1a5'|sbj_ID=='605c9355001a5eb6d51e657d'|sbj_ID=='5f11ccbc1a1a2c08b4a99efb'|sbj_ID=='5fb3f38909fc360164f7c98d'|sbj_ID=='60a45e33f404ba8cb7a19cfe'|sbj_ID=='608abc6251feb3ddc3b2e01d'|sbj_ID=='608edc13472b2dbc27b369fa'|sbj_ID=='612d5712d75b6c46b4cefc63'|sbj_ID=='5e82e99b37d333a1474dda93'|sbj_ID=='613d091096ca434d703f77c5'|sbj_ID=='609568823ff056b77e565445'|sbj_ID=='5e80c7d61a07dd7b0d8f0111'|sbj_ID=='59aaf4b1321f870001d16f6c'|sbj_ID=='6048158f62550615002408af'|sbj_ID=='6161f43ddd46e845e7b3fab8'|sbj_ID=='5ec806f532fe7d2afa2e315b'|sbj_ID=='5e99d95e0f50aa04266ad4ad'|sbj_ID=='5c5e04ca6539fe00016e1afa');
# testing boxplot
data_pilot4.1_testing_means <- aggregate(data_pilot4.1_testing$correct, list(data_pilot4.1_testing$sbj_ID), FUN=sum, na.rm=TRUE);
data_pilot4.1_testing_means$x <- (data_pilot4.1_testing_means$x)*10/4;
boxplot(data_pilot4.1_testing_means$x, ylab = "Accuracy score (in %)");
abline(h=50, lty=5);
# testing d'
dprimes <- dPrime(data_pilot4.1_testing$sbj_ID, data_pilot4.1_testing$expected, data_pilot4.1_testing$observed);
summary(dprimes);
# testing RTs
library(paletteer);
cols <- paletteer_d("ggthemes::Classic_20");
IDs <- list(data_pilot4.1_testing$sbj_ID);
IDs <- sapply(IDs, unique);
plot(density(data_pilot4.1_testing$rt[data_pilot4.1_testing$sbj_ID==IDs[1]],na.rm=TRUE),xlim=c(0,2200),ylim=c(0,0.005),xlab="RTs (ms)",main="",xaxt = "n",col=cols[1],yaxs="i",lwd=2,cex.lab=1.5);
axis(1, at = c(0,200,400,600,800,1000,1200,1400,1600,1800,2000,2200));
for (x in 2:20) {
lines(density(data_pilot4.1_testing$rt[data_pilot4.1_testing$sbj_ID==IDs[x]],na.rm=TRUE),col=cols[x],lwd=2)
};
legend("topright",title="Participant:",legend=c(1:20),fill=cols,bty = "n",
cex=0.85,y.intersp=0.5);
data_pilot4.1_testing_rt_means <- aggregate(data_pilot4.1_testing$rt, list(data_pilot4.1_testing$sbj_ID), FUN=mean, na.rm=TRUE);
# testing accuracy*RTs
cor(data_pilot4.1_testing_means$x, data_pilot4.1_testing_rt_means$x); # r = 0.16
plot(data_pilot4.1_testing_rt_means$x, data_pilot4.1_testing_means$x, pch=19);
# testing strategy
pilot4.1_strats <- list(data_pilot4.1_testing$strategy);
pilot4.1_strats <- sapply(pilot4.1_strats, unique);
# FAMILIARITY
data_pilot4_familiarity <- read.csv("familiarity_preprocessed.csv",header=T,sep=",");
data_pilot4_familiarity = subset(data_pilot4_familiarity, select = -c(X)) # remove redundant column added by Pavlovia
View(data_pilot4_familiarity)
# FAMILIARITY
data_pilot4_familiarity <- read.csv("familiarity_preprocessed.csv",header=T,sep=",");
data_pilot4_familiarity = subset(data_pilot4_familiarity, select = -c(X)) # remove redundant column added by Pavlovia
# make some variables factors
data_pilot4_familiarity$sbj_ID <- as.factor(data_pilot4_familiarity$sbj_ID);
data_pilot4_familiarity$task <- as.factor(data_pilot4_familiarity$task);
data_pilot4_familiarity$item <- as.factor(data_pilot4_familiarity$item);
data_pilot4_familiarity$correct <- as.logical(data_pilot4_familiarity$correct);
data_pilot4_familiarity$target <- as.factor(data_pilot4_familiarity$target);
data_pilot4_familiarity$confound <- as.factor(data_pilot4_familiarity$confound);
# split into different pilot 4 versions: 4.1 is with 4 training reps, 4.1 is with 8
data_pilot4.1_familiarity <- subset(data_pilot4_familiarity, sbj_ID=='5fb7b8880045d6396a86c803'|sbj_ID=='5f4cc4ea00dba58ecd5a98a4'|sbj_ID=='615c43b800752a4f3d0fd1f0'|sbj_ID=='6175a0a52e748285b3476b27'|sbj_ID=='60b55a6d44e17d6f0b810cdd'|sbj_ID=='60d87fdab51e54fe4863f97f'|sbj_ID=='60ba2011cd8052508d401296'|sbj_ID=='5ee7b7c9eef92207297a0ad4'|sbj_ID=='614060a52d7c64c27ef9887c'|sbj_ID=='5d97c38dce449e001244dc15'|sbj_ID=='5ed54d02957bee0c0de36cac'|sbj_ID=='61158a5c1d8390415ff117a8'|sbj_ID=='5e823b35726b2a9508db127c'|sbj_ID=='5caca6b4a9acb200011a6547'|sbj_ID=='5cf14e1eb4397d0001f94e20'|sbj_ID=='5cb4adc019ee7300189e8547'|sbj_ID=='5f3161410f87706425490ae1'|sbj_ID=='5e8783b0fde5153fbd9dca43'|sbj_ID=='60c9c6e1728092717b93abde'|sbj_ID=='5feb64b3341f42bb63200e36');
data_pilot4.2_familiarity <- subset(data_pilot4_familiarity, sbj_ID=='60f1846c851ee5a978a0e015'|sbj_ID=='60fd703ecd62eb39eb07c328'|sbj_ID=='60ddf71e95896d2595f0e1a5'|sbj_ID=='605c9355001a5eb6d51e657d'|sbj_ID=='5f11ccbc1a1a2c08b4a99efb'|sbj_ID=='5fb3f38909fc360164f7c98d'|sbj_ID=='60a45e33f404ba8cb7a19cfe'|sbj_ID=='608abc6251feb3ddc3b2e01d'|sbj_ID=='608edc13472b2dbc27b369fa'|sbj_ID=='612d5712d75b6c46b4cefc63'|sbj_ID=='5e82e99b37d333a1474dda93'|sbj_ID=='613d091096ca434d703f77c5'|sbj_ID=='609568823ff056b77e565445'|sbj_ID=='5e80c7d61a07dd7b0d8f0111'|sbj_ID=='59aaf4b1321f870001d16f6c'|sbj_ID=='6048158f62550615002408af'|sbj_ID=='6161f43ddd46e845e7b3fab8'|sbj_ID=='5ec806f532fe7d2afa2e315b'|sbj_ID=='5e99d95e0f50aa04266ad4ad'|sbj_ID=='5c5e04ca6539fe00016e1afa');
# pilot 4.1
data_pilot4.1_familiarity_means <- aggregate(data_pilot4.1_familiarity$correct, list(data_pilot4.1_familiarity$sbj_ID), FUN=sum);
data_pilot4.1_familiarity_means$x<-(data_pilot4.1_familiarity_means$x)*10/3;
boxplot(data_pilot4.1_familiarity_means$x, ylab = "Familiarity score (in %)");
abline(h=50, lty=5);
# familiarity RTs
IDs <- list(data_pilot4.1_familiarity$sbj_ID);
IDs <- sapply(IDs, unique);
summary(data_pilot4.1_familiarity$rt[data_pilot4.1_familiarity$sbj_ID==IDs[15]]) # this participant has super fast RTs
plot(density(data_pilot4.1_familiarity$rt[data_pilot4.1_familiarity$sbj_ID==IDs[1]]),xlim=c(0,4000),ylim=c(0,0.005),xlab="Familiarity RTs (ms)",main="",xaxt = "n",col=cols[1],yaxs="i");
axis(1, at = c(0,500,1000,1500,2000,2500,3000,3500,4000));
for (x in 2:20) {
lines(density(data_pilot4.1_familiarity$rt[data_pilot4.1_familiarity$sbj_ID==IDs[x]]),col=cols[x])
};
legend("topright",title="Participant:",legend=c(1:20),fill=cols,bty = "n",
cex=0.75,y.intersp=0.5);
data_pilot4.1_familiarity_rt_means <- aggregate(data_pilot4.1_familiarity$rt, list(data_pilot4.1_familiarity$sbj_ID), FUN=mean, na.rm=TRUE);
# familiarity accuracy*RTs
cor(data_pilot4.1_familiarity_means$x, data_pilot4.1_familiarity_rt_means$x); # r = 0.29
plot(data_pilot4.1_familiarity_rt_means$x, data_pilot4.1_familiarity_means$x, xlab="Mean participant RT (in ms)", ylab="Mean participant familiarity score (in %)", pch=19, cex=2, cex.lab=1.45);
text(3000,45,"Pearson's r = 0.29",cex=1.5);
# pilot 4.2
# testing boxplot
data_pilot4.2_testing_means <- aggregate(data_pilot4.2_testing$correct, list(data_pilot4.2_testing$sbj_ID), FUN=sum, na.rm=TRUE);
data_pilot4.2_testing_means$x<-(data_pilot4.2_testing_means$x)*10/4;
boxplot(data_pilot4.2_testing_means$x, ylab = "Accuracy score (in %)");
abline(h=50, lty=5);
# testing RTs
IDs <- list(data_pilot4.2_testing$sbj_ID);
IDs <- sapply(IDs, unique);
plot(density(data_pilot4.2_testing$rt[data_pilot4.2_testing$sbj_ID==IDs[1]],na.rm=TRUE),xlim=c(0,2200),ylim=c(0,0.0035),xlab="RTs (ms)",main="",xaxt = "n",col=cols[1],yaxs="i",lwd=2,cex.lab=1.5);
axis(1, at = c(0,200,400,600,800,1000,1200,1400,1600,1800,2000,2200));
for (x in 2:20) {
lines(density(data_pilot4.2_testing$rt[data_pilot4.2_testing$sbj_ID==IDs[x]],na.rm=TRUE),col=cols[x],lwd=2)
};
legend("topright",title="Participant:",legend=c(1:20),fill=cols,bty = "n",
cex=0.85,y.intersp=0.5);
data_pilot4.2_testing_rt_means <- aggregate(data_pilot4.2_testing$rt, list(data_pilot4.2_testing$sbj_ID), FUN=mean, na.rm=TRUE);
# testing accuracy*RTs
cor(data_pilot4.2_testing_means$x, data_pilot4.2_testing_rt_means$x); # r = 0.04
plot(data_pilot4.2_testing_rt_means$x, data_pilot4.2_testing_means$x, pch=19);
# testing strategy
pilot4.2_strats <- list(data_pilot4.2_testing$strategy);
pilot4.2_strats <- sapply(pilot4.2_strats, unique);
# pilot 4.2
data_pilot4.2_familiarity_means <- aggregate(data_pilot4.2_familiarity$correct, list(data_pilot4.2_familiarity$sbj_ID), FUN=sum);
data_pilot4.2_familiarity_means$x<-(data_pilot4.2_familiarity_means$x)*10/3;
boxplot(data_pilot4.2_familiarity_means$x, ylab = "Familiarity score (in %)");
abline(h=50, lty=5);
# familiarity RTs
IDs <- list(data_pilot4.2_familiarity$sbj_ID);
IDs <- sapply(IDs, unique);
summary(data_pilot4.2_familiarity$rt[data_pilot4.2_familiarity$sbj_ID==IDs[1]]); # this participant has super fast RTs
summary(data_pilot4.2_familiarity$rt[data_pilot4.2_familiarity$sbj_ID==IDs[10]]); # this participant has super fast RTs
summary(data_pilot4.2_familiarity$rt[data_pilot4.2_familiarity$sbj_ID==IDs[12]]); # this participant has super fast RTs
plot(density(data_pilot4.2_familiarity$rt[data_pilot4.2_familiarity$sbj_ID==IDs[1]]),xlim=c(0,4000),ylim=c(0,0.005),xlab="RTs (ms)",main="",xaxt = "n",col=cols[1],yaxs="i");
axis(1, at = c(0,500,1000,1500,2000,2500,3000,3500,4000));
for (x in 2:20) {
lines(density(data_pilot4.2_familiarity$rt[data_pilot4.2_familiarity$sbj_ID==IDs[x]]),col=cols[x])
};
legend("topright",title="Participant:",legend=c(1:20),fill=cols,bty = "n",
cex=0.75,y.intersp=0.5);
data_pilot4.2_familiarity_rt_means <- aggregate(data_pilot4.2_familiarity$rt, list(data_pilot4.2_familiarity$sbj_ID), FUN=mean, na.rm=TRUE);
# familiarity accuracy*RTs
cor(data_pilot4.2_familiarity_means$x, data_pilot4.2_familiarity_rt_means$x); # r = 0.21
plot(data_pilot4.2_familiarity_rt_means$x, data_pilot4.2_familiarity_means$x, xlab="Mean familiarity task RTs (in ms)", ylab="Mean familiarity score (in %)", pch=19);
# BLP
data_pilot4_BLP <- read.csv("BLP_preprocessed.csv",header=T,sep=",");
View(data_pilot4_BLP)
data_pilot4_BLP = subset(data_pilot4_BLP, select = -c(X)) # remove redundant column added by Pavlovia
# make some variables factors
data_pilot4_BLP$sbj_ID <- as.factor(data_pilot4_BLP$sbj_ID);
data_pilot4_BLP$Sex <- as.factor(data_pilot4_BLP$Sex);
data_pilot4_BLP$Education <- as.factor(data_pilot4_BLP$Education);
data_pilot4_BLP$L1 <- as.factor(data_pilot4_BLP$L1);
data_pilot4_BLP$L2 <- as.factor(data_pilot4_BLP$L2);
data_pilot4_BLP$L3 <- as.factor(data_pilot4_BLP$L3);
data_pilot4_BLP$L4 <- as.factor(data_pilot4_BLP$L4);
data_pilot4_BLP$otherLs <- as.factor(data_pilot4_BLP$otherLs);
data_pilot4_BLP$AttentionL1 <- as.factor(data_pilot4_BLP$AttentionL1);
data_pilot4_BLP$AttentionL2 <- as.factor(data_pilot4_BLP$AttentionL2);
data_pilot4_BLP$AttentionL3 <- as.factor(data_pilot4_BLP$AttentionL3);
data_pilot4_BLP$AttentionL4 <- as.factor(data_pilot4_BLP$AttentionL4);
summary(data_pilot4_BLP);
# standardise language responses
data_pilot4_BLP[data_pilot4_BLP == "italiano" | data_pilot4_BLP == "italiana" | data_pilot4_BLP == "Italiano" | data_pilot4_BLP == "Italiana"] <- "Italian";
View(data_pilot4_BLP)
# BLP
data_pilot4_BLP <- read.csv("BLP_preprocessed.csv",header=T,sep=",");
data_pilot4_BLP = subset(data_pilot4_BLP, select = -c(X)) # remove redundant column added by Pavlovia
# standardise language responses
data_pilot4_BLP[data_pilot4_BLP == "italiano" | data_pilot4_BLP == "italiana" | data_pilot4_BLP == "Italiano" | data_pilot4_BLP == "Italiana"] <- "Italian";
data_pilot4_BLP[data_pilot4_BLP == "portoghese" | data_pilot4_BLP == "Portoghese" | data_pilot4_BLP == "Portuguese"] <- "Portuguese";
data_pilot4_BLP[data_pilot4_BLP == "Francese" | data_pilot4_BLP == "francese"] <- "French";
data_pilot4_BLP[data_pilot4_BLP == "inglese" | data_pilot4_BLP == "Inglese"] <- "English";
data_pilot4_BLP[data_pilot4_BLP == "Spagnolo" | data_pilot4_BLP == "spagnolo"] <- "Spanish";
data_pilot4_BLP[data_pilot4_BLP == "Bulgaro"] <- "Bulgarian";
data_pilot4_BLP[data_pilot4_BLP == "Coreano"] <- "Korean";
data_pilot4_BLP[data_pilot4_BLP == "Piemontese"] <- "Piedmontese";
data_pilot4_BLP[data_pilot4_BLP == "napoletano"] <- "Neapolitan";
data_pilot4_BLP[data_pilot4_BLP == "Dialetto di Carovigno"] <- "Carovignian dialect";
data_pilot4_BLP[data_pilot4_BLP == "russo"] <- "Russian";
data_pilot4_BLP[data_pilot4_BLP == "Cinese"] <- "Chinese";
data_pilot4_BLP[data_pilot4_BLP == "tedesco" | data_pilot4_BLP == "Tedesco"] <- "German"
# make some variables factors
data_pilot4_BLP$sbj_ID <- as.factor(data_pilot4_BLP$sbj_ID);
data_pilot4_BLP$Sex <- as.factor(data_pilot4_BLP$Sex);
data_pilot4_BLP$Education <- as.factor(data_pilot4_BLP$Education);
data_pilot4_BLP$L1 <- as.factor(data_pilot4_BLP$L1);
data_pilot4_BLP$L2 <- as.factor(data_pilot4_BLP$L2);
data_pilot4_BLP$L3 <- as.factor(data_pilot4_BLP$L3);
data_pilot4_BLP$L4 <- as.factor(data_pilot4_BLP$L4);
data_pilot4_BLP$otherLs <- as.factor(data_pilot4_BLP$otherLs);
data_pilot4_BLP$AttentionL1 <- as.factor(data_pilot4_BLP$AttentionL1);
data_pilot4_BLP$AttentionL2 <- as.factor(data_pilot4_BLP$AttentionL2);
data_pilot4_BLP$AttentionL3 <- as.factor(data_pilot4_BLP$AttentionL3);
data_pilot4_BLP$AttentionL4 <- as.factor(data_pilot4_BLP$AttentionL4);
summary(data_pilot4_BLP);
# split into different pilot 4 versions: 4.1 is with 4 training reps, 4.1 is with 8
data_pilot4.1_BLP <- subset(data_pilot4_BLP, sbj_ID=='5fb7b8880045d6396a86c803'|sbj_ID=='5f4cc4ea00dba58ecd5a98a4'|sbj_ID=='615c43b800752a4f3d0fd1f0'|sbj_ID=='6175a0a52e748285b3476b27'|sbj_ID=='60b55a6d44e17d6f0b810cdd'|sbj_ID=='60d87fdab51e54fe4863f97f'|sbj_ID=='60ba2011cd8052508d401296'|sbj_ID=='5ee7b7c9eef92207297a0ad4'|sbj_ID=='614060a52d7c64c27ef9887c'|sbj_ID=='5d97c38dce449e001244dc15'|sbj_ID=='5ed54d02957bee0c0de36cac'|sbj_ID=='61158a5c1d8390415ff117a8'|sbj_ID=='5e823b35726b2a9508db127c'|sbj_ID=='5caca6b4a9acb200011a6547'|sbj_ID=='5cf14e1eb4397d0001f94e20'|sbj_ID=='5cb4adc019ee7300189e8547'|sbj_ID=='5f3161410f87706425490ae1'|sbj_ID=='5e8783b0fde5153fbd9dca43'|sbj_ID=='60c9c6e1728092717b93abde'|sbj_ID=='5feb64b3341f42bb63200e36');
data_pilot4.2_BLP <- subset(data_pilot4_BLP, sbj_ID=='60f1846c851ee5a978a0e015'|sbj_ID=='60fd703ecd62eb39eb07c328'|sbj_ID=='60ddf71e95896d2595f0e1a5'|sbj_ID=='605c9355001a5eb6d51e657d'|sbj_ID=='5f11ccbc1a1a2c08b4a99efb'|sbj_ID=='5fb3f38909fc360164f7c98d'|sbj_ID=='60a45e33f404ba8cb7a19cfe'|sbj_ID=='608abc6251feb3ddc3b2e01d'|sbj_ID=='608edc13472b2dbc27b369fa'|sbj_ID=='612d5712d75b6c46b4cefc63'|sbj_ID=='5e82e99b37d333a1474dda93'|sbj_ID=='613d091096ca434d703f77c5'|sbj_ID=='609568823ff056b77e565445'|sbj_ID=='5e80c7d61a07dd7b0d8f0111'|sbj_ID=='59aaf4b1321f870001d16f6c'|sbj_ID=='6048158f62550615002408af'|sbj_ID=='6161f43ddd46e845e7b3fab8'|sbj_ID=='5ec806f532fe7d2afa2e315b'|sbj_ID=='5e99d95e0f50aa04266ad4ad'|sbj_ID=='5c5e04ca6539fe00016e1afa');
# pilot 4.1
scores_list <- combineCols(data_pilot4.1_BLP, cols=c('L1Score','L2Score','L3Score','L4Score'),by_name=TRUE); # combine scores into 1 list
library(toolbox);
# pilot 4.1
scores_list <- combineCols(data_pilot4.1_BLP, cols=c('L1Score','L2Score','L3Score','L4Score'),by_name=TRUE); # combine scores into 1 list
data_pilot4.1_BLP$temp_sbjID <- c(1:20); # necessary: R doesn't like format of Prolific IDs
# multilingual balance: variance
vars <- list();
for (i in 1:20) { # calculate variance for each participant
temp <- unlist(scores_list[i]);
var <- var(temp,na.rm=TRUE);
vars <- append(vars, var)
};
data_pilot4.1_BLP$lang_var <- vars;
data_pilot4.1_BLP$lang_var <- as.numeric(data_pilot4.1_BLP$lang_var);
plot(data_pilot4.1_BLP$temp_sbjID,data_pilot4.1_BLP$lang_var,pch=19,xlab="Subject number",ylab="Language score variance",ylim=c(0,13000),cex.lab=1.5,yaxs="i");
# multilingual balance: entropy
entropies <- list();
library(DescTools);
for (i in 1:20) { # calculate entropy for each participant
temp <- unlist(scores_list[i]);
entropy <- Entropy(temp,na.rm=TRUE);
entropies <- append(entropies, entropy)
};
data_pilot4.1_BLP$lang_ent <- entropies;
data_pilot4.1_BLP$lang_ent <- as.numeric(data_pilot4.1_BLP$lang_ent);
plot(data_pilot4.1_BLP$temp_sbjID,data_pilot4.1_BLP$lang_ent,pch=19,xlab="Subject number",ylab="Language score entropy",cex.lab=1.5,ylim=c(0.7,2),yaxs="i");
# corr of variance & entropy
cor(unlist(data_pilot4.1_BLP$lang_var),unlist(data_pilot4.1_BLP$lang_ent),method="pearson"); # r = -0.89 so strongly negatively correlated
# multilingual experience: summing all language scores
data_pilot4.1_BLP["L2Score"][is.na(data_pilot4.1_BLP["L2Score"])] <- 0;
data_pilot4.1_BLP["L3Score"][is.na(data_pilot4.1_BLP["L3Score"])] <- 0;
data_pilot4.1_BLP["L4Score"][is.na(data_pilot4.1_BLP["L4Score"])] <- 0;
data_pilot4.1_BLP$multi_exp <- data_pilot4.1_BLP$L1Score + data_pilot4.1_BLP$L2Score + data_pilot4.1_BLP$L3Score + data_pilot4.1_BLP$L4Score;
plot(data_pilot4.1_BLP$temp_sbjID,data_pilot4.1_BLP$multi_exp,pch=19,xlab="Subject number",ylab="Amount of total multilingual experience (out of 872)",ylim=c(0,872),cex.lab=1.5,yaxs="i");
# L1 - L2 score
data_pilot4.1_BLP$L1_L2_diff <- data_pilot4.1_BLP$L1Score - data_pilot4.1_BLP$L2Score;
plot(data_pilot4.1_BLP$temp_sbjID,data_pilot4.1_BLP$L1_L2_diff,pch=19,xlab="Subject number",ylab="Score difference of L1 and L2",cex.lab=1.5,ylim=c(0,218),yaxs="i");
# corr of variance & accuracy
cor(data_pilot4.1_testing_means$x, data_pilot4.1_BLP$lang_var); # r = -0.01
plot(data_pilot4.1_BLP$lang_var, data_pilot4.1_testing_means$x, xlab="Language score variance", ylab="Testing accuracy (in %)", pch=19);
# corr of entropy & accuracy
cor(data_pilot4.1_testing_means$x, data_pilot4.1_BLP$lang_ent); # r = 0.12
plot(data_pilot4.1_BLP$lang_ent, data_pilot4.1_testing_means$x, xlab="Language score entropy", ylab="Testing accuracy (in %)", cex.lab=1.5,pch=19);
text(1.6,40,"Pearson's r = 0.12",cex=1.5);
# corr of multilingual experience & accuracy
cor(data_pilot4.1_testing_means$x, data_pilot4.1_BLP$multi_exp); # r = 0.05
# corr of L1-L2 score & accuracy
cor(data_pilot4.1_testing_means$x, data_pilot4.1_BLP$L1_L2_diff); # r = -0.15
# remove datapoints if participant doesn't know additional languages
data_pilot4.1_BLP$langfilter1 <- TRUE;
data_pilot4.1_BLP$langfilter2 <- TRUE;
data_pilot4.1_BLP$langfilter3 <- TRUE;
data_pilot4.1_BLP$langfilter4 <- TRUE;
data_pilot4.1_BLP$langfilter2[data_pilot4.1_BLP$L2Score==0] <- FALSE;
data_pilot4.1_BLP$langfilter3[data_pilot4.1_BLP$L3Score==0] <- FALSE;
data_pilot4.1_BLP$langfilter4[data_pilot4.1_BLP$L4Score==0] <- FALSE;
data_pilot4.1_BLP$L2Score[data_pilot4.1_BLP$langfilter2==FALSE] <- NA;
data_pilot4.1_BLP$L3Score[data_pilot4.1_BLP$langfilter3==FALSE] <- NA;
data_pilot4.1_BLP$L4Score[data_pilot4.1_BLP$langfilter4==FALSE] <- NA;
ok2 <- ! is.na(data_pilot4.1_BLP$L2Score);
ok3 <- ! is.na(data_pilot4.1_BLP$L3Score);
ok4 <- ! is.na(data_pilot4.1_BLP$L4Score);
# plot language scores per participant
plot(data_pilot4.1_BLP$L1Score~data_pilot4.1_BLP$temp_sbjID,ylab="Language Score",ylim=c(0,230),xlab="Participant",main="",pch=19,cex=2,cex.lab=1.5,col=cols[1],xaxt="n",yaxs="i");
axis(1, at = c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20));
points(data_pilot4.1_BLP$L2Score~data_pilot4.1_BLP$temp_sbjID,subset=ok2,pch=19,cex=2,col=cols[2]);
points(data_pilot4.1_BLP$L3Score~data_pilot4.1_BLP$temp_sbjID,subset=ok2,pch=19,cex=2,col=cols[3]);
points(data_pilot4.1_BLP$L4Score~data_pilot4.1_BLP$temp_sbjID,subset=ok2,pch=19,cex=2,col=cols[4]);
legend("bottomright",title="Language:",c("L1","L2","L3","L4"),fill=c(cols[1],cols[2],cols[3],cols[4]),bty = "n",
cex=1,y.intersp=0.5);
abline(h=218, lty=5);
# pilot 4.2
scores_list <- combineCols(data_pilot4.2_BLP, cols=c('L1Score','L2Score','L3Score','L4Score'),by_name=TRUE); # combine scores into 1 list
data_pilot4.2_BLP$temp_sbjID <- c(1:20) # necessary: R doesn't like format of Prolific IDs
# multilingual balance: variance
vars <- list();
for (i in 1:20) { # calculate variance for each participant
temp <- unlist(scores_list[i]);
var <- var(temp,na.rm=TRUE);
vars <- append(vars, var)
};
data_pilot4.2_BLP$lang_var <- vars;
data_pilot4.2_BLP$lang_var <- as.numeric(data_pilot4.2_BLP$lang_var);
plot(data_pilot4.2_BLP$temp_sbjID,data_pilot4.2_BLP$lang_var,pch=19,xlab="Subject number",ylab="Language score variance",ylim=c(0,13000),cex.lab=1.5,yaxs="i");
# multilingual balance: entropy
entropies <- list();
library(DescTools);
for (i in 1:20) { # calculate entropy for each participant
temp <- unlist(scores_list[i]);
entropy <- Entropy(temp,ra.rm=TRUE);
entropies <- append(entropies, entropy)
};
data_pilot4.2_BLP$lang_ent <- entropies;
data_pilot4.2_BLP$lang_ent <- as.numeric(data_pilot4.2_BLP$lang_ent);
plot(data_pilot4.2_BLP$temp_sbjID,data_pilot4.2_BLP$lang_ent,pch=19,xlab="Subject number",ylab="Language score entropy",cex.lab=1.5,ylim=c(0.7,2),yaxs="i");
# corr of variance & entropy
cor(unlist(data_pilot4.2_BLP$lang_var),unlist(data_pilot4.2_BLP$lang_ent),method="pearson"); # r = -0.94 so strongly negatively correlated
# multilingual experience: summing all language scores
data_pilot4.2_BLP["L2Score"][is.na(data_pilot4.2_BLP["L2Score"])] <- 0;
data_pilot4.2_BLP["L3Score"][is.na(data_pilot4.2_BLP["L3Score"])] <- 0;
data_pilot4.2_BLP["L4Score"][is.na(data_pilot4.2_BLP["L4Score"])] <- 0;
data_pilot4.2_BLP$multi_exp <- data_pilot4.2_BLP$L1Score + data_pilot4.2_BLP$L2Score + data_pilot4.2_BLP$L3Score + data_pilot4.2_BLP$L4Score;
plot(data_pilot4.2_BLP$temp_sbjID,data_pilot4.2_BLP$multi_exp,pch=19,xlab="Subject number",ylab="Amount of total multilingual experience (out of 872)",ylim=c(0,872),cex.lab=1.5,yaxs="i");
# L1 - L2 score
data_pilot4.2_BLP$L1_L2_diff <- data_pilot4.2_BLP$L1Score - data_pilot4.2_BLP$L2Score;
plot(data_pilot4.2_BLP$temp_sbjID,data_pilot4.2_BLP$L1_L2_diff,pch=19,xlab="Subject number",ylab="Score difference of L1 and L2",ylim=c(0,218),cex.lab=1.5,yaxs="i");
# corr of variance & accuracy
cor(data_pilot4.2_testing_means$x, data_pilot4.2_BLP$lang_var); # r = -0.35
plot(data_pilot4.2_BLP$lang_var, data_pilot4.2_testing_means$x, xlab="Language score variance", ylab="Testing accuracy (in %)", pch=19);
text(1.9,40,"Pearson's r = -0.35",cex=1.5);
# corr of entropy & accuracy
cor(data_pilot4.2_testing_means$x, data_pilot4.2_BLP$lang_ent); # r = 0.40
plot(data_pilot4.2_BLP$lang_ent, data_pilot4.2_testing_means$x, xlab="Language score entropy", ylab="Testing accuracy (in %)",cex.lab=1.5, pch=19);
text(1.6,40,"Pearson's r = 0.40",cex=1.5);
# corr of multilingual experience & accuracy
cor(data_pilot4.2_testing_means$x, data_pilot4.2_BLP$multi_exp); # r = 0.44
plot(data_pilot4.2_BLP$multi_exp, data_pilot4.2_testing_means$x, xlab="Amount of multilingual experience", ylab="Testing accuracy (in %)", pch=19);
text(475,40,"Pearson's r = 0.44");
# corr of L1-L2 score & accuracy
cor(data_pilot4.2_testing_means$x, data_pilot4.2_BLP$L1_L2_diff) # r = -0.25
plot(data_pilot4.2_BLP$L1_L2_diff, data_pilot4.2_testing_means$x, xlab="Difference between L1 and L2 score", ylab="Testing accuracy (in %)", pch=19)
text(100,40,"Pearson's r = -0.25");
# remove datapoints if participant doesn't know additional languages
data_pilot4.2_BLP$langfilter1 <- TRUE;
data_pilot4.2_BLP$langfilter2 <- TRUE;
data_pilot4.2_BLP$langfilter3 <- TRUE;
data_pilot4.2_BLP$langfilter4 <- TRUE;
data_pilot4.2_BLP$langfilter2[data_pilot4.2_BLP$L2Score==0] <- FALSE;
data_pilot4.2_BLP$langfilter3[data_pilot4.2_BLP$L3Score==0] <- FALSE;
data_pilot4.2_BLP$langfilter4[data_pilot4.2_BLP$L4Score==0] <- FALSE;
data_pilot4.2_BLP$L2Score[data_pilot4.2_BLP$langfilter2==FALSE] <- NA;
data_pilot4.2_BLP$L3Score[data_pilot4.2_BLP$langfilter3==FALSE] <- NA;
data_pilot4.2_BLP$L4Score[data_pilot4.2_BLP$langfilter4==FALSE] <- NA;
ok2 <- ! is.na(data_pilot4.2_BLP$L2Score);
ok3 <- ! is.na(data_pilot4.2_BLP$L3Score);
ok4 <- ! is.na(data_pilot4.2_BLP$L4Score);
# plot language scores per participant
plot(data_pilot4.2_BLP$L1Score~data_pilot4.2_BLP$temp_sbjID,ylab="Language Score",ylim=c(0,230),xlab="Participant",main="",pch=19,cex=2,cex.lab=1.5,col=cols[1],xaxt="n",yaxs="i");
axis(1, at = c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20));
points(data_pilot4.2_BLP$L2Score~data_pilot4.2_BLP$temp_sbjID,subset=ok2,pch=19,cex=2,col=cols[2]);
points(data_pilot4.2_BLP$L3Score~data_pilot4.2_BLP$temp_sbjID,subset=ok2,pch=19,cex=2,col=cols[3]);
points(data_pilot4.2_BLP$L4Score~data_pilot4.2_BLP$temp_sbjID,subset=ok2,pch=19,cex=2,col=cols[4]);
legend("bottomright",title="Language:",c("L1","L2","L3","L4"),fill=c(cols[1],cols[2],cols[3],cols[4]),bty = "n",
cex=1,y.intersp=0.5);
abline(h=218,lty=5)
# correlation of full pilot 4 data
entropy_4.1 <- data.frame(data_pilot4.1_BLP$sbj_ID);
entropy_4.1$lang_ent <- data_pilot4.1_BLP$lang_ent;
colnames(entropy_4.1)[colnames(entropy_4.1)=="data_pilot4.1_BLP.sbj_ID"]="sbj_ID";
entropy_4.2 <- data.frame(data_pilot4.2_BLP$sbj_ID);
entropy_4.2$lang_ent <- data_pilot4.2_BLP$lang_ent;
colnames(entropy_4.2)[colnames(entropy_4.2)=="data_pilot4.2_BLP.sbj_ID"]="sbj_ID";
all_entropy <- rbind(entropy_4.1, entropy_4.2);
colnames(data_pilot4_testing_means)[colnames(data_pilot4_testing_means)=="Group.1"]="sbj_ID";
data_pilot4_testing_means <- data_pilot4_testing_means[order(data_pilot4_testing_means[,'sbj_ID']),];
all_entropy <- all_entropy[order(all_entropy[,"sbj_ID"]),];
data_pilot4_entacc <- merge(data_pilot4_testing_means,all_entropy,by="sbj_ID")
cor(data_pilot4_entacc$x, data_pilot4_entacc$lang_ent); # 0.21
plot(data_pilot4_entacc$lang_ent, data_pilot4_entacc$x, xlab="Language score entropy", ylab="Testing accuracy (in %)", pch=19);
text(1.9,40,"Pearson's r = 0.21")

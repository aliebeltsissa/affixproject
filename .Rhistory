data_testing_2M_yes <- aggregate(data_testing$observed[data_testing$testing_condition=='2M'], by=list(data_testing$sbj_ID[data_testing$testing_condition=='2M']), FUN = function(x) sum(x == 'within_lang'));
names(data_testing_2M_yes) <- c("sbj_ID","yes_2M");
data_testing_2M_yes$yes_2M <- data_testing_2M_yes$yes_2M/total_2M*100; #transform into percent
summary(data_testing_2M_yes$yes_2M);
#min:11.8 Q1:55.9 med:64.7 mean:64.0 Q3:73.5 max:100
t.test(data_testing_2M_yes$yes_2M, mu=50);
#t=13.5 p<2.2-16 CI=[62.00;66.07] -> sig above chance
boxplot(data_testing_2M_yes$yes_2M, ylab = "2M Percent of 'yes' responses",ylim=c(0,100),yaxs="i");
abline(h=50, lty=5);
data_testing <- merge(data_testing,data_testing_2M_yes,by="sbj_ID");
data_testing_2M_aggr <- data_testing %>%
mutate(correct01 = case_when(correct == TRUE ~ 1,
correct == FALSE ~ 0),
yesno01 = case_when(observed == 'between_lang' ~ 0,
observed == 'within_lang' ~ 1)) %>%
filter(testing_condition == '2M') %>%
group_by(expected, sbj_ID) %>%
dplyr::summarise(meanCorrect = mean(correct01), se = sd(correct01/sqrt(n())),
meanYes = mean(yesno01), se = sd(yesno01/sqrt(n()))) %>%
mutate(meanNo = 1 - meanYes)
ggplot(data_testing_2M_aggr, aes(x=expected, y=meanCorrect)) +
geom_boxplot();
ggplot(data_testing_2M_aggr, aes(x=expected, y=meanYes)) +
geom_boxplot();
ggplot(data_testing_2M_aggr, aes(x=expected, y=meanNo)) +
geom_boxplot();
ggplot(data_testing_2M_aggr, aes(x=expected, y=meanCorrect, fill=expected)) +
geom_hline(yintercept=0.5, linetype="dashed",
color = "darkgray",lwd=1.25) +
geom_violin(alpha=0.75) +
geom_boxplot(width=0.1) +
scale_fill_manual(values=c(cols2[100],cols2[200]),
name="String nature",labels=c("Between-language","Within-language")) +
labs(x = "String nature", y = 'Proportion of correct responses') +
scale_x_discrete(labels=c("Between-language", "Within-language")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
axis.text = element_text(family = "CMU Serif", size = 20, color = "black"),
text=element_text(family="CMU Serif",size=20),
legend.position = "none");
ggplot(data_testing_2M_aggr, aes(x=expected, y=meanYes, fill=expected)) +
geom_hline(yintercept=0.5, linetype="dashed",
color = "darkgray",lwd=1.25) +
geom_violin(alpha=0.75) +
geom_boxplot(width=0.1) +
scale_fill_manual(values=c(cols2[100],cols2[200]),
name="String nature",labels=c("Between-language","Within-language")) +
labs(x = "String nature", y = 'Proportion of "yes" responses') +
scale_x_discrete(labels=c("Between-language", "Within-language")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
axis.text = element_text(family = "CMU Serif", size = 20, color = "black"),
text=element_text(family="CMU Serif",size=20),
legend.position = "none");
ggplot(data_testing_2M_aggr, aes(x=expected, y=meanNo, fill=expected)) +
geom_hline(yintercept=0.5, linetype="dashed",
color = "darkgray",lwd=1.25) +
geom_violin(alpha=0.75) +
geom_boxplot(width=0.1) +
scale_fill_manual(values=c(cols2[100],cols2[200]),
name="String nature",labels=c("Between-language","Within-language")) +
labs(x = "String nature", y = 'Proportion of "no" responses') +
scale_x_discrete(labels=c("Between-language", "Within-language")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
axis.text = element_text(family = "CMU Serif", size = 20, color = "black"),
text=element_text(family="CMU Serif",size=20),
legend.position = "none");
# 2M scores
data_testing_2M_means <- aggregate(data_testing$correct[data_testing$testing_condition=='2M'], list(data_testing$sbj_ID[data_testing$testing_condition=='2M']), FUN=mean, na.rm=TRUE);
names(data_testing_2M_means) <- c("sbj_ID","score_2M");
par(mar=c(2,5,2,2));
boxplot(data_testing_2M_means$score_2M, ylab = "2M accuracy score",yaxs="i",
family="CMU Serif",ylim=c(0,1),cex.lab=2,cex.axis=1.75,width=2);
abline(h=0.5, lty=5);
par(mar=c(5, 4, 4, 2) + 0.1) # back to default
summary(data_testing_2M_means$score_2M);
#min:0.26 Q1:0.44 med:0.50 mean:0.50 Q3:0.56 max:0.71
var(data_testing_2M_means$score_2M); #var=0.006
plot(data_testing_2M_means$score_2M,pch=3,ylim=c(0,1));
abline(h=0.5, lty=5); # clustered around chance
hist(data_testing_2M_means$score_2M); # normally distributed
t.test(data_testing_2M_means$score_2M, mu=0.50);
#t=-0.83 p=0.41 CI=[0.48;0.51] df = 192 -> not sig different from chance
data_testing <- merge(data_testing,data_testing_2M_means,by="sbj_ID");
# d' computations
data_testing_2M <- data_testing[data_testing$testing_condition == '2M',];
data_testing_2M$expected_bi[data_testing_2M$expected == "between_lang"] <- 0;
data_testing_2M$expected_bi[data_testing_2M$expected == "within_lang"] <- 1;
data_testing_2M$observed_bi[data_testing_2M$observed == "between_lang"] <- 0;
data_testing_2M$observed_bi[data_testing_2M$observed == "within_lang"] <- 1;
dprimes2M <- dPrime(data_testing_2M$sbj_ID, data_testing_2M$expected_bi, data_testing_2M$observed_bi);
names(dprimes2M) <- c("sbj_ID","dprime","log_beta","c");
summary(dprimes2M);
# mean(d') = -0.02, mean(c) = -0.37
data_testing <- merge(data_testing,dprimes2M,by="sbj_ID");
cor.test(data_testing$dprime,data_testing$c,method="pearson");
### "YES" responses across conditions ################################
# evaluating the differences between conditions
data_testing_conditions <- merge(data_testing_0M_yes,data_testing_1M_yes, by='sbj_ID');
data_testing_conditions <- merge(data_testing_conditions,data_testing_2M_yes, by='sbj_ID');
par(mar=c(5, 5, 4, 2) + 0.1)
boxplot(data_testing_conditions$yes_0M,data_testing_conditions$yes_1M,data_testing_conditions$yes_2M, ylab='Percent of "yes" responses', xlab="Condition", names=c('0M','1M','2M'),ylim=c(0,100),yaxs="i",cex.lab=2,cex.axis=1.75);
abline(h=50, lty=5);
par(mar=c(5, 4, 4, 2) + 0.1) # back to default
conditions_table <- table(data_testing$testing_condition, data_testing$observed);
chisq.test(conditions_table);
# X-squared=308, df=2, p<2.2e-16
data_testing_conditions <- data_testing_conditions %>%
gather(condition, score, -sbj_ID);
data_testing_conditions$score <- data_testing_conditions$score/100;
# plotting all "yes" responses across conditions
ggplot(data_testing_conditions, aes(x = condition, y = score, color = condition)) +
geom_hline(yintercept=0.5, linetype="dashed",
color = "darkgray",lwd=1.25) +
geom_jitter(width = 0.1, height = 0, alpha = 0.3,color= "black",size=2) +
labs(x = "Condition", y = 'Proportion of "yes" responses') +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
axis.text = element_text(family = "CMU Serif", size = 28, color = "black"),
text=element_text(family="CMU Serif",size=28)) +
scale_y_continuous(expand = c(0, 0),breaks=seq(0,1,0.2)) +
expand_limits(y = 1.05) +
stat_summary(geom = "point",fun = "mean",col = "red",size = 4,shape = 19) +
stat_summary(geom = "errorbar", fun.data = "mean_se", width = 0.1,col="red",position = position_dodge(width = 0.5)) +
scale_x_discrete(labels=c("0M", "1M", "2M"));
# 2M accuracy*RTs
cor.test(data_testing_2M_means$score_2M, data_testing_rt_means$x, method="pearson"); # r = 0.04 ()
plot(data_testing_2M_means$score_2M~data_testing_rt_means$x,
xlab="Reaction times (ms)",ylab="2M score",pch=19);
# strategies used
strats <- subset(data_testing, select = c(sbj_ID, strategy));
strats <- strats[!duplicated(strats),];
write.csv(strats,"BASL_exp1_strats.csv", row.names = FALSE)
# those having used chunks
chunkID_strategists <- list('5caccaed2f93d700157b4782','5e577e79ce30ae13226e61ae','5e8c57d9b4483e012006e7aa','5eaae42f19a24d05cbd6ccb4','5ecbb4c00bc62403dae2df59','5ee942381a22491bbb7170f8','5f18a80367ef6b0bbc5f3720','5f5a713d37f71112463ab4d9','5fc2d2d79da439201ab6addc','600f0f9c3bfcdc077c924e51','60123adc24c9f126819861b6','601705a0246e51313e8ed38e','601ffb441dc6d959b855eea5','60491025dd8eb31e48a0ca8d','60664619eac28843177fee96','60db4aed5dd7b87124f51341','60f6b8f8e574e14634ead43e','60fd0f49858465796afd5da9','6144742e57a61e489cc9e978','61520b079436973e05f72d33','615b1ab789b14c9996251fb4','615da9ee365ab7d547b98979','616891e25a026e1f7262116c','63ee5d8aaee278de46b7d4cc','6455490f7c5f35e4221a810a');
data_chunkIDstrategists <- data_testing[data_testing$sbj_ID %in% chunkID_strategists,];
boxplot(data_chunkIDstrategists$score_2M, ylab = "Accuracy score (in %)");
abline(h=0.5, lty=5);
summary(data_chunkIDstrategists$score_2M);
# min:0.32 Q1:0.47 med:0.50 mean:0.52 Q3:0.56 max:0.71
t.test(data_chunkIDstrategists$score_2M, mu=0.50);
#t=10.87 p<2.2e-16 CI=[0.51;0.52] -> sig different from chance
summary(data_chunkIDstrategists$dprime);
summary(data_chunkIDstrategists$c);
# those having used their intuition
intuition_strategists <- list('5aa787c66219a30001c765f8','5ae5db897edeb000014a85ee','5b213220809d160001a2c36d','5bcd11401662020001fe82c1','5c1bfabab0fcc900019d9ff4','5dab6e7d80e1780016d5bc9b','5dcb33ab0550ef819f508abf','5e12048c7605fe8839180a14','5e3ff59bf2160b23942ada93','5e89e89bf025be000c01eead','5e8e55509422bb10abed1f54','5e9bd025eb6b380e1d66d04c','5ea9611edec14d052ada0bae','5ea9cd383b32cf15448a86ac','5eaf1c50f3540c614eb973a5','5eb35dff41a381156be161c2','5ec6d06c67b0da0fb6f85e83','5ecd21dec04cca02c9032485','5ed013f88fce6e0d858b732e','5ee623674afa60375e30eec3','5ee83da8817af0000d47448f','5f0471a92ec97b6d1aec7739','5f0d65ef2ad0c60009209f0f','5f11c9f84078cd0888177499','5f18a80367ef6b0bbc5f3720','5f19fa0f3e85b20d0336258c','5f1e8dc7e2161c86cdcd220a','5f219602670e5a0af2cf5237','5f47e34858dd331165bf9f00','5f5e7de4c81d3672642cd612','5f708f5f0d32bb66960d4473','5f858743256d25036d9fa693','5f91dc284909fe0b08f9e2e1','5fa5793490f10705755818c0','5fa59d4d5a29c90da975efe9','5fc44d83862e3e79b02e0438','5fc781689771f106330abf6a','5fd2416e5061f30735e202e9','5fd9c5c67fa7c74ec42bb318','5fe2308a91773957e88b89be','600e0dadada7da69afc5b3de','6042a56575ab0c1ccffc3152','605aa0bb5fb71bbcf0808892','60645fe61129208791535d15','606dc21c1ce7dc64af9d81fb','608858869a591bd129fbbc6c','60957b300f08087b0af0031c','60a3fe2d888e7a090d6d8f82','60a68725b2b424dc0d7ce793','60bbe0da43325dadf2b1b6a9','60d7605d7af8d66774061717','60dee3200c7c3355c62326d9','60ec51c51a3158a50ded8a3e','60f030dca19a06db1b50d16a','6100174f92a7a0e5141b195e','61001b6892ebd05a24fe82e1','610f2eabb45be8717fc155e0','61125e23136464bd2cbbefc9','611bdb0fed7c9df6dce28c3f','611cebb780fbae98c5bcc84d','611e9c16e90a0d4c6f0d8df5','611eeafa283a2d1f57537fea','6131f7010e926c9103558040','613867f34e206e4f573bc6ef','613a73d06cf1fcfef304d3fa','6140ff9c5750f0081ca8d71f','614c80483d06dcf7ad552679','614c8e5469405530dc27b9d5','614dd6473c74b217ad73cc9c','6155e204cc071b306458dfff','6156a440279fdf408ee663ae','6156b68cc77b48d6693b361c','61616ce2bb94584e11c911af','6170821d1e8ffb9c893b28a4','6171349b89a54d4823f9eca1','617142c2a843eef6f8f148b6','6171d922c871ba795b6a4827','6172078b966225960be2a7b5','65032a60861e9a17bc1a7444','65089e7ce53888b0b3840c62');
data_intuitionstrategists <- data_testing[data_testing$sbj_ID %in% intuition_strategists,];
boxplot(data_intuitionstrategists$score_2M, ylab = "Accuracy score (in %)");
abline(h=0.5, lty=5);
summary(data_intuitionstrategists$score_2M);
# min:0.26 Q1:0.46 med:0.50 mean:0.49 Q3:0.56 max:0.62
t.test(data_intuitionstrategists$score_2M, mu=0.50);
#t=-9.94 p<2.2e-16 CI=[0.491;0.494] -> sig different from chance
summary(data_intuitionstrategists$dprime);
summary(data_intuitionstrategists$c);
# FAMILIARITY --------------------------------------------------------
data_all_familiarity <- read.csv("exp1_familiarity_preprocessed.csv",header=T,sep=",");
data_all_familiarity <- subset(data_all_familiarity, select = -c(X)) # remove redundant column added by Pavlovia
data_familiarity <- data_all_familiarity[data_all_familiarity$sbj_ID %in% participants,]; # n = 187 participants
data_familiarity <- data_familiarity[!data_familiarity$sbj_ID %in% c('615b042301e3a24311563ee4','5e8b66490d48450346bf2755','615b41767003d4ece749ed9d'),];
# make some variables factors
data_familiarity$sbj_ID <- as.factor(data_familiarity$sbj_ID);
data_familiarity$task <- as.factor(data_familiarity$task);
data_familiarity$correct <- as.logical(data_familiarity$correct);
data_familiarity$target <- as.factor(data_familiarity$target);
data_familiarity$confound <- as.factor(data_familiarity$confound);
# familiarity accuracy boxplot
data_familiarity_means <- aggregate(data_familiarity$correct, list(data_familiarity$sbj_ID), FUN=mean);
colnames(data_familiarity_means)[colnames(data_familiarity_means)=="Group.1"]="sbj_ID";
par(mar=c(2,5,2,2));
boxplot(data_familiarity_means$x, ylab = "Familiarity score",ylim=c(0,1),
cex.lab=2,cex.axis=1.75,yaxs="i",width=2);
abline(h=0.5, lty=5);
par(mar=c(5, 4, 4, 2) + 0.1); # back to default
summary(data_familiarity_means$x);
# min:0.29 Q1:0.50 med:0.57 mean:0.57 Q3:0.64 max:0.86
hist(data_familiarity_means$x); # mostly normally distributed
t.test(data_familiarity_means$x, mu=0.50);
# t=9.16, p<2.2e-16, CI = [0.55;0.58] -> sig above chance
var(data_familiarity_means$x); #var = 0.01
# familiarity accuracy violin plot
ggplot(data_familiarity_means, aes(x="score", y=x, fill="score")) +
geom_hline(yintercept=0.5, linetype="dashed",
color = "darkgray",lwd=1.25) +
geom_violin(alpha=0.75) +
geom_boxplot(width=0.1) +
ylim(0,1) +
scale_fill_manual(values=cols2[350]) +
labs(y = 'Proportion of correct familiarity responses') +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
axis.text = element_text(family = "CMU Serif", size = 20, color = "black"),
text=element_text(family="CMU Serif",size=20),
legend.position = "none",
axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank());
# familiarity RTs
IDs <- list(data_familiarity$sbj_ID);
IDs <- sapply(IDs, unique);
plot(density(data_familiarity$rt[data_familiarity$sbj_ID==IDs[1]]),xlim=c(0,4000),ylim=c(0,0.01),xlab="Familiarity RTs (ms)",main="",xaxt = "n",col=cols2[1],lwd=2,yaxs="i");
axis(1, at = c(0,500,1000,1500,2000,2500,3000,3500,4000));
for (x in 2:193) {
lines(density(data_familiarity$rt[data_familiarity$sbj_ID==IDs[x]]),col=cols2[x],lwd=2)
};
data_familiarity_rt_means <- aggregate(data_familiarity$rt, list(data_familiarity$sbj_ID), FUN=mean, na.rm=TRUE);
summary(data_familiarity_rt_means$x);
# familiarity accuracy*RTs
cor.test(data_familiarity_means$x, data_familiarity_rt_means$x, method="pearson") # r = 0.20
# slower at responding = better accuracy
plot(data_familiarity_rt_means$x, data_familiarity_means$x, xlab="Mean participant RT (in ms)", ylab="Mean participant familiarity score (in %)", pch=19, cex=2, cex.lab=1.45);
# familiarity accuracy*testing accuracy
cor.test(data_familiarity_means$x, data_testing_2M_means$score_2M, method="pearson"); # r = 0.11
# familiarity accuracy by testing strategy
data_strategistsfam <- data_familiarity_means;
data_strategistsfam$strat[data_strategistsfam$sbj_ID %in% intuition_strategists] <- 'intuition';
data_strategistsfam$strat[data_strategistsfam$sbj_ID %in% chunkID_strategists] <- 'chunks';
data_strategistsfam$strat[data_strategistsfam$sbj_ID %in% chunkID_strategists] <- 'chunks';
data_strategistsfam$strat <- data_strategistsfam$strat %>% replace_na('other');
boxplot(data_strategistsfam$x[data_strategistsfam$strat=='chunks'],ylab = "Familiarity score (chunk strategists)",ylim=c(0,1),cex.lab=2,cex.axis=1.75,yaxs="i");
abline(h=0.5, lty=5);
summary(data_strategistsfam$x[data_strategistsfam$strat=='chunks']);
# min:0.46 Q1:0.54 med:0.57 mean:0.58 Q3:0.61 max:0.75
t.test(data_strategistsfam$x[data_strategistsfam$strat=='chunks'],mu=0.50);
boxplot(data_strategistsfam$x[data_strategistsfam$strat=='intuition'],ylab = "Familiarity score (intuition strategists)",ylim=c(0,1),cex.lab=2,cex.axis=1.75,yaxs="i");
abline(h=0.5, lty=5);
summary(data_strategistsfam$x[data_strategistsfam$strat=='intuition']);
# min:0.29 Q1:0.50 med:0.57 mean:0.55 Q3:0.64 max:0.79
t.test(data_strategistsfam$x[data_strategistsfam$strat=='intuition'],mu=0.50);
par(mar=c(5,5,2,2));
boxplot(data_strategistsfam$x~data_strategistsfam$strat,ylab = "Familiarity score",xlab="Testing strategy",ylim=c(0.28,0.9),cex.lab=2,cex.axis=1.75,yaxs="i");
abline(h=0.5, lty=5);
par(mar=c(5, 4, 4, 2) + 0.1); # back to default
# BLP ----------------------------------------------------------------
data_all_BLP <- read.csv("exp1_BLP_preprocessed.csv",header=T,sep=",");
data_all_BLP <- subset(data_all_BLP, select = -c(X)); # remove redundant column added by Pavlovia
data_BLP <- data_all_BLP[data_all_BLP$sbj_ID %in% participants,]; # n = 190 participants
data_BLP <- subset(data_BLP, select = -c(AoAgioL1, AoAgioL2, AoAgioL3, AoAgioL4, anniInstrL1, anniInstrL2, anniInstrL3, anniInstrL4, anniPaeseL1, anniPaeseL2, anniPaeseL3, anniPaeseL4, anniFamigliaL1, anniFamigliaL2, anniFamigliaL3, anniFamigliaL4, anniLavoroL1, anniLavoroL2, anniLavoroL3, anniLavoroL4, PercAmiciL1, PercAmiciL2, PercAmiciL3, PercAmiciL4, PercFamigliaL1, PercFamigliaL2, PercFamigliaL3, PercFamigliaL4, PercLavoroL1, PercLavoroL2, PercLavoroL3, PercLavoroL4, PercStessoL1, PercStessoL2, PercStessoL3, PercStessoL4, PercCalcoliL1, PercCalcoliL2, PercCalcoliL3, PercCalcoliL4, ProfParlaL1, ProfParlaL2, ProfParlaL3, ProfParlaL4, ProfCapisceL1, ProfCapisceL2, ProfCapisceL3, ProfCapisceL4, ProfLeggeL1, ProfLeggeL2, ProfLeggeL3, ProfLeggeL4, ProfScriveL1, ProfScriveL2, ProfScriveL3, ProfScriveL4, AttMiStessoL1, AttMiStessoL2, AttMiStessoL3, AttMiStessoL4, AttCulturaL1, AttCulturaL2, AttCulturaL3, AttCulturaL4, AttLivNativoL1, AttLivNativoL2, AttLivNativoL3, AttLivNativoL4, AttMadrelinguaL1, AttMadrelinguaL2, AttMadrelinguaL3, AttMadrelinguaL4));
data_BLP <- data_BLP[!data_BLP$sbj_ID %in% c('615b042301e3a24311563ee4','5e8b66490d48450346bf2755','615b41767003d4ece749ed9d'),];
BLP_correction <- function(data_BLP)
{
data_BLP[data_BLP == "polish"|data_BLP == "POLISH"] <- "Polish";
data_BLP[data_BLP == "english"|data_BLP=="ENGLISH"|data_BLP=="Englsih"|data_BLP=="Englsh"|data_BLP=="British"|data_BLP=="Engllish"|data_BLP=="ENGLISH "|data_BLP=="English "|data_BLP=="ENGLISH"|data_BLP=="english"|data_BLP=="english "|data_BLP=="englis"|data_BLP=="eanglish"|data_BLP=="Enlish"] <- "English";
data_BLP[data_BLP == "portuguese"|data_BLP == "portuguese"|data_BLP == "Portugal"|data_BLP=="Potuguese"] <- "Portuguese";
data_BLP[data_BLP =="SPANISH"|data_BLP=="Spnsh"|data_BLP=="spanish"] <- "Spanish";
data_BLP[data_BLP == "ITALIAN"|data_BLP=="italian"] <- "Italian";
data_BLP[data_BLP == "sotho"] <- "Sotho";
data_BLP[data_BLP == "greek"|data_BLP=="Greece"] <- "Greek";
data_BLP[data_BLP == "tshivenda"] <- "Tshivenda";
data_BLP[data_BLP == "Gujrau"] <- "Gujarati"; # to check
data_BLP[data_BLP == "ukrainian"|data_BLP=="ukranian"] <- "Ukrainian";
data_BLP[data_BLP == "SETSWANA"] <- "Setswana";
data_BLP[data_BLP == "afrikaans"] <- "Afrikaans";
data_BLP[data_BLP == "punjabi"] <- "Punjabi";
data_BLP[data_BLP == "siswati"] <- "Siswati";
data_BLP[data_BLP == "Germany"|data_BLP=="german"|data_BLP=="germany"|data_BLP=="GERMANY"|data_BLP=="GERMAN"|data_BLP=="Deustch"|data_BLP == "Deutch"] <- "German";
data_BLP[data_BLP == "russian"] <- "Russian";
data_BLP[data_BLP == "Isiulu"] <- "IsiZulu";
data_BLP[data_BLP == "ZULU"|data_BLP=="zulu"] <- "Zulu";
data_BLP[data_BLP == "northern sotho"] <- "Northern Sotho";
data_BLP[data_BLP == "chinese"] <- "Chinese";
data_BLP[data_BLP == "sesotho"|data_BLP=="SESOTHO"] <- "Sesotho";
data_BLP[data_BLP == "sepedi"] <- "Sepedi";
data_BLP[data_BLP == "TSHIVENDA"] <- "Tshivenda";
data_BLP[data_BLP == "arabic"] <- "Arabic";
data_BLP[data_BLP == "XHOSA"|data_BLP=="xhosa"] <- "Xhosa";
data_BLP[data_BLP == "french"|data_BLP=="fRANCH"] <- "French";
data_BLP[data_BLP == "hungarian"] <- "Hungarian";
data_BLP[data_BLP == "POLISH"] <- "Polish";
data_BLP[data_BLP == "croatian"] <- "Croatian";
data_BLP[data_BLP == "bosnian"] <- "Bosnian";
data_BLP[data_BLP == "madarin"] <- "Mandarin";
data_BLP[data_BLP == "Icelandic and German"] <- "Icelandic";
data_BLP[data_BLP == "a little bit of russian"|data_BLP=="RUSSIAN"|data_BLP=="russian"] <- "Russian";
data_BLP[data_BLP == "NDEBELE"] <- "Ndebele";
data_BLP[data_BLP == "urdu"] <- "Urdu";
data_BLP[data_BLP == "latvian"] <- "Latvian";
data_BLP[data_BLP == "Malayam"] <- "Malayan";
data_BLP[data_BLP == "swahili"] <- "Swahili";
data_BLP[data_BLP == "serbian"] <- "Serbian";
data_BLP[data_BLP == "SEPEDI"|data_BLP=="sepedit"] <- "Sepedi";
data_BLP[data_BLP == "japanese"] <- "Japanese";
data_BLP[data_BLP == "TSWANA"|data_BLP=="tswana"] <- "Tswana";
data_BLP[data_BLP == "SHONA"] <- "Shona";
data_BLP[data_BLP == "sweedish"] <- "Swedish";
data_BLP[data_BLP == "XItsonga"] <- "Xitsonga";
data_BLP[data_BLP == "N/A"|data_BLP=="---"] <- "n/a";
data_BLP["L1"][is.na(data_BLP["L1"])] <- "n/a";
data_BLP["L2"][is.na(data_BLP["L2"])] <- "n/a";
data_BLP["L3"][is.na(data_BLP["L3"])] <- "n/a";
data_BLP["L4"][is.na(data_BLP["L4"])] <- "n/a";
# correcting some participants' demographic information - correction based off of Prolific's information
data_BLP["Age"][data_BLP["sbj_ID"] == "5aa787c66219a30001c765f8"] <- "24";
data_BLP["Age"][data_BLP["sbj_ID"] == "5e577e79ce30ae13226e61ae"] <- "24";
data_BLP["Age"][data_BLP["sbj_ID"] == "5e8c57d9b4483e012006e7aa"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "5ecbb4c00bc62403dae2df59"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "5ee942381a22491bbb7170f8"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "5f219602670e5a0af2cf5237"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "5f47e34858dd331165bf9f00"] <- "21";
data_BLP["Age"][data_BLP["sbj_ID"] == "5f99cee5a2a7d109a1624e10"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "5fa4725a186c050edc3bcc20"] <- "23";
data_BLP["Age"][data_BLP["sbj_ID"] == "5fc2d2d79da439201ab6addc"] <- "24";
data_BLP["Age"][data_BLP["sbj_ID"] == "5fc44d83862e3e79b02e0438"] <- "24";
data_BLP["Age"][data_BLP["sbj_ID"] == "5fd9c5c67fa7c74ec42bb318"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "6065d7d47409810344f7e6bb"] <- "24";
data_BLP["Age"][data_BLP["sbj_ID"] == "60883a7e91c0be66dbb96fc8"] <- "23";
data_BLP["Age"][data_BLP["sbj_ID"] == "608c2e566d92c2aa3543e2d2"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "60e3b18d3d4205b4c52ada56"] <- "24";
data_BLP["Age"][data_BLP["sbj_ID"] == "611eafa6011b0423f7d7230f"] <- "20";
data_BLP["Age"][data_BLP["sbj_ID"] == "612a98181f4b6d1cf01f926c"] <- "21";
data_BLP["Age"][data_BLP["sbj_ID"] == "61301fcb49db2f170cb02b93"] <- "25";
data_BLP["Age"][data_BLP["sbj_ID"] == "6156b68cc77b48d6693b361c"] <- "21";
data_BLP["Age"][data_BLP["sbj_ID"] == "616891e25a026e1f7262116c"] <- "22";
data_BLP["Age"][data_BLP["sbj_ID"] == "6171d922c871ba795b6a4827"] <- "23";
data_BLP["Gender"][data_BLP["sbj_ID"] == "5aa787c66219a30001c765f8"] <- "Man";
data_BLP["Gender"][data_BLP["sbj_ID"] == "5bcd11401662020001fe82c1"] <- "Man";
data_BLP["Gender"][data_BLP["sbj_ID"] == "5e3ff59bf2160b23942ada93"] <- "Man";
data_BLP["Gender"][data_BLP["sbj_ID"] == "5f5a713d37f71112463ab4d9"] <- "Woman";
data_BLP["Gender"][data_BLP["sbj_ID"] == "60e9ea97d19e613e60a994da"] <- "Man";
data_BLP["Gender"][data_BLP["sbj_ID"] == "616eb493bb7e4ab4fa1de8d4"] <- "Woman";
return (data_BLP)
}
data_BLP <- BLP_correction(data_BLP);
# make some variables factors
data_BLP$task <- as.factor(data_BLP$task)
data_BLP$sbj_ID <- as.factor(data_BLP$sbj_ID);
data_BLP$Age <- as.numeric(data_BLP$Age);
data_BLP$Gender <- as.factor(data_BLP$Gender);
data_BLP$Education <- as.factor(data_BLP$Education);
data_BLP$L1 <- as.factor(data_BLP$L1);
data_BLP$L2 <- as.factor(data_BLP$L2);
data_BLP$L3 <- as.factor(data_BLP$L3);
data_BLP$L4 <- as.factor(data_BLP$L4);
data_BLP$otherLs <- as.factor(data_BLP$otherLs);
data_BLP$AttentionL1 <- as.factor(data_BLP$AttentionL1);
data_BLP$AttentionL2 <- as.factor(data_BLP$AttentionL2);
data_BLP$AttentionL3 <- as.factor(data_BLP$AttentionL3);
data_BLP$AttentionL4 <- as.factor(data_BLP$AttentionL4);
summary(data_BLP);
scores_list <- subset(data_BLP, select=c('sbj_ID','L1Score','L2Score','L3Score','L4Score')); # combine scores into 1 list
write.csv(scores_list,"BASL_exp1_scores.csv", row.names = FALSE);
use_scores_list <- subset(data_BLP, select=c('sbj_ID','UseL1Score','UseL2Score','UseL3Score','UseL4Score')); # combine use scores into 1 list
write.csv(use_scores_list,"BASL_exp1_usescores.csv", row.names = FALSE);
# correlations of BLP scores
BLP_scores <- subset(data_BLP,select=c(HistoryL1Score,HistoryL2Score,HistoryL3Score,HistoryL4Score,
UseL1Score,UseL2Score,UseL3Score,UseL4Score,
ProficiencyL1Score,ProficiencyL2Score,ProficiencyL3Score,ProficiencyL4Score,
AttitudeL1Score,AttitudeL2Score,AttitudeL3Score,AttitudeL4Score));
png('exp1_corrPlot_BLP.png', width=1000, height=1000);
corrplot::corrplot(cor(BLP_scores),type="lower", order="original", diag=T, method="color", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black',number.cex=1.5,tl.cex=1.5);
dev.off();
png('exp1_corrPlot_BLP_hclust.png', width=1000, height=1000);
corrplot::corrplot(cor(BLP_scores),type="lower", order="hclust", diag=T, method="color", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=1.5,tl.cex=1.5);
dev.off();
# BLP scores PCA
pca_varimax <- psych::principal(BLP_scores, nfactors=16, rotate='varimax');
data_BLP <- cbind(data_BLP, pca_varimax$scores[,c('RC1','RC9','RC2','RC8','RC3')]);
colnames(data_BLP)[which(names(data_BLP) == "RC1")] <- "RC1_L3";
colnames(data_BLP)[which(names(data_BLP) == "RC9")] <- "RC9_L4";
colnames(data_BLP)[which(names(data_BLP) == "RC2")] <- "RC2_use_L1vsL2";
colnames(data_BLP)[which(names(data_BLP) == "RC8")] <- "RC8_hist_L2"
colnames(data_BLP)[which(names(data_BLP) == "RC3")] <- "RC3_prof_L2"
## Multilingual scores ===============================================
multilingual_metrics <- data.frame();
for (i in 1:193) {
temp <- scores_list[which(scores_list$sbj_ID==unique(scores_list$sbj_ID)[i]),];
sbj_ID <- temp$sbj_ID[1];
temp_scores <- as.list(temp);
temp_scores <- temp_scores[-1];
temp_scores <- unlist(temp_scores);
use_temp <- use_scores_list[which(use_scores_list$sbj_ID==unique(use_scores_list$sbj_ID)[i]),];
use_temp_scores <- as.list(use_temp);
use_temp_scores <- use_temp_scores[-1];
use_temp_scores <- unlist(use_temp_scores);
# variance
variance <- var(temp_scores,na.rm=TRUE);
# entropy
entropy <- Entropy(temp_scores,na.rm=TRUE);
use_entropy <- Entropy(use_temp_scores,na.rm=TRUE);
# multilingual experience
multiexp <- sum(temp_scores);
# L1 - L2 score
L1L2 <- abs(temp_scores[[1]]-temp_scores[[2]]);
multilingual_metrics <- rbind(multilingual_metrics,
list(sbj_ID,variance,entropy,use_entropy,multiexp,L1L2));
};
names(multilingual_metrics) <- c("sbj_ID","var","ent","use_ent","multiexp","L1_L2_diff");
data_BLP <- merge(data_BLP,multilingual_metrics,by="sbj_ID");
# import cosine similarity scores
cossim <- read.csv("distances_exp1_NOLOWSCORES.csv",header=T,sep=",");
cossim <- subset(cossim, select = -c(X)); # remove redundant column added by Python
names(cossim) <- c('sbj_ID','cossim');
data_BLP <- merge(data_BLP,cossim,by="sbj_ID");
use_cossim <- read.csv("distances_exp1_usescores.csv",header=T,sep=",");
use_cossim <- subset(use_cossim, select = -c(X)); # remove redundant column added by Python
names(use_cossim) <- c('sbj_ID','use_cossim');
data_BLP <- merge(data_BLP,use_cossim,by="sbj_ID");
# multilingual category
data_BLP$category <- "mono";
data_BLP$category[data_BLP$L2Score>0] <- "bi";
data_BLP$category[data_BLP$L3Score>0] <- "tri";
data_BLP$category[data_BLP$L4Score>0] <- "quadri";
data_BLP$category <- factor(data_BLP$category,levels=c("mono","bi","tri","quadri"));
summary(data_BLP);
# same-script vs different-script multilinguals
diff_script_sbjID <- c('5cbe02ab39447e0001745a5e','5e3ff59bf2160b23942ada93','6147aed5b2a4f748dc2b6ba4');
# n=3
mixed_script_sbjID <- c('5ea171c1a8782801263e7540','5ea9611edec14d052ada0bae','5eb35dff41a381156be161c2','5f0f93938935de000855898b','5f7bd801486f5e1ce581980f','5fc2d2d79da439201ab6addc','5fc44d83862e3e79b02e0438','5fd9c5c67fa7c74ec42bb318','600f0f9c3bfcdc077c924e51','602bb123612bfe330818d4ef','6093cacf9a39751eedd55916','61055020201a7da5a704f7dd','611bdb0fed7c9df6dce28c3f','6163faf9d9ac4586fe776568','616eb493bb7e4ab4fa1de8d4','63ee5d8aaee278de46b7d4cc','64ef422a4789bd6b6b9042ce');
# n=17
sbj_IDs_included <- list(unique(data_BLP$sbj_ID))[[1]];
sbj_IDs_included <- as.character(sbj_IDs_included);
same_script_sbjID <- sbj_IDs_included[!sbj_IDs_included %in% diff_script_sbjID];
same_script_sbjID <- same_script_sbjID[!same_script_sbjID %in% mixed_script_sbjID];
# n=173
data_BLP$script[data_BLP$sbj_ID %in% same_script_sbjID] <- 'same';
data_BLP$script[data_BLP$sbj_ID %in% mixed_script_sbjID] <- 'mixed/diff';
data_BLP$script[data_BLP$sbj_ID %in% diff_script_sbjID] <- 'mixed/diff';
data_BLP$script <- factor(data_BLP$script,levels=c("same","mixed/diff"));
# looking at each metric individually
#var
summary(data_BLP$var);
#min=452, Q1=5659, med=7727, mean=7209, Q3=9172, max=11570
var(data_BLP$var);
#var = 6580066
plot(data_BLP$var,pch=19);
#ent
summary(data_BLP$ent);
#min=0, Q1=0.95, med=1.32, mean=1.29, Q3=1.58, max=1.99
var(data_BLP$ent);
#var = 0.18
plot(data_BLP$ent,pch=19);
cor.test(data_BLP$var,data_BLP$ent,method="pearson");
#use_ent
summary(data_BLP$use_ent);
#min=0, Q1=0.65, med=0.96, mean=0.94, Q3=1.28, max=1.95
var(data_BLP$use_ent);
#var = 0.17
plot(data_BLP$use_ent,pch=19);
#multiexp
summary(data_BLP$multiexp);
#min=167, Q1=310 med=351, mean=368, Q3=425, max=592
var(data_BLP$multiexp);
#var = 6460
plot(data_BLP$multiexp,pch=19);
#L1_L2_diff
summary(data_BLP$L1_L2_diff);
#min=0.09, Q1=52, med=78, mean=76, Q3=97, Q4=208
var(data_BLP$L1_L2_diff);
#var = 1724
plot(data_BLP$L1_L2_diff,pch=19);
#cossim
summary(data_BLP$cossim);
#min=0.86, Q1=0.92, med=0.95, mean=0.95, Q3=0.97, max=1
var(data_BLP$cossim);
#var = 0.001
plot(data_BLP$cossim,pch=19);
#use_cossim
summary(data_BLP$use_cossim);
#min=0.63, Q1=0.76, med=0.82, mean=0.83, Q3=0.88, max=1
var(data_BLP$use_cossim);
#var = 0.007
plot(data_BLP$use_cossim,pch=19);
#ent & multiexp
par(mar=c(5,5,2,2));
plot(data_BLP$ent,data_BLP$multiexp,pch=19,yaxs="i",
ylab="Multilingual experience",xlab="Entropy",
cex.lab=1.5);
cor.test(data_BLP$ent,data_BLP$multiexp,method="pearson");
# t = 37.295, df = 191, p-value < 2.2e-16, CI=[0.92;0.95], est=0.94 (***)
text(0.25,500,"r = 0.94",cex=1.5);
#cossim & multiexp
plot(data_BLP$cossim,data_BLP$multiexp,pch=19,yaxs="i",
ylab="Multilingual experience",xlab="Cosine similarity",
cex.lab=1.5);
cor.test(data_BLP$cossim,data_BLP$multiexp,method="pearson");
# t = -1.6814, df = 191, p-value = 0.09432, CI=[-0.26;0.02], est=-0.12 ()
text(0.87,550,"r = -0.12",cex=1.5);
#ent & use_ent
plot(data_BLP$ent,data_BLP$use_ent,pch=19,
ylab="Use entropy",xlab="Entropy",cex.lab=1.5);
abline(a=0,b=1, col = "blue",lwd=2);
cor.test(data_BLP$ent,data_BLP$use_ent,method="pearson");
# t = 15.149, df = 191, p-value < 2.2e-16, CI=[0.67;0.80], est=0.74 (***)
text(0.25,1.75,"r = 0.74",cex=1.5);
# correlations of multilingual metrics
M <- cor(subset(data_BLP,select=c('var','ent','use_ent','multiexp','L1_L2_diff','cossim','use_cossim')));
png('exp1_corrPlot_multimetrics.png', width=1000, height=1000);
corrplot::corrplot(M,type="lower", order="original", diag=T, method="color", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black',number.cex=1.5,tl.cex=1.5);
dev.off();
png('exp1_corrPlot_multimetrics_hclust.png', width=1000, height=1000);
corrplot::corrplot(M,type="lower", order="hclust", diag=T, method="color", outline=F, addgrid.col=F, tl.col='black', tl.pos='ld', addCoef.col='black', number.cex=1.5,tl.cex=1.5);
dev.off();
# export BLP dataframe
write.csv(data_BLP,"BASL_exp1_BLP.csv", row.names = FALSE);
## COMBINING BLP & TESTING SCORES ====================================
data_BLP_shortened <- subset(data_BLP, select=c(sbj_ID,Gender,Age,
HistoryL1Score,HistoryL2Score,HistoryL3Score,HistoryL4Score,
UseL1Score,UseL2Score,UseL3Score,UseL4Score,
ProficiencyL1Score,ProficiencyL2Score,ProficiencyL3Score,ProficiencyL4Score,
AttitudeL1Score,AttitudeL2Score,AttitudeL3Score,AttitudeL4Score,
L1Score,L2Score,L3Score,L4Score,category,script,
var,ent,use_ent,multiexp,L1_L2_diff,cossim,use_cossim,
RC1_L3,RC9_L4,RC2_use_L1vsL2,RC8_hist_L2,RC3_prof_L2));
data_BLP_testing <- list(data_testing,data_BLP_shortened) %>% reduce(inner_join, by='sbj_ID');
data_BLP_familiarity <- list(data_familiarity,data_BLP_shortened) %>% reduce(inner_join, by='sbj_ID');
# correlations of BLP metrics with testing scores
M <- cor(subset(data_BLP_testing,select=c(score_2M,dprime,c,
var,ent,use_ent,multiexp,L1_L2_diff,cossim,use_cossim,
RC1_L3,RC9_L4,RC2_use_L1vsL2,RC8_hist_L2,RC3_prof_L2)));
lm_Age <- glmer(observed ~ scale(trialn) + testing_condition*scale(Age) + (1+testing_condition|sbj_ID), data=subset(data_BLP_testing, rt>300 & rt<3000), family='binomial');
summary(lm_Age);

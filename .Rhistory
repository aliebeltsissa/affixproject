ncol = 1, nrow = 2)
bi<-data.frame(Mean=c(84.07,38.69,52.41,69.66),
sd=c(2.27,3.26,3.11,2.45),
Type=as.factor(c("Cognate","Control","Interlingual Homophone","Semantic")),
Category=c("Cognate","Control","Interlingual Homophone","Semantic"),
Insert= c(0.0, 0.1, 0.5, 1))
bi<-data.frame(Mean=c(84.07,38.69,52.41,69.66),
sd=c(2.27,3.26,3.11,2.45),
Type=as.factor(c("Cognate","Control","Interlingual Homophone","Semantic")),
Category=c("Cognate","Control","Interlingual Homophone","Semantic"),
Insert= c(0.0, 0.1, 0.5, 1))
bi2<-ggplot(bi, aes(x=Category, y=Mean, fill=Category)) +
geom_bar(position=position_dodge(), stat="identity",
colour='black') +
geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2) +
scale_fill_manual(values=c("#696969", "#808080", "#a9a9a9", "#DCDCDC")) +
theme(text = element_text(family = "serif")) +
labs(y="Scores", title="Bilinguals") +
theme(legend.position = "none") +
theme(axis.title.x = element_blank()) +
theme(axis.text.x = element_text(size = 12)) +
theme(plot.title = element_text(size = 14)) +
theme(plot.title = element_text(hjust = 0.5)) +
ylim(0, 100)
bi2
mono<-data.frame(Mean=c(79.83,47.13,57.39,49.83),
sd=c(3.26,2.73,2.31,2.29),
Type=as.factor(c("Cognate","Control","Interlingual Homophone","Semantic")),
Category=c("Cognate","Control","Interlingual Homophone","Semantic"),
Insert= c(0.0, 0.1, 0.5, 1))
mono2 <- ggplot(mono, aes(x=Category, y=Mean, fill=Category)) +
geom_bar(position=position_dodge(), stat="identity",
colour='black') +
geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2) +
scale_fill_manual(values=c("#696969", "#808080", "#a9a9a9", "#DCDCDC")) +
theme(text = element_text(family = "serif")) +
labs(y="Scores", title="Monolinguals") +
theme(legend.position = "none") +
theme(axis.title.x = element_blank()) +
theme(axis.text.x = element_text(size = 12)) +
theme(plot.title = element_text(size = 14)) +
theme(plot.title = element_text(hjust = 0.5)) +
ylim(0, 100)
ggarrange(bi2, mono2,
ncol = 1, nrow = 2)
cog<-data.frame(Mean=c(72.72,72.03),
sd=c(2.46,2.50),
Type=as.factor(c("Bilingual","Monolingual")),
Category=c("Bilingual","Monolingual"),
Insert= c(0.0, 0.5))
cog2 <- ggplot(cog, aes(x=Category, y=Mean, fill=Category)) +
geom_bar(position=position_dodge(), stat="identity",
colour='black') +
geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2) +
scale_fill_manual(values=c("#999999", "#646464")) +
theme(text = element_text(family = "serif")) +
labs(y="Scores", title="Cognate condition") +
theme(legend.position = "none") +
theme(axis.title.x = element_blank()) +
theme(axis.text.x = element_text(size = 12)) +
theme(plot.title = element_text(size = 14)) +
theme(plot.title = element_text(hjust = 0.5)) +
ylim(0, 100)
con<-data.frame(Mean=c(50.93,50.02),
sd=c(3.13,3.56),
Type=as.factor(c("Bilingual","Monolingual")),
Category=c("Bilingual","Monolingual"),
Insert= c(0.0, 0.5))
con2 <- ggplot(con, aes(x=Category, y=Mean, fill=Category)) +
geom_bar(position=position_dodge(), stat="identity",
colour='black') +
geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2) +
scale_fill_manual(values=c("#999999", "#646464")) +
theme(text = element_text(family = "serif")) +
labs(y="Scores", title="Control condition") +
theme(legend.position = "none") +
theme(axis.title.x = element_blank()) +
theme(axis.text.x = element_text(size = 12)) +
theme(plot.title = element_text(size = 14)) +
theme(plot.title = element_text(hjust = 0.5)) +
ylim(0, 100)
int<-data.frame(Mean=c(60.07,59.55),
sd=c(2.68,2.82),
Type=as.factor(c("Bilingual","Monolingual")),
Category=c("Bilingual","Monolingual"),
Insert= c(0.0, 0.5))
int2 <- ggplot(int, aes(x=Category, y=Mean, fill=Category)) +
geom_bar(position=position_dodge(), stat="identity",
colour='black') +
geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2) +
scale_fill_manual(values=c("#999999", "#646464")) +
theme(text = element_text(family = "serif")) +
labs(y="Scores", title="Interlingual Homophone condition") +
theme(legend.position = "none") +
theme(axis.title.x = element_blank()) +
theme(axis.text.x = element_text(size = 12)) +
theme(plot.title = element_text(size = 14)) +
theme(plot.title = element_text(hjust = 0.5)) +
ylim(0, 100)
sem<-data.frame(Mean=c(66.62,2.57),
sd=c(51.28,3.32),
Type=as.factor(c("Bilingual","Monolingual")),
Category=c("Bilingual","Monolingual"),
Insert= c(0.0, 0.5))
sem2 <- ggplot(sem, aes(x=Category, y=Mean, fill=Category)) +
geom_bar(position=position_dodge(), stat="identity",
colour='black') +
geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2) +
scale_fill_manual(values=c("#999999", "#646464")) +
theme(text = element_text(family = "serif")) +
labs(y="Scores", title="Semantic condition") +
theme(legend.position = "none") +
theme(axis.title.x = element_blank()) +
theme(axis.text.x = element_text(size = 12)) +
theme(plot.title = element_text(size = 14)) +
theme(plot.title = element_text(hjust = 0.5)) +
ylim(0, 100)
ggarrange(cog2, con2, int2, sem2,
ncol = 2, nrow = 2)
sem<-data.frame(Mean=c(66.62,51.28),
sd=c(2.57,3.32),
Type=as.factor(c("Bilingual","Monolingual")),
Category=c("Bilingual","Monolingual"),
Insert= c(0.0, 0.5))
sem2 <- ggplot(sem, aes(x=Category, y=Mean, fill=Category)) +
geom_bar(position=position_dodge(), stat="identity",
colour='black') +
geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2) +
scale_fill_manual(values=c("#999999", "#646464")) +
theme(text = element_text(family = "serif")) +
labs(y="Scores", title="Semantic condition") +
theme(legend.position = "none") +
theme(axis.title.x = element_blank()) +
theme(axis.text.x = element_text(size = 12)) +
theme(plot.title = element_text(size = 14)) +
theme(plot.title = element_text(hjust = 0.5)) +
ylim(0, 100)
ggarrange(cog2, con2, int2, sem2,
ncol = 2, nrow = 2)
bi<-data.frame(Mean=c(72.72,50.93,60.07,66.62),
sd=c(2.46,3.13,2.68,2.57),
Type=as.factor(c("Cognate","Control","Interlingual Homophone","Semantic")),
Category=c("Cognate","Control","Interlingual Homophone","Semantic"),
Insert= c(0.0, 0.1, 0.5, 1))
bi2<-ggplot(bi, aes(x=Category, y=Mean, fill=Category)) +
geom_bar(position=position_dodge(), stat="identity",
colour='black') +
geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2) +
scale_fill_manual(values=c("#696969", "#808080", "#a9a9a9", "#DCDCDC")) +
theme(text = element_text(family = "serif")) +
labs(y="Scores", title="Bilinguals") +
theme(legend.position = "none") +
theme(axis.title.x = element_blank()) +
theme(axis.text.x = element_text(size = 12)) +
theme(plot.title = element_text(size = 14)) +
theme(plot.title = element_text(hjust = 0.5)) +
ylim(0, 100)
mono<-data.frame(Mean=c(72.03,50.02,59.55,51.28),
sd=c(2.50,3.56,2.82,3.32),
Type=as.factor(c("Cognate","Control","Interlingual Homophone","Semantic")),
Category=c("Cognate","Control","Interlingual Homophone","Semantic"),
Insert= c(0.0, 0.1, 0.5, 1))
mono2 <- ggplot(mono, aes(x=Category, y=Mean, fill=Category)) +
geom_bar(position=position_dodge(), stat="identity",
colour='black') +
geom_errorbar(aes(ymin=Mean-sd, ymax=Mean+sd), width=.2) +
scale_fill_manual(values=c("#696969", "#808080", "#a9a9a9", "#DCDCDC")) +
theme(text = element_text(family = "serif")) +
labs(y="Scores", title="Monolinguals") +
theme(legend.position = "none") +
theme(axis.title.x = element_blank()) +
theme(axis.text.x = element_text(size = 12)) +
theme(plot.title = element_text(size = 14)) +
theme(plot.title = element_text(hjust = 0.5)) +
ylim(0, 100)
ggarrange(bi2, mono2,
ncol = 1, nrow = 2)
summary3<-read.csv("C:/Users/annal/OneDrive - University of Sussex/School/2021-2022/Spring term - 4th year project/Data/SummaryAnalysisByParticipant3.csv")
attach(summary3)
str(summary3)
summary3 <- summary3 %>%
gather(key = "condition", value = "scores", CogDiffCon, IntDiffCon, SemDiffCon) %>%
convert_as_factor(Participant.External.Session.ID, condition)
res.aov <- aov(scores ~ condition, data = summary3)
summary4 <- summary4 %>%
gather(key = "langexp", value = "exp", Eng_yearsused, Fr_yearsused, Eng_hoursspeaking, Fr_hoursspeaking) %>%
convert_as_factor(Participant.External.Session.ID, langexp)
summary4<-read.csv("C:/Users/annal/OneDrive - University of Sussex/School/2021-2022/Spring term - 4th year project/Data/SummaryAnalysisByParticipant4.csv")
attach(summary4)
str(summary4)
summary4 <- summary4 %>%
gather(key = "condition", value = "scores", CognateLogOdds, ControlLogOdds, InterlingualHomophoneLogOdds, SemanticLogOdds) %>%
convert_as_factor(Participant.External.Session.ID, condition)
summary4 <- summary4 %>%
gather(key = "langexp", value = "exp", Eng_yearsused, Fr_yearsused, Eng_hoursspeaking, Fr_hoursspeaking) %>%
convert_as_factor(Participant.External.Session.ID, langexp)
res.aov <- summary4 %>%
anova_test(scores ~ langexp + condition)
get_anova_table(res.aov)
knitr::opts_chunk$set(echo = TRUE,
eval = TRUE,
warning = FALSE,
fig.path = "graphics/",
fig.width = 8,
fig.height = 4,
fig.retina = 2,
fig.align = "center",
fig.pos = "t",
collapse = TRUE
)
load("data/class5.RData");
library(lme4); #this is necessary for 'lmer'
library(rms); #this is necessary for 'rcs'
package.install(rms)
install.packages("rms")
library(rms); #this is necessary for 'rcs'
library(Hmisc)
install.packages("htmltools")
install.packages("htmltools")
knitr::opts_chunk$set(echo = TRUE,
eval = TRUE,
warning = FALSE,
fig.path = "graphics/",
fig.width = 8,
fig.height = 4,
fig.retina = 2,
fig.align = "center",
fig.pos = "t",
collapse = TRUE
)
load("data/class5.RData");
library(lme4); #this is necessary for 'lmer'
library(rms); #this is necessary for 'rcs'
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
remove.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
knitr::opts_chunk$set(echo = TRUE,
eval = TRUE,
warning = FALSE,
fig.path = "graphics/",
fig.width = 8,
fig.height = 4,
fig.retina = 2,
fig.align = "center",
fig.pos = "t",
collapse = TRUE
)
load("data/class5.RData");
library(lme4); #this is necessary for 'lmer'
library(rms); #this is necessary for 'rcs'
m4 <- lmer(rt ~ 1 + rcs(ticks,4)*condition + (1|sbjId) + (1|target), data=data_for_analysis);
summary(m4)[[10]]; #betas are quite crazy (high and low), and quite some variability. Lots of significance, but not easy to interpret. But wait before jumping there, let's check whether the non-linearity was worth it:
anova(m4,m3); #it does provide a nice improvement in goodness of fit, for the extra complexity that it costs (which is a lot, note -- 6 dfs)
#does the model fit the data better?
library(effects);
###########
# PILOT 4 #
###########
setwd("C:/Users/annal/OneDrive/Documents/GitHub/affixproject")
data_pilot4 <- read.csv("Prolific_preprocessed.csv",header=T,sep=",");
data_pilot4 = subset(data_pilot4, select = -c(X)) # remove redundant column added by Pavlovia
# standardise language responses
data_pilot4[data_pilot4 == "italiano" | data_pilot4 == "italiana" | data_pilot4 == "Italiano" | data_pilot4 == "Italiana"] <- "Italian";
data_pilot4[data_pilot4 == "portoghese" | data_pilot4 == "Portoghese" | data_pilot4 == "Portuguese"] <- "Portuguese";
data_pilot4[data_pilot4 == "Francese" | data_pilot4 == "francese"] <- "French";
data_pilot4[data_pilot4 == "inglese" | data_pilot4 == "Inglese"] <- "English";
data_pilot4[data_pilot4 == "Spagnolo" | data_pilot4 == "spagnolo"] <- "Spanish";
data_pilot4[data_pilot4 == "Bulgaro"] <- "Bulgarian";
data_pilot4[data_pilot4 == "Coreano"] <- "Korean";
data_pilot4[data_pilot4 == "Piemontese"] <- "Piedmontese";
data_pilot4[data_pilot4 == "napoletano"] <- "Neapolitan";
data_pilot4[data_pilot4 == "Dialetto di Carovigno"] <- "Carovignian dialect";
data_pilot4[data_pilot4 == "russo"] <- "Russian";
data_pilot4[data_pilot4 == "Cinese"] <- "Chinese";
data_pilot4[data_pilot4 == "tedesco" | data_pilot4 == "Tedesco"] <- "German"
# make some variables factors
data_pilot4$sbj_ID <- as.factor(data_pilot4$sbj_ID);
data_pilot4$task <- as.factor(data_pilot4$task);
data_pilot4$target <- as.factor(data_pilot4$target);
data_pilot4$confound <- as.factor(data_pilot4$confound);
data_pilot4$item <- as.factor(data_pilot4$item);
data_pilot4$correct <- as.logical(data_pilot4$correct);
data_pilot4$Sex <- as.factor(data_pilot4$Sex);
data_pilot4$Education <- as.factor(data_pilot4$Education);
data_pilot4$L1 <- as.factor(data_pilot4$L1);
data_pilot4$L2 <- as.factor(data_pilot4$L2);
data_pilot4$L3 <- as.factor(data_pilot4$L3);
data_pilot4$L4 <- as.factor(data_pilot4$L4);
data_pilot4$otherLs <- as.factor(data_pilot4$otherLs);
data_pilot4$AttentionL1 <- as.factor(data_pilot4$AttentionL1);
data_pilot4$AttentionL2 <- as.factor(data_pilot4$AttentionL2);
data_pilot4$AttentionL3 <- as.factor(data_pilot4$AttentionL3);
data_pilot4$AttentionL4 <- as.factor(data_pilot4$AttentionL4);
# boxplot of all pilot 4 testing data
data_pilot4_testing <- subset(data_pilot4, task=='testing',select=c(sbj_ID,task,trialn,expected,observed,correct,rt,item));
data_pilot4_testing_means <- aggregate(data_pilot4_testing$correct[complete.cases(data_pilot4_testing$correct)], list(data_pilot4_testing$sbj_ID[complete.cases(data_pilot4_testing$correct)]), FUN=sum);
data_pilot4_testing_means$x<-(data_pilot4_testing_means$x)*10/4;
View(data_pilot4_testing_means)
View(data_pilot4_testing_means)
# split into different pilot 4 versions: 4.1 is with 4 training reps, 4.1 is with 8
data_pilot4.1 <- subset(data_pilot4, sbj_ID=='5fb7b8880045d6396a86c803'|sbj_ID=='5f4cc4ea00dba58ecd5a98a4'|sbj_ID=='615c43b800752a4f3d0fd1f0'|sbj_ID=='6175a0a52e748285b3476b27'|sbj_ID=='60b55a6d44e17d6f0b810cdd'|sbj_ID=='60d87fdab51e54fe4863f97f'|sbj_ID=='60ba2011cd8052508d401296'|sbj_ID=='5ee7b7c9eef92207297a0ad4'|sbj_ID=='614060a52d7c64c27ef9887c'|sbj_ID=='5d97c38dce449e001244dc15'|sbj_ID=='5ed54d02957bee0c0de36cac'|sbj_ID=='61158a5c1d8390415ff117a8'|sbj_ID=='5e823b35726b2a9508db127c'|sbj_ID=='5caca6b4a9acb200011a6547'|sbj_ID=='5cf14e1eb4397d0001f94e20'|sbj_ID=='5cb4adc019ee7300189e8547'|sbj_ID=='5f3161410f87706425490ae1'|sbj_ID=='5e8783b0fde5153fbd9dca43'|sbj_ID=='60c9c6e1728092717b93abde'|sbj_ID=='5feb64b3341f42bb63200e36');
data_pilot4.2 <- subset(data_pilot4, sbj_ID=='60f1846c851ee5a978a0e015'|sbj_ID=='60fd703ecd62eb39eb07c328'|sbj_ID=='60ddf71e95896d2595f0e1a5'|sbj_ID=='605c9355001a5eb6d51e657d'|sbj_ID=='5f11ccbc1a1a2c08b4a99efb'|sbj_ID=='5fb3f38909fc360164f7c98d'|sbj_ID=='60a45e33f404ba8cb7a19cfe'|sbj_ID=='608abc6251feb3ddc3b2e01d'|sbj_ID=='608edc13472b2dbc27b369fa'|sbj_ID=='612d5712d75b6c46b4cefc63'|sbj_ID=='5e82e99b37d333a1474dda93'|sbj_ID=='613d091096ca434d703f77c5'|sbj_ID=='609568823ff056b77e565445'|sbj_ID=='5e80c7d61a07dd7b0d8f0111'|sbj_ID=='59aaf4b1321f870001d16f6c'|sbj_ID=='6048158f62550615002408af'|sbj_ID=='6161f43ddd46e845e7b3fab8'|sbj_ID=='5ec806f532fe7d2afa2e315b'|sbj_ID=='5e99d95e0f50aa04266ad4ad'|sbj_ID=='5c5e04ca6539fe00016e1afa');
# testing
data_pilot4.1_testing <- subset(data_pilot4.1, task=='testing',select=c(sbj_ID,task,trialn,expected,observed,correct,rt,item,testing_strategy));
# testing boxplot
data_pilot4.1_testing_means <- aggregate(data_pilot4.1_testing$correct, list(data_pilot4.1_testing$sbj_ID), FUN=sum); # this doesn't work
data_pilot4.1_testing_means$x <- (data_pilot4.1_testing_means$x)*10/4;
View(data_pilot4.1_testing_means)
View(data_pilot4.1_testing)
# testing boxplot
data_pilot4.1_testing_means <- aggregate(data_pilot4.1_testing$correct, list(data_pilot4.1_testing$sbj_ID), FUN=sum); # this doesn't work
View(data_pilot4.1_testing_means)
# testing boxplot
data_pilot4.1_testing_means <- aggregate(data_pilot4.1_testing$correct, list(data_pilot4.1_testing$sbj_ID), FUN=sum, na.action="NULL"); # this doesn't work
# testing boxplot
data_pilot4.1_testing_means <- aggregate(data_pilot4.1_testing$correct, list(data_pilot4.1_testing$sbj_ID), FUN=sum, na.rm=TRUE); # this doesn't work
View(data_pilot4.1_testing_means)
data_pilot4.1_testing_means$x <- (data_pilot4.1_testing_means$x)*10/4;
boxplot(data_pilot4.1_testing_means$x, ylab = "Accuracy score (in %)");
# testing RTs
library(paletteer);
cols <- paletteer_d("ggthemes::Classic_20");
IDs <- list(data_pilot4.1_testing$sbj_ID);
IDs <- sapply(IDs, unique);
# testing accuracy*RTs
cor(data_pilot4.1_testing$rt, data_pilot4.1_testing$correct)
data_pilot4.1_rt_means <- aggregate(data_pilot4.1_testing$rt, list(data_pilot4.1_testing$sbj_ID), FUN=mean, na.rm=TRUE);
View(data_pilot4.1_rt_means)
# testing accuracy*RTs
cor(data_pilot4.1_testing_means$x, data_pilot4.1_rt_means$x)
plot(data_pilot4.1_rt_means$x, data_pilot4.1_testing_means$x)
plot(data_pilot4.1_rt_means$x, data_pilot4.1_testing_means$x, pch=19)
plot(data_pilot4.1_rt_means$x, data_pilot4.1_testing_means$x, type="b", pch=19);
plot(data_pilot4.1_rt_means$x, data_pilot4.1_testing_means$x, pch=19);
data_pilot4.1_testing_rt_means <- aggregate(data_pilot4.1_testing$rt, list(data_pilot4.1_testing$sbj_ID), FUN=mean, na.rm=TRUE);
plot(data_pilot4.1_testing_rt_means$x, data_pilot4.1_testing_means$x, pch=19);
# familiarity
data_pilot4.1_familiarity <- subset(data_pilot4.1, task=='familiarity',select=c(sbj_ID,task,trialn,target,confound,expected,observed,correct,rt));
data_pilot4.1_familiarity_means <- aggregate(data_pilot4.1_familiarity$correct, list(data_pilot4.1_familiarity$sbj_ID), FUN=sum);
data_pilot4.1_familiarity_means$x<-(data_pilot4.1_familiarity_means$x)*10/3;
data_pilot4.1_familiarity_rt_means <- aggregate(data_pilot4.1_familiarity$rt, list(data_pilot4.1_familiarity$sbj_ID), FUN=mean, na.rm=TRUE);
# familiarity accuracy*RTs
cor(data_pilot4.1_familiarity_means$x, data_pilot4.1_familiarity_rt_means$x); # 0.16
plot(data_pilot4.1_familiarity_rt_means$x, data_pilot4.1_familiarity_means$x, pch=19);
# testing
data_pilot4.2_testing <- subset(data_pilot4.2, task=='testing',select=c(sbj_ID,task,trialn,expected,observed,correct,rt,item,testing_strategy));
# testing boxplot
data_pilot4.2_testing_means <- aggregate(data_pilot4.2_testing$correct, list(data_pilot4.2_testing$sbj_ID), FUN=sum, na.rm=TRUE);
data_pilot4.2_testing_means$x<-(data_pilot4.2_testing_means$x)*10/4;
boxplot(data_pilot4.2_testing_means$x, ylab = "Accuracy score (in %)");
# testing RTs
IDs <- list(data_pilot4.2_testing$sbj_ID);
IDs <- sapply(IDs, unique);
data_pilot4.2_testing_rt_means <- aggregate(data_pilot4.2_testing$rt, list(data_pilot4.2_testing$sbj_ID), FUN=mean, na.rm=TRUE);
# testing accuracy*RTs
cor(data_pilot4.2_testing_means$x, data_pilot4.2_testing_rt_means$x); # 0.16
plot(data_pilot4.2_testing_rt_means$x, data_pilot4.2_testing_means$x, pch=19);
data_pilot4.2_familiarity_rt_means <- aggregate(data_pilot4.2_familiarity$rt, list(data_pilot4.2_familiarity$sbj_ID), FUN=mean, na.rm=TRUE);
# familiarity
data_pilot4.2_familiarity <- subset(data_pilot4.2, task=='familiarity',select=c(sbj_ID,task,trialn,target,confound,expected,observed,correct,rt));
data_pilot4.2_familiarity_means <- aggregate(data_pilot4.2_familiarity$correct, list(data_pilot4.2_familiarity$sbj_ID), FUN=sum);
data_pilot4.2_familiarity_means$x<-(data_pilot4.2_familiarity_means$x)*10/3;
boxplot(data_pilot4.2_familiarity_means$x, ylab = "Familiarity score (in %)");
# familiarity RTs
IDs <- list(data_pilot4.2_familiarity$sbj_ID);
IDs <- sapply(IDs, unique);
data_pilot4.2_familiarity_rt_means <- aggregate(data_pilot4.2_familiarity$rt, list(data_pilot4.2_familiarity$sbj_ID), FUN=mean, na.rm=TRUE);
# familiarity accuracy*RTs
cor(data_pilot4.2_familiarity_means$x, data_pilot4.2_familiarity_rt_means$x); # 0.29
plot(data_pilot4.2_familiarity_rt_means$x, data_pilot4.2_familiarity_means$x, pch=19);
# BLP
data_pilot4.1_BLP <- subset(data_pilot4.1, task=='BLP',select=-c(trialn,target,confound,expected,observed,correct,rt,item));
# remove datapoints if participant doesn't know additional languages
data_pilot4.1_BLP$langfilter1 <- TRUE;
data_pilot4.1_BLP$langfilter2 <- TRUE;
data_pilot4.1_BLP$langfilter3 <- TRUE;
data_pilot4.1_BLP$langfilter4 <- TRUE;
data_pilot4.1_BLP$langfilter2[data_pilot4.1_BLP$L2Score==0] <- FALSE;
data_pilot4.1_BLP$langfilter3[data_pilot4.1_BLP$L3Score==0] <- FALSE;
data_pilot4.1_BLP$langfilter4[data_pilot4.1_BLP$L4Score==0] <- FALSE;
data_pilot4.1_BLP$L2Score[data_pilot4.1_BLP$langfilter2==FALSE] <- NA;
data_pilot4.1_BLP$L3Score[data_pilot4.1_BLP$langfilter3==FALSE] <- NA;
data_pilot4.1_BLP$L4Score[data_pilot4.1_BLP$langfilter4==FALSE] <- NA;
ok2 <- ! is.na(data_pilot4.1_BLP$L2Score);
ok3 <- ! is.na(data_pilot4.1_BLP$L3Score);
ok4 <- ! is.na(data_pilot4.1_BLP$L4Score);
# BLP
data_pilot4.1_BLP <- subset(data_pilot4.1, task=='BLP',select=-c(trialn,target,confound,expected,observed,correct,rt,item));
# plot language scores per participant
data_pilot4.1_BLP$temp_sbjID <- c(1:20) # necessary: R doesn't like format of Prolific IDs
# multilingual balance: variance
library(toolbox);
scores_list <- combineCols(data_pilot4.1_BLP, cols=c('L1Score','L2Score','L3Score','L4Score'),by_name=TRUE); # combine scores into 1 list
vars <- list();
for (i in 1:20) { # calculate variance for each participant
temp <- unlist(scores_list[i]);
var <- var(temp,na.rm=TRUE);
vars <- append(vars, var)
};
data_pilot4.1_BLP$lang_var <- vars;
as.numeric(data_pilot4.1_BLP$lang_var);
# multilingual balance: entropy
entropies <- list();
test <- c(1,2,3,4)
library(DescTools);
for (i in 1:20) { # calculate entropy for each participant
temp <- unlist(scores_list[i]);
entropy <- Entropy(table(temp,useNA = "no"))
entropies <- append(entropies, entropy)
};
data_pilot4.1_BLP$lang_ent <- entropies;
as.numeric(data_pilot4.1_BLP$lang_ent);
# corr of variance & entropy
cor(unlist(data_pilot4.1_BLP$lang_var),unlist(data_pilot4.1_BLP$lang_ent),method="pearson"); # r = -0.44 so moderately negatively correlated
# corr of variance & accuracy
cor(data_pilot4.1_testing_means, data_pilot4.1_BLP$lang_var)
is.numeric(data_pilot4.1_testing_means)
# corr of variance & accuracy
cor(data_pilot4.1_testing_means$x, data_pilot4.1_BLP$lang_var)
is.numeric(data_pilot4.1_BLP$lang_var)
typeof(data_pilot4.1_BLP$lang_var)
as.numeric(data_pilot4.1_BLP$lang_var);
# corr of variance & accuracy
cor(data_pilot4.1_testing_means$x, data_pilot4.1_BLP$lang_var)
data_pilot4.1_BLP$lang_var <- as.numeric(data_pilot4.1_BLP$lang_var);
# corr of variance & accuracy
cor(data_pilot4.1_testing_means$x, data_pilot4.1_BLP$lang_var)
data_pilot4.1_BLP$lang_ent <- as.numeric(data_pilot4.1_BLP$lang_ent);
# corr of entropy & accuracy
cor(data_pilot4.1_testing_means$x, data_pilot4.1_BLP$lang_ent) # -0.01
# multilingual experience: summing all language scores
data_pilot4.1_BLP["L2Score"][is.na(data_pilot4.1_BLP["L2Score"])] <- 0;
data_pilot4.1_BLP["L3Score"][is.na(data_pilot4.1_BLP["L3Score"])] <- 0;
data_pilot4.1_BLP["L4Score"][is.na(data_pilot4.1_BLP["L4Score"])] <- 0;
data_pilot4.1_BLP$multi_exp <- data_pilot4.1_BLP$L1Score + data_pilot4.1_BLP$L2Score + data_pilot4.1_BLP$L3Score + data_pilot4.1_BLP$L4Score;
# corr of multilingual experience & accuracy
cor(data_pilot4.1_testing_means$x, data_pilot4.1_BLP$multi_exp) # -0.01
# L1 - L2 score
data_pilot4.1_BLP$L1_L2_diff <- data_pilot4.1_BLP$L1Score - data_pilot4.1_BLP$L2Score;
# corr of L1-L2 score & accuracy
cor(data_pilot4.1_testing_means$x, data_pilot4.1_BLP$L1_L2_diff) # -0.01
# BLP
data_pilot4.2_BLP <- subset(data_pilot4.2, task=='BLP',select=-c(trialn,target,confound,expected,observed,correct,rt,item));
# plot language scores per participant
data_pilot4.2_BLP$temp_sbjID <- c(1:20) # necessary: R doesn't like format of Prolific IDs
# multilingual balance: variance
scores_list <- combineCols(data_pilot4.2_BLP, cols=c('L1Score','L2Score','L3Score','L4Score'),by_name=TRUE); # combine scores into 1 list
vars <- list();
for (i in 1:20) { # calculate variance for each participant
temp <- unlist(scores_list[i]);
var <- var(temp,na.rm=TRUE);
vars <- append(vars, var)
};
data_pilot4.2_BLP$lang_var <- vars;
data_pilot4.2_BLP$lang_var <- as.numeric(data_pilot4.2_BLP$lang_var);
# multilingual experience: summing all language scores
data_pilot4.2_BLP["L2Score"][is.na(data_pilot4.2_BLP["L2Score"])] <- 0;
data_pilot4.2_BLP["L3Score"][is.na(data_pilot4.2_BLP["L3Score"])] <- 0;
data_pilot4.2_BLP["L4Score"][is.na(data_pilot4.2_BLP["L4Score"])] <- 0;
data_pilot4.2_BLP$multi_exp <- data_pilot4.2_BLP$L1Score + data_pilot4.2_BLP$L2Score + data_pilot4.2_BLP$L3Score + data_pilot4.2_BLP$L4Score;
# L1 - L2 score
data_pilot4.2_BLP$L1_L2_diff <- data_pilot4.2_BLP$L1Score - data_pilot4.2_BLP$L2Score;
# multilingual balance: entropy
entropies <- list();
library(DescTools);
for (i in 1:20) { # calculate entropy for each participant
temp <- unlist(scores_list[i]);
entropy <- Entropy(table(temp,useNA = "no"))
entropies <- append(entropies, entropy)
};
# multilingual balance: variance
scores_list <- combineCols(data_pilot4.2_BLP, cols=c('L1Score','L2Score','L3Score','L4Score'),by_name=TRUE); # combine scores into 1 list
library(DescTools);
for (i in 1:20) { # calculate entropy for each participant
temp <- unlist(scores_list[i]);
entropy <- Entropy(table(temp,useNA = "no"))
entropies <- append(entropies, entropy)
};
data_pilot4.2_BLP$lang_ent <- entropies;
# multilingual balance: entropy
entropies <- list();
library(DescTools);
for (i in 1:20) { # calculate entropy for each participant
temp <- unlist(scores_list[i]);
entropy <- Entropy(table(temp,useNA = "no"))
entropies <- append(entropies, entropy)
};
data_pilot4.2_BLP$lang_ent <- entropies;
data_pilot4.2_BLP$lang_ent <- as.numeric(data_pilot4.2_BLP$lang_ent);
# corr of variance & entropy
cor(unlist(data_pilot4.2_BLP$lang_var),unlist(data_pilot4.2_BLP$lang_ent),method="pearson"); # r = -0.44 so moderately negatively correlated
# multilingual experience: summing all language scores
data_pilot4.2_BLP["L2Score"][is.na(data_pilot4.2_BLP["L2Score"])] <- 0;
data_pilot4.2_BLP["L3Score"][is.na(data_pilot4.2_BLP["L3Score"])] <- 0;
data_pilot4.2_BLP["L4Score"][is.na(data_pilot4.2_BLP["L4Score"])] <- 0;
data_pilot4.2_BLP$multi_exp <- data_pilot4.2_BLP$L1Score + data_pilot4.2_BLP$L2Score + data_pilot4.2_BLP$L3Score + data_pilot4.2_BLP$L4Score;
# L1 - L2 score
data_pilot4.2_BLP$L1_L2_diff <- data_pilot4.2_BLP$L1Score - data_pilot4.2_BLP$L2Score;
# corr of variance & accuracy
cor(data_pilot4.2_testing_means$x, data_pilot4.2_BLP$lang_var) # -0.01
# corr of entropy & accuracy
cor(data_pilot4.2_testing_means$x, data_pilot4.2_BLP$lang_ent) # 0.29
# corr of multilingual experience & accuracy
cor(data_pilot4.2_testing_means$x, data_pilot4.2_BLP$multi_exp) # 0.05
# corr of L1-L2 score & accuracy
cor(data_pilot4.2_testing_means$x, data_pilot4.2_BLP$L1_L2_diff) # -0.15
plot(data_pilot4.2_BLP$temp_sbjID,data_pilot4.2_BLP$L1_L2_diff,pch=19,xlab="Subject number",ylab="Score difference of L1 and L2",ylim=c(0,218),yaxs="i")
